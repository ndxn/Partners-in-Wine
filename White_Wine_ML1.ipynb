{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "White_Wine_ML1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhwv0JVk4OYf",
        "outputId": "fe6dc9d4-7761-4a4e-990c-18698f029361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.0'\n",
        "spark_version = 'spark-3.0.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install psycopg2-binary\n",
        "!pip install keras-tuner\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sqlalchemy import create_engine\n",
        "from kerastuner.tuners import RandomSearch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [40.1 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [405 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,687 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,353 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,118 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,165 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,748 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [864 kB]\n",
            "Fetched 10.7 MB in 5s (2,014 kB/s)\n",
            "Reading package lists... Done\n",
            "Collecting psycopg2-binary\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/1b/720b36697158113ca1b2221a8e96a470088ccf3770d182214689d1a96a07/psycopg2_binary-2.8.6-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
            "Successfully installed psycopg2-binary-2.8.6\n",
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/f7/4b41b6832abf4c9bef71a664dc563adb25afc5812831667c6db572b1a261/keras-tuner-1.0.1.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.17.0)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-cp36-none-any.whl size=73200 sha256=1d64cffe4348f7d2ef6599fb5b6236babdd843a795870e69d7c6f14ddd67bde2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/cc/62/52716b70dd90f3db12519233c3a93a5360bc672da1a10ded43\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15356 sha256=d577b32cafedb4314666dade0d4f8c9345d7c98dc7125148513af74023affd1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.1 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA2YiP5p4diM",
        "outputId": "45d1bfeb-ad79-4445-8376-9030cfbb854c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# enter the following code to download a Postgres driver that will allow Spark to interact with Postgres:\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-02 23:21:03--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  1.01MB/s    in 1.0s    \n",
            "\n",
            "2020-11-02 23:21:05 (1.01 MB/s) - ‘postgresql-42.2.16.jar’ saved [1002883/1002883]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Dpxt-P4eci"
      },
      "source": [
        "# start a Spark session with an additional option that adds the driver to Spark:\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Wine_Weather\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufHy0SIvYK7W"
      },
      "source": [
        "##***White Wine Machine Learning Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5cDkhQuDASb",
        "outputId": "61503a2f-22f2-4672-ebbf-caa8d575a1af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "#Read white wine sql table into a dataframe\n",
        "White_Soil_ML_df = pd.read_sql_table('white_soil_table', 'postgresql://postgres:postgres@database-1.cslpjur96f9r.us-east-2.rds.amazonaws.com:5432') \n",
        "White_Soil_ML_df.head() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appellation</th>\n",
              "      <th>wine</th>\n",
              "      <th>wine_id</th>\n",
              "      <th>color</th>\n",
              "      <th>regions</th>\n",
              "      <th>country</th>\n",
              "      <th>vintage</th>\n",
              "      <th>is_primeurs</th>\n",
              "      <th>score</th>\n",
              "      <th>confidence_index</th>\n",
              "      <th>journalist_count</th>\n",
              "      <th>avgPrcpFebruary</th>\n",
              "      <th>avgTempFebruary</th>\n",
              "      <th>avgPrcpMarch</th>\n",
              "      <th>avgTempMarch</th>\n",
              "      <th>avgPrcpApril</th>\n",
              "      <th>avgTempApril</th>\n",
              "      <th>avgPrcpMay</th>\n",
              "      <th>avgTempMay</th>\n",
              "      <th>avgPrcpJune</th>\n",
              "      <th>avgTempJune</th>\n",
              "      <th>avgPrcpJuly</th>\n",
              "      <th>avgTempJuly</th>\n",
              "      <th>avgPrcpAugust</th>\n",
              "      <th>avgTempAugust</th>\n",
              "      <th>avgPrcpSeptember</th>\n",
              "      <th>avgTempSeptember</th>\n",
              "      <th>avgPrcpOctober</th>\n",
              "      <th>avgTempOctober</th>\n",
              "      <th>bdod_0-100cm</th>\n",
              "      <th>bdod_100-200cm</th>\n",
              "      <th>cec_0-100cm</th>\n",
              "      <th>cec_100-200cm</th>\n",
              "      <th>cfvo_0-100cm</th>\n",
              "      <th>cfvo_100-200cm</th>\n",
              "      <th>clay_0-100cm</th>\n",
              "      <th>clay_100-200cm</th>\n",
              "      <th>nitrogen_0-100cm</th>\n",
              "      <th>nitrogen_100-200cm</th>\n",
              "      <th>ocd_0-100cm</th>\n",
              "      <th>ocd_100-200cm</th>\n",
              "      <th>ocs_0-30cm</th>\n",
              "      <th>phh2o_0-100cm</th>\n",
              "      <th>phh2o_100-200cm</th>\n",
              "      <th>sand_0-100cm</th>\n",
              "      <th>sand_100-200cm</th>\n",
              "      <th>silt_0-100cm</th>\n",
              "      <th>silt_100-200cm</th>\n",
              "      <th>soc_0-100cm</th>\n",
              "      <th>soc_100-200cm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Santa Cruz Mountains</td>\n",
              "      <td>Mount Eden Vineyards, Chardonnay, White, Santa...</td>\n",
              "      <td>107658</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.22</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>0.174747</td>\n",
              "      <td>58</td>\n",
              "      <td>0.018630</td>\n",
              "      <td>60</td>\n",
              "      <td>0.096254</td>\n",
              "      <td>59</td>\n",
              "      <td>0.002989</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>65</td>\n",
              "      <td>0.001132</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000947</td>\n",
              "      <td>70</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>68</td>\n",
              "      <td>0.005581</td>\n",
              "      <td>66</td>\n",
              "      <td>139.75</td>\n",
              "      <td>149</td>\n",
              "      <td>153.4</td>\n",
              "      <td>145</td>\n",
              "      <td>183.5</td>\n",
              "      <td>245</td>\n",
              "      <td>197.50</td>\n",
              "      <td>193</td>\n",
              "      <td>145.7</td>\n",
              "      <td>60</td>\n",
              "      <td>124.95</td>\n",
              "      <td>25</td>\n",
              "      <td>60</td>\n",
              "      <td>5.50206</td>\n",
              "      <td>5.9</td>\n",
              "      <td>442.10</td>\n",
              "      <td>468</td>\n",
              "      <td>324.85</td>\n",
              "      <td>283</td>\n",
              "      <td>128.55</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Napa Valley</td>\n",
              "      <td>Pahlmeyer, Napa Valley Chardonnay, White, Napa...</td>\n",
              "      <td>111897</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.83</td>\n",
              "      <td>C+</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.5</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.6</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>418.85</td>\n",
              "      <td>410</td>\n",
              "      <td>84.00</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sonoma Coast</td>\n",
              "      <td>Marcassin, Lorenzo Vineyard Chardonnay, White,...</td>\n",
              "      <td>101640</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1993</td>\n",
              "      <td>False</td>\n",
              "      <td>92.07</td>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "      <td>0.275357</td>\n",
              "      <td>58</td>\n",
              "      <td>0.086129</td>\n",
              "      <td>67</td>\n",
              "      <td>0.050667</td>\n",
              "      <td>68</td>\n",
              "      <td>0.068929</td>\n",
              "      <td>73</td>\n",
              "      <td>0.029333</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85</td>\n",
              "      <td>0.058710</td>\n",
              "      <td>77</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.5</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.5</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>319.20</td>\n",
              "      <td>251</td>\n",
              "      <td>98.60</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sonoma Coast</td>\n",
              "      <td>Marcassin, Lorenzo Vineyard Chardonnay, White,...</td>\n",
              "      <td>101640</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1998</td>\n",
              "      <td>False</td>\n",
              "      <td>91.74</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>0.674643</td>\n",
              "      <td>57</td>\n",
              "      <td>0.074516</td>\n",
              "      <td>64</td>\n",
              "      <td>0.060345</td>\n",
              "      <td>68</td>\n",
              "      <td>0.125806</td>\n",
              "      <td>67</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>76</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>83</td>\n",
              "      <td>0.027419</td>\n",
              "      <td>75</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.5</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.5</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>319.20</td>\n",
              "      <td>251</td>\n",
              "      <td>98.60</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Napa Valley</td>\n",
              "      <td>Kongsgaard, The Judge Chardonnay, White, Napa ...</td>\n",
              "      <td>91591</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>97.27</td>\n",
              "      <td>B+</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.5</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.6</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>418.85</td>\n",
              "      <td>410</td>\n",
              "      <td>84.00</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            appellation  ... soc_100-200cm\n",
              "0  Santa Cruz Mountains  ...            38\n",
              "1           Napa Valley  ...            27\n",
              "2          Sonoma Coast  ...            18\n",
              "3          Sonoma Coast  ...            18\n",
              "4           Napa Valley  ...            27\n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NORZgQZO59u",
        "outputId": "a55186b1-49a6-4d9a-9001-077bc0c87df6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "White_Soil_ML_df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "appellation            object\n",
              "wine                   object\n",
              "wine_id                 int64\n",
              "color                  object\n",
              "regions                object\n",
              "country                object\n",
              "vintage                 int64\n",
              "is_primeurs              bool\n",
              "score                 float64\n",
              "confidence_index       object\n",
              "journalist_count        int64\n",
              "avgPrcpFebruary       float64\n",
              "avgTempFebruary         int64\n",
              "avgPrcpMarch          float64\n",
              "avgTempMarch            int64\n",
              "avgPrcpApril          float64\n",
              "avgTempApril            int64\n",
              "avgPrcpMay            float64\n",
              "avgTempMay              int64\n",
              "avgPrcpJune           float64\n",
              "avgTempJune             int64\n",
              "avgPrcpJuly           float64\n",
              "avgTempJuly             int64\n",
              "avgPrcpAugust         float64\n",
              "avgTempAugust           int64\n",
              "avgPrcpSeptember      float64\n",
              "avgTempSeptember        int64\n",
              "avgPrcpOctober        float64\n",
              "avgTempOctober          int64\n",
              "bdod_0-100cm          float64\n",
              "bdod_100-200cm          int64\n",
              "cec_0-100cm           float64\n",
              "cec_100-200cm           int64\n",
              "cfvo_0-100cm          float64\n",
              "cfvo_100-200cm          int64\n",
              "clay_0-100cm          float64\n",
              "clay_100-200cm          int64\n",
              "nitrogen_0-100cm      float64\n",
              "nitrogen_100-200cm      int64\n",
              "ocd_0-100cm           float64\n",
              "ocd_100-200cm           int64\n",
              "ocs_0-30cm              int64\n",
              "phh2o_0-100cm         float64\n",
              "phh2o_100-200cm       float64\n",
              "sand_0-100cm          float64\n",
              "sand_100-200cm          int64\n",
              "silt_0-100cm          float64\n",
              "silt_100-200cm          int64\n",
              "soc_0-100cm           float64\n",
              "soc_100-200cm           int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yFuv7s1O59y",
        "outputId": "4c97ca4e-fa08-49c4-ecb4-bd7d1c66bd6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "White_Soil_ML_df[\"score\"].astype(int) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      92\n",
              "1      92\n",
              "2      92\n",
              "3      91\n",
              "4      97\n",
              "       ..\n",
              "727    87\n",
              "728    91\n",
              "729    93\n",
              "730    86\n",
              "731    88\n",
              "Name: score, Length: 732, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFRIEoeWO590"
      },
      "source": [
        "#Splitting score into good(1) and bad(0) and making it it's own column \"quality\"\n",
        "quality = []\n",
        "\n",
        "for x in White_Soil_ML_df[\"score\"]:\n",
        "  if x >= 91:\n",
        "    quality.append(1)\n",
        "  else:\n",
        "    quality.append(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUx-ic_fO592"
      },
      "source": [
        "White_Soil_ML_df[\"quality\"] = quality"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvx4qNPNO594",
        "outputId": "70c454a9-79a3-422c-c0ff-ebba26415279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "White_Soil_ML_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appellation</th>\n",
              "      <th>wine</th>\n",
              "      <th>wine_id</th>\n",
              "      <th>color</th>\n",
              "      <th>regions</th>\n",
              "      <th>country</th>\n",
              "      <th>vintage</th>\n",
              "      <th>is_primeurs</th>\n",
              "      <th>score</th>\n",
              "      <th>confidence_index</th>\n",
              "      <th>journalist_count</th>\n",
              "      <th>avgPrcpFebruary</th>\n",
              "      <th>avgTempFebruary</th>\n",
              "      <th>avgPrcpMarch</th>\n",
              "      <th>avgTempMarch</th>\n",
              "      <th>avgPrcpApril</th>\n",
              "      <th>avgTempApril</th>\n",
              "      <th>avgPrcpMay</th>\n",
              "      <th>avgTempMay</th>\n",
              "      <th>avgPrcpJune</th>\n",
              "      <th>avgTempJune</th>\n",
              "      <th>avgPrcpJuly</th>\n",
              "      <th>avgTempJuly</th>\n",
              "      <th>avgPrcpAugust</th>\n",
              "      <th>avgTempAugust</th>\n",
              "      <th>avgPrcpSeptember</th>\n",
              "      <th>avgTempSeptember</th>\n",
              "      <th>avgPrcpOctober</th>\n",
              "      <th>avgTempOctober</th>\n",
              "      <th>bdod_0-100cm</th>\n",
              "      <th>bdod_100-200cm</th>\n",
              "      <th>cec_0-100cm</th>\n",
              "      <th>cec_100-200cm</th>\n",
              "      <th>cfvo_0-100cm</th>\n",
              "      <th>cfvo_100-200cm</th>\n",
              "      <th>clay_0-100cm</th>\n",
              "      <th>clay_100-200cm</th>\n",
              "      <th>nitrogen_0-100cm</th>\n",
              "      <th>nitrogen_100-200cm</th>\n",
              "      <th>ocd_0-100cm</th>\n",
              "      <th>ocd_100-200cm</th>\n",
              "      <th>ocs_0-30cm</th>\n",
              "      <th>phh2o_0-100cm</th>\n",
              "      <th>phh2o_100-200cm</th>\n",
              "      <th>sand_0-100cm</th>\n",
              "      <th>sand_100-200cm</th>\n",
              "      <th>silt_0-100cm</th>\n",
              "      <th>silt_100-200cm</th>\n",
              "      <th>soc_0-100cm</th>\n",
              "      <th>soc_100-200cm</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Santa Cruz Mountains</td>\n",
              "      <td>Mount Eden Vineyards, Chardonnay, White, Santa...</td>\n",
              "      <td>107658</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.22</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>0.174747</td>\n",
              "      <td>58</td>\n",
              "      <td>0.018630</td>\n",
              "      <td>60</td>\n",
              "      <td>0.096254</td>\n",
              "      <td>59</td>\n",
              "      <td>0.002989</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>65</td>\n",
              "      <td>0.001132</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000947</td>\n",
              "      <td>70</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>68</td>\n",
              "      <td>0.005581</td>\n",
              "      <td>66</td>\n",
              "      <td>139.75</td>\n",
              "      <td>149</td>\n",
              "      <td>153.4</td>\n",
              "      <td>145</td>\n",
              "      <td>183.50</td>\n",
              "      <td>245</td>\n",
              "      <td>197.50</td>\n",
              "      <td>193</td>\n",
              "      <td>145.70</td>\n",
              "      <td>60</td>\n",
              "      <td>124.95</td>\n",
              "      <td>25</td>\n",
              "      <td>60</td>\n",
              "      <td>5.50206</td>\n",
              "      <td>5.9</td>\n",
              "      <td>442.10</td>\n",
              "      <td>468</td>\n",
              "      <td>324.85</td>\n",
              "      <td>283</td>\n",
              "      <td>128.55</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Napa Valley</td>\n",
              "      <td>Pahlmeyer, Napa Valley Chardonnay, White, Napa...</td>\n",
              "      <td>111897</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.83</td>\n",
              "      <td>C+</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.50</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.60</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>418.85</td>\n",
              "      <td>410</td>\n",
              "      <td>84.00</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sonoma Coast</td>\n",
              "      <td>Marcassin, Lorenzo Vineyard Chardonnay, White,...</td>\n",
              "      <td>101640</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1993</td>\n",
              "      <td>False</td>\n",
              "      <td>92.07</td>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "      <td>0.275357</td>\n",
              "      <td>58</td>\n",
              "      <td>0.086129</td>\n",
              "      <td>67</td>\n",
              "      <td>0.050667</td>\n",
              "      <td>68</td>\n",
              "      <td>0.068929</td>\n",
              "      <td>73</td>\n",
              "      <td>0.029333</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85</td>\n",
              "      <td>0.058710</td>\n",
              "      <td>77</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.50</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.50</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>319.20</td>\n",
              "      <td>251</td>\n",
              "      <td>98.60</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sonoma Coast</td>\n",
              "      <td>Marcassin, Lorenzo Vineyard Chardonnay, White,...</td>\n",
              "      <td>101640</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1998</td>\n",
              "      <td>False</td>\n",
              "      <td>91.74</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>0.674643</td>\n",
              "      <td>57</td>\n",
              "      <td>0.074516</td>\n",
              "      <td>64</td>\n",
              "      <td>0.060345</td>\n",
              "      <td>68</td>\n",
              "      <td>0.125806</td>\n",
              "      <td>67</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>76</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>83</td>\n",
              "      <td>0.027419</td>\n",
              "      <td>75</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.50</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.50</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>319.20</td>\n",
              "      <td>251</td>\n",
              "      <td>98.60</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Napa Valley</td>\n",
              "      <td>Kongsgaard, The Judge Chardonnay, White, Napa ...</td>\n",
              "      <td>91591</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>97.27</td>\n",
              "      <td>B+</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.50</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.60</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>418.85</td>\n",
              "      <td>410</td>\n",
              "      <td>84.00</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>Carneros</td>\n",
              "      <td>Truchard Vineyards, Chardonnay, White, Carneros</td>\n",
              "      <td>136966</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1996</td>\n",
              "      <td>False</td>\n",
              "      <td>87.68</td>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "      <td>0.312000</td>\n",
              "      <td>62</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>68</td>\n",
              "      <td>0.116333</td>\n",
              "      <td>71</td>\n",
              "      <td>0.108710</td>\n",
              "      <td>76</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90</td>\n",
              "      <td>0.005667</td>\n",
              "      <td>83</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>76</td>\n",
              "      <td>160.40</td>\n",
              "      <td>161</td>\n",
              "      <td>215.4</td>\n",
              "      <td>233</td>\n",
              "      <td>30.15</td>\n",
              "      <td>25</td>\n",
              "      <td>216.10</td>\n",
              "      <td>219</td>\n",
              "      <td>60.15</td>\n",
              "      <td>36</td>\n",
              "      <td>117.25</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>5.80206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>317.75</td>\n",
              "      <td>340</td>\n",
              "      <td>408.60</td>\n",
              "      <td>401</td>\n",
              "      <td>57.90</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>Sonoma County</td>\n",
              "      <td>Peter Michael Winery, Belle Cote Chardonnay, W...</td>\n",
              "      <td>114819</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1996</td>\n",
              "      <td>False</td>\n",
              "      <td>91.76</td>\n",
              "      <td>C+</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>145.00</td>\n",
              "      <td>150</td>\n",
              "      <td>184.4</td>\n",
              "      <td>190</td>\n",
              "      <td>105.50</td>\n",
              "      <td>110</td>\n",
              "      <td>262.80</td>\n",
              "      <td>298</td>\n",
              "      <td>84.70</td>\n",
              "      <td>36</td>\n",
              "      <td>121.60</td>\n",
              "      <td>29</td>\n",
              "      <td>55</td>\n",
              "      <td>5.20206</td>\n",
              "      <td>5.7</td>\n",
              "      <td>352.40</td>\n",
              "      <td>337</td>\n",
              "      <td>371.65</td>\n",
              "      <td>346</td>\n",
              "      <td>110.95</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>Carneros</td>\n",
              "      <td>Kistler Vineyards, Hudson Vineyard Chardonnay,...</td>\n",
              "      <td>91298</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1995</td>\n",
              "      <td>False</td>\n",
              "      <td>93.90</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "      <td>0.029286</td>\n",
              "      <td>63</td>\n",
              "      <td>0.428710</td>\n",
              "      <td>63</td>\n",
              "      <td>0.044333</td>\n",
              "      <td>68</td>\n",
              "      <td>0.060968</td>\n",
              "      <td>72</td>\n",
              "      <td>0.034667</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80</td>\n",
              "      <td>160.40</td>\n",
              "      <td>161</td>\n",
              "      <td>215.4</td>\n",
              "      <td>233</td>\n",
              "      <td>30.15</td>\n",
              "      <td>25</td>\n",
              "      <td>216.10</td>\n",
              "      <td>219</td>\n",
              "      <td>60.15</td>\n",
              "      <td>36</td>\n",
              "      <td>117.25</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>5.80206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>317.75</td>\n",
              "      <td>340</td>\n",
              "      <td>408.60</td>\n",
              "      <td>401</td>\n",
              "      <td>57.90</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>Los Carneros</td>\n",
              "      <td>Joseph Phelps Vineyards, Carneros Chardonnay, ...</td>\n",
              "      <td>89562</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1996</td>\n",
              "      <td>False</td>\n",
              "      <td>86.86</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "      <td>0.368800</td>\n",
              "      <td>52</td>\n",
              "      <td>0.087500</td>\n",
              "      <td>54</td>\n",
              "      <td>0.127000</td>\n",
              "      <td>56</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>64</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>63</td>\n",
              "      <td>0.062581</td>\n",
              "      <td>60</td>\n",
              "      <td>158.50</td>\n",
              "      <td>160</td>\n",
              "      <td>218.4</td>\n",
              "      <td>224</td>\n",
              "      <td>80.25</td>\n",
              "      <td>60</td>\n",
              "      <td>196.15</td>\n",
              "      <td>190</td>\n",
              "      <td>60.85</td>\n",
              "      <td>35</td>\n",
              "      <td>118.15</td>\n",
              "      <td>37</td>\n",
              "      <td>34</td>\n",
              "      <td>5.60206</td>\n",
              "      <td>6.2</td>\n",
              "      <td>353.05</td>\n",
              "      <td>365</td>\n",
              "      <td>362.85</td>\n",
              "      <td>391</td>\n",
              "      <td>63.50</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>731</th>\n",
              "      <td>Sonoma County</td>\n",
              "      <td>Ferrari-Carano, Fume Blanc, White, Sonoma County</td>\n",
              "      <td>73121</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1993</td>\n",
              "      <td>False</td>\n",
              "      <td>88.14</td>\n",
              "      <td>B+</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>145.00</td>\n",
              "      <td>150</td>\n",
              "      <td>184.4</td>\n",
              "      <td>190</td>\n",
              "      <td>105.50</td>\n",
              "      <td>110</td>\n",
              "      <td>262.80</td>\n",
              "      <td>298</td>\n",
              "      <td>84.70</td>\n",
              "      <td>36</td>\n",
              "      <td>121.60</td>\n",
              "      <td>29</td>\n",
              "      <td>55</td>\n",
              "      <td>5.20206</td>\n",
              "      <td>5.7</td>\n",
              "      <td>352.40</td>\n",
              "      <td>337</td>\n",
              "      <td>371.65</td>\n",
              "      <td>346</td>\n",
              "      <td>110.95</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>732 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              appellation  ... quality\n",
              "0    Santa Cruz Mountains  ...       1\n",
              "1             Napa Valley  ...       1\n",
              "2            Sonoma Coast  ...       1\n",
              "3            Sonoma Coast  ...       1\n",
              "4             Napa Valley  ...       1\n",
              "..                    ...  ...     ...\n",
              "727              Carneros  ...       0\n",
              "728         Sonoma County  ...       1\n",
              "729              Carneros  ...       1\n",
              "730          Los Carneros  ...       0\n",
              "731         Sonoma County  ...       0\n",
              "\n",
              "[732 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FBb4KAPO596",
        "outputId": "d6918e13-f322-4f80-e462-fd435ec6feeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Generate our categorical variable list\n",
        "White_Wine_cat = White_Soil_ML_df.dtypes[White_Soil_ML_df.dtypes == \"object\"].index.tolist()\n",
        "\n",
        "# Check the number of unique values in each column\n",
        "White_Soil_ML_df[White_Wine_cat].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "appellation          22\n",
              "wine                163\n",
              "color                 1\n",
              "regions               3\n",
              "country               1\n",
              "confidence_index      6\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4mB3r6TO598",
        "outputId": "27e0f909-35cd-4686-c164-5da465ef15f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the unique value counts to see if binning is required for Appellation\n",
        "Appellation_Count = White_Soil_ML_df.appellation.value_counts()\n",
        "Appellation_Count.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Napa Valley             229\n",
              "Carneros                112\n",
              "Russian River Valley     92\n",
              "Sonoma County            80\n",
              "Knights Valley           49\n",
              "Sonoma Coast             37\n",
              "Sonoma Mountain          29\n",
              "Santa Cruz Mountains     19\n",
              "Columbia Valley          17\n",
              "Eola-Amity Hills         13\n",
              "Name: appellation, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg62g5TjO5-A",
        "outputId": "43e0eb8c-cc05-4866-b09e-382e176344ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Visualize the Appellation_Count\n",
        "Appellation_Count.plot.density()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff5749ae978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pTwMSKWO5-C"
      },
      "source": [
        "# Determine which values to replace for \n",
        "Appellation_Bin =  list(Appellation_Count[Appellation_Count < 200].index)\n",
        "# Replace in DataFrame\n",
        "for type in Appellation_Bin:\n",
        "    White_Soil_ML_df.appellation = White_Soil_ML_df.appellation.replace(type,\"Other\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55cb4HnEO5-G",
        "outputId": "277213bc-f161-4cb4-c695-725c703f7706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check to make sure binning was successful for Appellation\n",
        "White_Soil_ML_df.appellation.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Other          503\n",
              "Napa Valley    229\n",
              "Name: appellation, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoMqlVkUO5-I"
      },
      "source": [
        "# White_Soil_ML_df[White_Soil_ML_df.appellation != 'Other']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLCf6JriO5-L",
        "outputId": "f4882b8e-55e9-4dbd-aa10-5e86e53c8cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "# Create the OneHotEncoder instance\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit the encoder and produce encoded DataFrame\n",
        "White_Wine_encode_df = pd.DataFrame(enc.fit_transform(White_Soil_ML_df[White_Wine_cat]))\n",
        "\n",
        "# Rename encoded columns\n",
        "White_Wine_encode_df.columns = enc.get_feature_names(White_Wine_cat)\n",
        "White_Wine_encode_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appellation_Napa Valley</th>\n",
              "      <th>appellation_Other</th>\n",
              "      <th>wine_Alpha Omega, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Alpha Omega, Reserve Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Apsara Cellars, 'Rivers Reach' Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Araujo Estate, Eisele Vineyard Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Aubert Wines, Hudson Vineyard Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Aubert Wines, Larry Hyde &amp; Sons Vineyard Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Aubert Wines, Ritchie Vineyard Chardonnay, White, Sonoma Coast</th>\n",
              "      <th>wine_Aubert Wines, Sugar Shack Estate Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Aubert Wines, Uv-Sl Vineyards Chardonnay, White, Sonoma Coast</th>\n",
              "      <th>wine_Beaulieu Vineyard Bv, Reserve Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Beringer Vineyards, 'Luminus' Chardonnay, White, Oak Knoll District</th>\n",
              "      <th>wine_Beringer Vineyards, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Beringer Vineyards, Private Reserve Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Cakebread Cellars, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Cakebread Cellars, Reserve Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Cakebread Cellars, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Chappellet, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Charles Krug Peter Mondavi Family, Sauvignon Blanc, White, St Helena</th>\n",
              "      <th>wine_Chateau Montelena, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Cliff Lede Vineyards, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Clos Du Val, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Clos Du Val, Winemaker'S Signature Series Three Graces White Blend, White, Napa Valley</th>\n",
              "      <th>wine_Crossbarn By Paul Hobbs, Chardonnay, White, Sonoma Coast</th>\n",
              "      <th>wine_Cuvaison, Ats Selection Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Cuvaison, Carneros Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Delille Cellars, Chaleur Estate Blanc, White, Columbia Valley</th>\n",
              "      <th>wine_Delille Cellars, Doyenne Metier Blanc, White, Red Mountain</th>\n",
              "      <th>wine_Delille Cellars, Doyenne Roussanne, White, Red Mountain</th>\n",
              "      <th>wine_Domaine Serene, 'Dijon Clones - Cote Sud Vineyard' Chardonnay, White, Willamette Valley</th>\n",
              "      <th>wine_Domaine Serene, 'Evenstad Reserve' Chardonnay, White, Dundee Hills</th>\n",
              "      <th>wine_Domaine Serene, Clos Du Soleil Vineyard Chardonnay, White, Dundee Hills</th>\n",
              "      <th>wine_Domaine Serene, Etoile Vineyard Chardonnay, White, Dundee Hills</th>\n",
              "      <th>wine_Duckhorn Vineyards, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Duckhorn Vineyards, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Dumol, Clare Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Etude, Grace Benoist Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Etude, Pinot Gris, White, Carneros</th>\n",
              "      <th>wine_Evening Land, Gold Label Seven Springs Vineyard Chardonnay, White, Eola-Amity Hills</th>\n",
              "      <th>...</th>\n",
              "      <th>wine_Robert Foley Vineyards, Pinot Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Robert Mondavi Winery, Carneros Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Robert Mondavi Winery, Napa Valley Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Rombauer Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Rudd, Bacigalupi Vineyard Chardonnay, White, Russian River Valley</th>\n",
              "      <th>wine_Rudd, Mount Veeder Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Saintsbury, Brown Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Saintsbury, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Saintsbury, Reserve Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Screaming Eagle, Sauvignon Blanc, White, Oakville</th>\n",
              "      <th>wine_Shafer Vineyards, Red Shoulder Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards Estate, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards, 'Vineburg Vineyard' Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards, Miller Ranch Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Smith Madrone, Riesling, White, Spring Mountain District</th>\n",
              "      <th>wine_Spottswoode, Sauvignon Blanc, White, Napa County</th>\n",
              "      <th>wine_St. Clement Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Arcadia Vineyard Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Aveta Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Karia Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Stags' Leap Winery, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Trefethen Family Vineyards, Chardonnay, White, Oak Knoll District</th>\n",
              "      <th>wine_Truchard Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Truchard Vineyards, Roussanne, White, Carneros</th>\n",
              "      <th>wine_Turnbull Wine Cellars, Sauvignon Blanc, White, Oakville</th>\n",
              "      <th>wine_Twomey Cellars, Sauvignon Blanc, White, Napa County</th>\n",
              "      <th>wine_Venge Vineyards, Maldonado Vineyard Dijon Clones Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Vine Cliff Winery, Chardonnay, White, Los Carneros</th>\n",
              "      <th>color_White</th>\n",
              "      <th>regions_California</th>\n",
              "      <th>regions_Oregon</th>\n",
              "      <th>regions_Washington</th>\n",
              "      <th>country_Usa</th>\n",
              "      <th>confidence_index_A</th>\n",
              "      <th>confidence_index_A+</th>\n",
              "      <th>confidence_index_B</th>\n",
              "      <th>confidence_index_B+</th>\n",
              "      <th>confidence_index_C</th>\n",
              "      <th>confidence_index_C+</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 176 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   appellation_Napa Valley  ...  confidence_index_C+\n",
              "0                      0.0  ...                  0.0\n",
              "1                      1.0  ...                  1.0\n",
              "2                      0.0  ...                  0.0\n",
              "3                      0.0  ...                  0.0\n",
              "4                      1.0  ...                  0.0\n",
              "\n",
              "[5 rows x 176 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF4QT7qzO5-N",
        "outputId": "b3e49a54-5c42-4865-e582-43273e46c2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "# Merge one-hot encoded features and drop the originals\n",
        "White_Soil_ML_df = White_Soil_ML_df.merge(White_Wine_encode_df,left_index=True, right_index=True)\n",
        "White_Soil_ML_df = White_Soil_ML_df.drop(White_Wine_cat,1)\n",
        "White_Soil_ML_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wine_id</th>\n",
              "      <th>vintage</th>\n",
              "      <th>is_primeurs</th>\n",
              "      <th>score</th>\n",
              "      <th>journalist_count</th>\n",
              "      <th>avgPrcpFebruary</th>\n",
              "      <th>avgTempFebruary</th>\n",
              "      <th>avgPrcpMarch</th>\n",
              "      <th>avgTempMarch</th>\n",
              "      <th>avgPrcpApril</th>\n",
              "      <th>avgTempApril</th>\n",
              "      <th>avgPrcpMay</th>\n",
              "      <th>avgTempMay</th>\n",
              "      <th>avgPrcpJune</th>\n",
              "      <th>avgTempJune</th>\n",
              "      <th>avgPrcpJuly</th>\n",
              "      <th>avgTempJuly</th>\n",
              "      <th>avgPrcpAugust</th>\n",
              "      <th>avgTempAugust</th>\n",
              "      <th>avgPrcpSeptember</th>\n",
              "      <th>avgTempSeptember</th>\n",
              "      <th>avgPrcpOctober</th>\n",
              "      <th>avgTempOctober</th>\n",
              "      <th>bdod_0-100cm</th>\n",
              "      <th>bdod_100-200cm</th>\n",
              "      <th>cec_0-100cm</th>\n",
              "      <th>cec_100-200cm</th>\n",
              "      <th>cfvo_0-100cm</th>\n",
              "      <th>cfvo_100-200cm</th>\n",
              "      <th>clay_0-100cm</th>\n",
              "      <th>clay_100-200cm</th>\n",
              "      <th>nitrogen_0-100cm</th>\n",
              "      <th>nitrogen_100-200cm</th>\n",
              "      <th>ocd_0-100cm</th>\n",
              "      <th>ocd_100-200cm</th>\n",
              "      <th>ocs_0-30cm</th>\n",
              "      <th>phh2o_0-100cm</th>\n",
              "      <th>phh2o_100-200cm</th>\n",
              "      <th>sand_0-100cm</th>\n",
              "      <th>sand_100-200cm</th>\n",
              "      <th>...</th>\n",
              "      <th>wine_Robert Foley Vineyards, Pinot Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Robert Mondavi Winery, Carneros Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Robert Mondavi Winery, Napa Valley Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Rombauer Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Rudd, Bacigalupi Vineyard Chardonnay, White, Russian River Valley</th>\n",
              "      <th>wine_Rudd, Mount Veeder Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Saintsbury, Brown Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Saintsbury, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Saintsbury, Reserve Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Screaming Eagle, Sauvignon Blanc, White, Oakville</th>\n",
              "      <th>wine_Shafer Vineyards, Red Shoulder Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards Estate, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards, 'Vineburg Vineyard' Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards, Miller Ranch Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Smith Madrone, Riesling, White, Spring Mountain District</th>\n",
              "      <th>wine_Spottswoode, Sauvignon Blanc, White, Napa County</th>\n",
              "      <th>wine_St. Clement Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Arcadia Vineyard Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Aveta Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Karia Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Stags' Leap Winery, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Trefethen Family Vineyards, Chardonnay, White, Oak Knoll District</th>\n",
              "      <th>wine_Truchard Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Truchard Vineyards, Roussanne, White, Carneros</th>\n",
              "      <th>wine_Turnbull Wine Cellars, Sauvignon Blanc, White, Oakville</th>\n",
              "      <th>wine_Twomey Cellars, Sauvignon Blanc, White, Napa County</th>\n",
              "      <th>wine_Venge Vineyards, Maldonado Vineyard Dijon Clones Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Vine Cliff Winery, Chardonnay, White, Los Carneros</th>\n",
              "      <th>color_White</th>\n",
              "      <th>regions_California</th>\n",
              "      <th>regions_Oregon</th>\n",
              "      <th>regions_Washington</th>\n",
              "      <th>country_Usa</th>\n",
              "      <th>confidence_index_A</th>\n",
              "      <th>confidence_index_A+</th>\n",
              "      <th>confidence_index_B</th>\n",
              "      <th>confidence_index_B+</th>\n",
              "      <th>confidence_index_C</th>\n",
              "      <th>confidence_index_C+</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>107658</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.22</td>\n",
              "      <td>4</td>\n",
              "      <td>0.174747</td>\n",
              "      <td>58</td>\n",
              "      <td>0.018630</td>\n",
              "      <td>60</td>\n",
              "      <td>0.096254</td>\n",
              "      <td>59</td>\n",
              "      <td>0.002989</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>65</td>\n",
              "      <td>0.001132</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000947</td>\n",
              "      <td>70</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>68</td>\n",
              "      <td>0.005581</td>\n",
              "      <td>66</td>\n",
              "      <td>139.75</td>\n",
              "      <td>149</td>\n",
              "      <td>153.4</td>\n",
              "      <td>145</td>\n",
              "      <td>183.5</td>\n",
              "      <td>245</td>\n",
              "      <td>197.50</td>\n",
              "      <td>193</td>\n",
              "      <td>145.7</td>\n",
              "      <td>60</td>\n",
              "      <td>124.95</td>\n",
              "      <td>25</td>\n",
              "      <td>60</td>\n",
              "      <td>5.50206</td>\n",
              "      <td>5.9</td>\n",
              "      <td>442.10</td>\n",
              "      <td>468</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>111897</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.83</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.5</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.6</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101640</td>\n",
              "      <td>1993</td>\n",
              "      <td>False</td>\n",
              "      <td>92.07</td>\n",
              "      <td>3</td>\n",
              "      <td>0.275357</td>\n",
              "      <td>58</td>\n",
              "      <td>0.086129</td>\n",
              "      <td>67</td>\n",
              "      <td>0.050667</td>\n",
              "      <td>68</td>\n",
              "      <td>0.068929</td>\n",
              "      <td>73</td>\n",
              "      <td>0.029333</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85</td>\n",
              "      <td>0.058710</td>\n",
              "      <td>77</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.5</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.5</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>101640</td>\n",
              "      <td>1998</td>\n",
              "      <td>False</td>\n",
              "      <td>91.74</td>\n",
              "      <td>4</td>\n",
              "      <td>0.674643</td>\n",
              "      <td>57</td>\n",
              "      <td>0.074516</td>\n",
              "      <td>64</td>\n",
              "      <td>0.060345</td>\n",
              "      <td>68</td>\n",
              "      <td>0.125806</td>\n",
              "      <td>67</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>76</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>83</td>\n",
              "      <td>0.027419</td>\n",
              "      <td>75</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.5</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.5</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91591</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>97.27</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.5</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.6</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 221 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   wine_id  vintage  ...  confidence_index_C  confidence_index_C+\n",
              "0   107658     2015  ...                 0.0                  0.0\n",
              "1   111897     2015  ...                 0.0                  1.0\n",
              "2   101640     1993  ...                 1.0                  0.0\n",
              "3   101640     1998  ...                 0.0                  0.0\n",
              "4    91591     2015  ...                 0.0                  0.0\n",
              "\n",
              "[5 rows x 221 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uPm_kDc8Fon"
      },
      "source": [
        "## ***Wine Only - Drop All weather and soil columns***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCbZATbmO5-Q"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = White_Soil_ML_df[\"quality\"].values\n",
        "X = White_Soil_ML_df.drop([\"quality\", \"is_primeurs\", \"journalist_count\", \"confidence_index_A\",\"confidence_index_A+\", \"confidence_index_B\", \"confidence_index_B+\",\"confidence_index_C\", \"confidence_index_C+\", 'avgPrcpFebruary',\n",
        " 'avgTempFebruary',\n",
        " 'avgPrcpMarch',\n",
        " 'avgTempMarch',\n",
        " 'avgPrcpApril',\n",
        " 'avgTempApril',\n",
        " 'avgPrcpMay',\n",
        " 'avgTempMay',\n",
        " 'avgPrcpJune',\n",
        " 'avgTempJune',\n",
        " 'avgPrcpJuly',\n",
        " 'avgTempJuly',\n",
        " 'avgPrcpAugust',\n",
        " 'avgTempAugust',\n",
        " 'avgPrcpSeptember',\n",
        " 'avgTempSeptember',\n",
        " 'avgPrcpOctober',\n",
        " 'avgTempOctober',\n",
        " 'bdod_0-100cm',\n",
        " 'bdod_100-200cm',\n",
        " 'cec_0-100cm',\n",
        " 'cec_100-200cm',\n",
        " 'cfvo_0-100cm',\n",
        " 'cfvo_100-200cm',\n",
        " 'clay_0-100cm',\n",
        " 'clay_100-200cm',\n",
        " 'nitrogen_0-100cm',\n",
        " 'nitrogen_100-200cm',\n",
        " 'ocd_0-100cm',\n",
        " 'ocd_100-200cm',\n",
        " 'ocs_0-30cm',\n",
        " 'phh2o_0-100cm',\n",
        " 'phh2o_100-200cm',\n",
        " 'sand_0-100cm',\n",
        " 'sand_100-200cm',\n",
        " 'silt_0-100cm',\n",
        " 'silt_100-200cm',\n",
        " 'soc_0-100cm',\n",
        " 'soc_100-200cm'],1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcVEIlvIO5-S"
      },
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X)\n",
        "X_scaled = X_scaler.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE4Fr6BaJ-Ep"
      },
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, random_state=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G73C39aiO5-V"
      },
      "source": [
        "###***Deep Learning Neural Netwrok for training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u7Lvg2HO5-V",
        "outputId": "bae1b542-1cad-4286-a856-94c83c6b84b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[-1])\n",
        "hidden_nodes_layer1 =  24\n",
        "hidden_nodes_layer2 = 12\n",
        "\n",
        "# metrics = [\n",
        "#     tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "#     tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "#     tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "#     tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "#     tf.keras.metrics.Precision(name=\"precision\"),\n",
        "#     tf.keras.metrics.Recall(name=\"recall\"),\n",
        "# ]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.5,verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 - 0s - loss: 0.7252 - accuracy: 0.5730 - val_loss: 0.6733 - val_accuracy: 0.6073\n",
            "Epoch 2/50\n",
            "9/9 - 0s - loss: 0.6403 - accuracy: 0.6606 - val_loss: 0.6261 - val_accuracy: 0.6582\n",
            "Epoch 3/50\n",
            "9/9 - 0s - loss: 0.5832 - accuracy: 0.6971 - val_loss: 0.5893 - val_accuracy: 0.7273\n",
            "Epoch 4/50\n",
            "9/9 - 0s - loss: 0.5333 - accuracy: 0.7737 - val_loss: 0.5582 - val_accuracy: 0.7273\n",
            "Epoch 5/50\n",
            "9/9 - 0s - loss: 0.4925 - accuracy: 0.7883 - val_loss: 0.5336 - val_accuracy: 0.7273\n",
            "Epoch 6/50\n",
            "9/9 - 0s - loss: 0.4565 - accuracy: 0.7993 - val_loss: 0.5091 - val_accuracy: 0.7564\n",
            "Epoch 7/50\n",
            "9/9 - 0s - loss: 0.4219 - accuracy: 0.8321 - val_loss: 0.4879 - val_accuracy: 0.7782\n",
            "Epoch 8/50\n",
            "9/9 - 0s - loss: 0.3941 - accuracy: 0.8467 - val_loss: 0.4696 - val_accuracy: 0.7855\n",
            "Epoch 9/50\n",
            "9/9 - 0s - loss: 0.3690 - accuracy: 0.8540 - val_loss: 0.4539 - val_accuracy: 0.8000\n",
            "Epoch 10/50\n",
            "9/9 - 0s - loss: 0.3456 - accuracy: 0.8613 - val_loss: 0.4388 - val_accuracy: 0.7964\n",
            "Epoch 11/50\n",
            "9/9 - 0s - loss: 0.3239 - accuracy: 0.8759 - val_loss: 0.4246 - val_accuracy: 0.8036\n",
            "Epoch 12/50\n",
            "9/9 - 0s - loss: 0.3049 - accuracy: 0.8796 - val_loss: 0.4118 - val_accuracy: 0.8036\n",
            "Epoch 13/50\n",
            "9/9 - 0s - loss: 0.2876 - accuracy: 0.8796 - val_loss: 0.4006 - val_accuracy: 0.8109\n",
            "Epoch 14/50\n",
            "9/9 - 0s - loss: 0.2725 - accuracy: 0.8796 - val_loss: 0.3905 - val_accuracy: 0.8218\n",
            "Epoch 15/50\n",
            "9/9 - 0s - loss: 0.2580 - accuracy: 0.8832 - val_loss: 0.3836 - val_accuracy: 0.8218\n",
            "Epoch 16/50\n",
            "9/9 - 0s - loss: 0.2444 - accuracy: 0.8905 - val_loss: 0.3734 - val_accuracy: 0.8255\n",
            "Epoch 17/50\n",
            "9/9 - 0s - loss: 0.2325 - accuracy: 0.8942 - val_loss: 0.3649 - val_accuracy: 0.8255\n",
            "Epoch 18/50\n",
            "9/9 - 0s - loss: 0.2211 - accuracy: 0.9051 - val_loss: 0.3593 - val_accuracy: 0.8291\n",
            "Epoch 19/50\n",
            "9/9 - 0s - loss: 0.2114 - accuracy: 0.9088 - val_loss: 0.3545 - val_accuracy: 0.8327\n",
            "Epoch 20/50\n",
            "9/9 - 0s - loss: 0.2022 - accuracy: 0.9124 - val_loss: 0.3492 - val_accuracy: 0.8400\n",
            "Epoch 21/50\n",
            "9/9 - 0s - loss: 0.1946 - accuracy: 0.9234 - val_loss: 0.3466 - val_accuracy: 0.8436\n",
            "Epoch 22/50\n",
            "9/9 - 0s - loss: 0.1873 - accuracy: 0.9307 - val_loss: 0.3428 - val_accuracy: 0.8473\n",
            "Epoch 23/50\n",
            "9/9 - 0s - loss: 0.1794 - accuracy: 0.9307 - val_loss: 0.3388 - val_accuracy: 0.8473\n",
            "Epoch 24/50\n",
            "9/9 - 0s - loss: 0.1728 - accuracy: 0.9307 - val_loss: 0.3357 - val_accuracy: 0.8509\n",
            "Epoch 25/50\n",
            "9/9 - 0s - loss: 0.1663 - accuracy: 0.9270 - val_loss: 0.3333 - val_accuracy: 0.8509\n",
            "Epoch 26/50\n",
            "9/9 - 0s - loss: 0.1605 - accuracy: 0.9270 - val_loss: 0.3300 - val_accuracy: 0.8618\n",
            "Epoch 27/50\n",
            "9/9 - 0s - loss: 0.1548 - accuracy: 0.9453 - val_loss: 0.3287 - val_accuracy: 0.8582\n",
            "Epoch 28/50\n",
            "9/9 - 0s - loss: 0.1494 - accuracy: 0.9453 - val_loss: 0.3267 - val_accuracy: 0.8582\n",
            "Epoch 29/50\n",
            "9/9 - 0s - loss: 0.1442 - accuracy: 0.9380 - val_loss: 0.3243 - val_accuracy: 0.8582\n",
            "Epoch 30/50\n",
            "9/9 - 0s - loss: 0.1400 - accuracy: 0.9380 - val_loss: 0.3223 - val_accuracy: 0.8582\n",
            "Epoch 31/50\n",
            "9/9 - 0s - loss: 0.1357 - accuracy: 0.9526 - val_loss: 0.3205 - val_accuracy: 0.8618\n",
            "Epoch 32/50\n",
            "9/9 - 0s - loss: 0.1317 - accuracy: 0.9526 - val_loss: 0.3187 - val_accuracy: 0.8655\n",
            "Epoch 33/50\n",
            "9/9 - 0s - loss: 0.1272 - accuracy: 0.9526 - val_loss: 0.3177 - val_accuracy: 0.8691\n",
            "Epoch 34/50\n",
            "9/9 - 0s - loss: 0.1231 - accuracy: 0.9526 - val_loss: 0.3156 - val_accuracy: 0.8727\n",
            "Epoch 35/50\n",
            "9/9 - 0s - loss: 0.1203 - accuracy: 0.9562 - val_loss: 0.3156 - val_accuracy: 0.8764\n",
            "Epoch 36/50\n",
            "9/9 - 0s - loss: 0.1153 - accuracy: 0.9599 - val_loss: 0.3145 - val_accuracy: 0.8764\n",
            "Epoch 37/50\n",
            "9/9 - 0s - loss: 0.1133 - accuracy: 0.9635 - val_loss: 0.3136 - val_accuracy: 0.8727\n",
            "Epoch 38/50\n",
            "9/9 - 0s - loss: 0.1100 - accuracy: 0.9635 - val_loss: 0.3135 - val_accuracy: 0.8727\n",
            "Epoch 39/50\n",
            "9/9 - 0s - loss: 0.1059 - accuracy: 0.9635 - val_loss: 0.3138 - val_accuracy: 0.8691\n",
            "Epoch 40/50\n",
            "9/9 - 0s - loss: 0.1027 - accuracy: 0.9672 - val_loss: 0.3134 - val_accuracy: 0.8655\n",
            "Epoch 41/50\n",
            "9/9 - 0s - loss: 0.0995 - accuracy: 0.9708 - val_loss: 0.3114 - val_accuracy: 0.8691\n",
            "Epoch 42/50\n",
            "9/9 - 0s - loss: 0.0979 - accuracy: 0.9672 - val_loss: 0.3109 - val_accuracy: 0.8727\n",
            "Epoch 43/50\n",
            "9/9 - 0s - loss: 0.0949 - accuracy: 0.9708 - val_loss: 0.3124 - val_accuracy: 0.8727\n",
            "Epoch 44/50\n",
            "9/9 - 0s - loss: 0.0930 - accuracy: 0.9672 - val_loss: 0.3110 - val_accuracy: 0.8764\n",
            "Epoch 45/50\n",
            "9/9 - 0s - loss: 0.0936 - accuracy: 0.9672 - val_loss: 0.3121 - val_accuracy: 0.8764\n",
            "Epoch 46/50\n",
            "9/9 - 0s - loss: 0.0870 - accuracy: 0.9745 - val_loss: 0.3116 - val_accuracy: 0.8800\n",
            "Epoch 47/50\n",
            "9/9 - 0s - loss: 0.0853 - accuracy: 0.9708 - val_loss: 0.3127 - val_accuracy: 0.8800\n",
            "Epoch 48/50\n",
            "9/9 - 0s - loss: 0.0825 - accuracy: 0.9745 - val_loss: 0.3113 - val_accuracy: 0.8800\n",
            "Epoch 49/50\n",
            "9/9 - 0s - loss: 0.0809 - accuracy: 0.9818 - val_loss: 0.3106 - val_accuracy: 0.8764\n",
            "Epoch 50/50\n",
            "9/9 - 0s - loss: 0.0790 - accuracy: 0.9781 - val_loss: 0.3127 - val_accuracy: 0.8764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rYkzjY0Jpn4",
        "outputId": "85c2a0fc-09f2-47a3-8ab9-f83d3422ae1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "tf.keras.utils.plot_model(nn, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw6xMQP-O5-X"
      },
      "source": [
        "###***Deep Learning Neural Netwrok Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-6Z3XUQsali",
        "outputId": "be4bb9a1-c1db-4908-b121-7b24d409c338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step - loss: 0.8089 - accuracy: 0.7978\n",
            "Loss: 0.8089192509651184, Accuracy: 0.7978141903877258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uQLqejXO5-Z"
      },
      "source": [
        "# # Evaluate the model using the test data\n",
        "# model_loss, FalseNegatives,FalsePositives, TrueNegatives, TruePositives, Precision, Recall = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "# print(f\"\"\"\\t  Loss: {model_loss},\n",
        "#           FalseNegatives: {FalseNegatives},\n",
        "#           FalsePositives: {FalsePositives},\n",
        "#           TrueNegatives: {TrueNegatives},\n",
        "#           TruePositives: {TruePositives},\n",
        "#           Precision: {Precision},\n",
        "#           Recall: {Recall},\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qdKZ89DiBfB",
        "outputId": "b059a491-c24a-4aea-920f-589b94c1267c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = nn.predict(X_test_scaled)\n",
        "adjusted_predictions = [(100 * x[0]) for x in predictions]\n",
        "adjusted_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.007918832125142217,\n",
              " 0.08450448513031006,\n",
              " 70.68836688995361,\n",
              " 0.22229552268981934,\n",
              " 0.18036067485809326,\n",
              " 99.54880475997925,\n",
              " 91.09059572219849,\n",
              " 36.04047894477844,\n",
              " 45.00427842140198,\n",
              " 4.874363541603088,\n",
              " 0.0017087011656258255,\n",
              " 2.123698592185974,\n",
              " 98.70395064353943,\n",
              " 18.76862943172455,\n",
              " 6.656262278556824,\n",
              " 0.0036223606002749875,\n",
              " 97.70236015319824,\n",
              " 96.16299867630005,\n",
              " 1.5012145042419434,\n",
              " 99.05567169189453,\n",
              " 43.29199492931366,\n",
              " 97.8837251663208,\n",
              " 94.23391819000244,\n",
              " 3.290984034538269,\n",
              " 92.71305203437805,\n",
              " 94.5466160774231,\n",
              " 99.7454047203064,\n",
              " 73.78293871879578,\n",
              " 41.23391509056091,\n",
              " 0.07576942443847656,\n",
              " 0.01596510410308838,\n",
              " 99.94702339172363,\n",
              " 0.017392635345458984,\n",
              " 22.847917675971985,\n",
              " 63.858628273010254,\n",
              " 0.0065496962633915246,\n",
              " 99.95293617248535,\n",
              " 99.83625411987305,\n",
              " 99.92221593856812,\n",
              " 0.17339885234832764,\n",
              " 0.10298192501068115,\n",
              " 9.132370352745056,\n",
              " 25.714382529258728,\n",
              " 35.034966468811035,\n",
              " 1.2539595365524292,\n",
              " 99.88113641738892,\n",
              " 0.1124262809753418,\n",
              " 28.150570392608643,\n",
              " 78.50817441940308,\n",
              " 99.86158609390259,\n",
              " 0.10676085948944092,\n",
              " 92.12512969970703,\n",
              " 99.6016263961792,\n",
              " 5.0851136445999146,\n",
              " 99.88242983818054,\n",
              " 0.02664327621459961,\n",
              " 67.84061789512634,\n",
              " 0.2909034490585327,\n",
              " 99.86376166343689,\n",
              " 99.07933473587036,\n",
              " 99.48939085006714,\n",
              " 0.006610144191654399,\n",
              " 93.88449192047119,\n",
              " 0.49526989459991455,\n",
              " 98.43543767929077,\n",
              " 19.39544379711151,\n",
              " 64.2143964767456,\n",
              " 97.97607660293579,\n",
              " 96.71005010604858,\n",
              " 96.73970937728882,\n",
              " 0.09933710098266602,\n",
              " 99.91723299026489,\n",
              " 0.0013817176295560785,\n",
              " 95.9675669670105,\n",
              " 0.03151595592498779,\n",
              " 96.74051403999329,\n",
              " 0.9739130735397339,\n",
              " 97.53244519233704,\n",
              " 90.65929651260376,\n",
              " 99.40608739852905,\n",
              " 4.938638210296631,\n",
              " 0.005085545126348734,\n",
              " 0.6576091051101685,\n",
              " 99.69782829284668,\n",
              " 99.56534504890442,\n",
              " 0.07594823837280273,\n",
              " 0.006762525299564004,\n",
              " 0.04793107509613037,\n",
              " 0.15794336795806885,\n",
              " 99.99608993530273,\n",
              " 99.42442178726196,\n",
              " 0.0003349843609612435,\n",
              " 0.0858604907989502,\n",
              " 73.20482730865479,\n",
              " 36.37911379337311,\n",
              " 2.0006388425827026,\n",
              " 99.73647594451904,\n",
              " 0.4620105028152466,\n",
              " 99.95017647743225,\n",
              " 99.45876598358154,\n",
              " 0.0008347080438397825,\n",
              " 96.68842554092407,\n",
              " 94.07986998558044,\n",
              " 58.584439754486084,\n",
              " 99.84381198883057,\n",
              " 80.8415949344635,\n",
              " 88.9307975769043,\n",
              " 11.836332082748413,\n",
              " 96.66297435760498,\n",
              " 0.18878281116485596,\n",
              " 8.904388546943665,\n",
              " 0.005035354843130335,\n",
              " 98.69987368583679,\n",
              " 8.11474621295929,\n",
              " 99.74383115768433,\n",
              " 0.9161859750747681,\n",
              " 11.397483944892883,\n",
              " 98.94818067550659,\n",
              " 0.0014763002582185436,\n",
              " 1.1170268058776855,\n",
              " 0.7912516593933105,\n",
              " 86.09951734542847,\n",
              " 90.55204391479492,\n",
              " 0.07029175758361816,\n",
              " 99.9762773513794,\n",
              " 0.012955069541931152,\n",
              " 19.199585914611816,\n",
              " 0.004653430369216949,\n",
              " 13.949891924858093,\n",
              " 94.48422193527222,\n",
              " 96.08148336410522,\n",
              " 99.79336261749268,\n",
              " 99.93098974227905,\n",
              " 0.011455841740826145,\n",
              " 99.8832106590271,\n",
              " 68.69999170303345,\n",
              " 99.17042255401611,\n",
              " 0.026303529739379883,\n",
              " 43.57801377773285,\n",
              " 0.009840495476964861,\n",
              " 25.16028881072998,\n",
              " 99.55413341522217,\n",
              " 99.21912550926208,\n",
              " 0.0007690599886700511,\n",
              " 17.368102073669434,\n",
              " 98.32463264465332,\n",
              " 99.50476884841919,\n",
              " 51.90557241439819,\n",
              " 84.72675085067749,\n",
              " 0.2107471227645874,\n",
              " 95.69275379180908,\n",
              " 0.26952624320983887,\n",
              " 0.00041708085518621374,\n",
              " 6.914988160133362,\n",
              " 0.00270982418442145,\n",
              " 0.015020370483398438,\n",
              " 4.281148314476013,\n",
              " 0.06177723407745361,\n",
              " 0.20809471607208252,\n",
              " 17.762184143066406,\n",
              " 2.2182226181030273,\n",
              " 77.56794691085815,\n",
              " 86.28121018409729,\n",
              " 1.81865394115448,\n",
              " 99.92578029632568,\n",
              " 99.40746426582336,\n",
              " 19.505098462104797,\n",
              " 43.62117052078247,\n",
              " 45.276689529418945,\n",
              " 0.011065844591939822,\n",
              " 82.99243450164795,\n",
              " 1.724526286125183,\n",
              " 99.7200608253479,\n",
              " 0.042691826820373535,\n",
              " 92.26099252700806,\n",
              " 0.4932284355163574,\n",
              " 0.00020195350316498661,\n",
              " 99.88082647323608,\n",
              " 29.486405849456787,\n",
              " 1.0727494955062866,\n",
              " 99.64048266410828,\n",
              " 92.25943088531494,\n",
              " 0.013116002082824707]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_6G4L1TO5-d"
      },
      "source": [
        "### ***Random Forest Classifier Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stnp4Ep3O5-d",
        "outputId": "4968e713-c696-4c0e-f8cc-8f5d48c06e8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a random forest classifier.\n",
        "rf_model = RandomForestClassifier(n_estimators=256, random_state=32)\n",
        "\n",
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Random forest predictive accuracy: 1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_pG1RM0JDwr",
        "outputId": "c8226809-35dc-4493-cb47-f711a5773025",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 75   0]\n",
            " [  0 108]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkIB9d0lslob"
      },
      "source": [
        "### ***Logistic Regression Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baU-hliossZ1"
      },
      "source": [
        "# Create a Logistic Regression Model\n",
        "classifier = LogisticRegression(solver='lbfgs',\n",
        "                                max_iter=200,\n",
        "                                random_state=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAiKwCp4suyg",
        "outputId": "6f483c3e-1384-4003-c50e-605f139ce0fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit (train) or model using the training data\n",
        "classifier.fit(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiOZe0KQtHm1",
        "outputId": "6d3f4317-2463-4743-e98a-a16450a9513c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
        "results.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Prediction  Actual\n",
              "0            0       0\n",
              "1            0       0\n",
              "2            1       1\n",
              "3            0       0\n",
              "4            0       0\n",
              "5            1       1\n",
              "6            1       1\n",
              "7            1       1\n",
              "8            1       1\n",
              "9            1       1\n",
              "10           0       0\n",
              "11           0       0\n",
              "12           1       1\n",
              "13           0       0\n",
              "14           0       0\n",
              "15           0       0\n",
              "16           1       0\n",
              "17           1       1\n",
              "18           1       1\n",
              "19           1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUKD1EJUtLhy",
        "outputId": "650ed6c7-96e1-4d79-d5a6-641507915757",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.907103825136612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp_KzZnUJQg_",
        "outputId": "6f26414a-7620-4e31-f235-c837b9d8fb27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[68  7]\n",
            " [10 98]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QIUMu-a8ZDw"
      },
      "source": [
        "## ***Wine & Weather - Drop All soil columns***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl3c8lXV8ZDx"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = White_Soil_ML_df[\"quality\"].values\n",
        "X = White_Soil_ML_df.drop([\"quality\", \"is_primeurs\", \"journalist_count\", \"confidence_index_A\",\"confidence_index_A+\", \"confidence_index_B\", \"confidence_index_B+\",\"confidence_index_C\", \"confidence_index_C+\",'avgPrcpFebruary',\n",
        " 'bdod_0-100cm',\n",
        " 'bdod_100-200cm',\n",
        " 'cec_0-100cm',\n",
        " 'cec_100-200cm',\n",
        " 'cfvo_0-100cm',\n",
        " 'cfvo_100-200cm',\n",
        " 'clay_0-100cm',\n",
        " 'clay_100-200cm',\n",
        " 'nitrogen_0-100cm',\n",
        " 'nitrogen_100-200cm',\n",
        " 'ocd_0-100cm',\n",
        " 'ocd_100-200cm',\n",
        " 'ocs_0-30cm',\n",
        " 'phh2o_0-100cm',\n",
        " 'phh2o_100-200cm',\n",
        " 'sand_0-100cm',\n",
        " 'sand_100-200cm',\n",
        " 'silt_0-100cm',\n",
        " 'silt_100-200cm',\n",
        " 'soc_0-100cm',\n",
        " 'soc_100-200cm',],1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgW_GLNG8ZD1"
      },
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X)\n",
        "X_scaled = X_scaler.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naWidjg3K2Be"
      },
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, random_state=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDkDyjKx8ZD4"
      },
      "source": [
        "###***Deep Learning Neural Netwrok for training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbMo7m578ZD4",
        "outputId": "a850f4d9-0da4-4715-cc48-63afaaccd04b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[-1])\n",
        "hidden_nodes_layer1 =  24\n",
        "hidden_nodes_layer2 = 12\n",
        "\n",
        "# metrics = [\n",
        "#     tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "#     tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "#     tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "#     tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "#     tf.keras.metrics.Precision(name=\"precision\"),\n",
        "#     tf.keras.metrics.Recall(name=\"recall\"),\n",
        "# ]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.7961 - accuracy: 0.4635 - val_loss: 0.7348 - val_accuracy: 0.4545\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7034 - accuracy: 0.5292 - val_loss: 0.6777 - val_accuracy: 0.5055\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.5912 - val_loss: 0.6409 - val_accuracy: 0.5564\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.6569 - val_loss: 0.6113 - val_accuracy: 0.6255\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.7263 - val_loss: 0.5861 - val_accuracy: 0.6764\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7701 - val_loss: 0.5635 - val_accuracy: 0.7164\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7956 - val_loss: 0.5426 - val_accuracy: 0.7455\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.8394 - val_loss: 0.5221 - val_accuracy: 0.7491\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.8650 - val_loss: 0.5036 - val_accuracy: 0.7636\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8723 - val_loss: 0.4849 - val_accuracy: 0.7855\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8905 - val_loss: 0.4697 - val_accuracy: 0.7964\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8905 - val_loss: 0.4570 - val_accuracy: 0.8036\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8942 - val_loss: 0.4418 - val_accuracy: 0.8073\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8978 - val_loss: 0.4299 - val_accuracy: 0.8182\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.9124 - val_loss: 0.4188 - val_accuracy: 0.8218\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2795 - accuracy: 0.9124 - val_loss: 0.4084 - val_accuracy: 0.8218\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2632 - accuracy: 0.9088 - val_loss: 0.3970 - val_accuracy: 0.8255\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2491 - accuracy: 0.9088 - val_loss: 0.3863 - val_accuracy: 0.8436\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2344 - accuracy: 0.9124 - val_loss: 0.3815 - val_accuracy: 0.8545\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2217 - accuracy: 0.9234 - val_loss: 0.3740 - val_accuracy: 0.8509\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2096 - accuracy: 0.9270 - val_loss: 0.3692 - val_accuracy: 0.8618\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1979 - accuracy: 0.9307 - val_loss: 0.3633 - val_accuracy: 0.8582\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.9380 - val_loss: 0.3621 - val_accuracy: 0.8618\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1766 - accuracy: 0.9380 - val_loss: 0.3607 - val_accuracy: 0.8618\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.9416 - val_loss: 0.3577 - val_accuracy: 0.8655\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1548 - accuracy: 0.9489 - val_loss: 0.3517 - val_accuracy: 0.8618\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1475 - accuracy: 0.9489 - val_loss: 0.3512 - val_accuracy: 0.8582\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1383 - accuracy: 0.9489 - val_loss: 0.3523 - val_accuracy: 0.8691\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9562 - val_loss: 0.3576 - val_accuracy: 0.8873\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.9635 - val_loss: 0.3499 - val_accuracy: 0.8800\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.9599 - val_loss: 0.3512 - val_accuracy: 0.8691\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1135 - accuracy: 0.9635 - val_loss: 0.3514 - val_accuracy: 0.8727\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1087 - accuracy: 0.9781 - val_loss: 0.3460 - val_accuracy: 0.8764\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9818 - val_loss: 0.3486 - val_accuracy: 0.8764\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.9818 - val_loss: 0.3531 - val_accuracy: 0.8727\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 0.9854 - val_loss: 0.3523 - val_accuracy: 0.8727\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9818 - val_loss: 0.3505 - val_accuracy: 0.8727\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0861 - accuracy: 0.9891 - val_loss: 0.3483 - val_accuracy: 0.8655\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9891 - val_loss: 0.3511 - val_accuracy: 0.8655\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0783 - accuracy: 0.9927 - val_loss: 0.3531 - val_accuracy: 0.8655\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9927 - val_loss: 0.3500 - val_accuracy: 0.8655\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9891 - val_loss: 0.3518 - val_accuracy: 0.8655\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9964 - val_loss: 0.3594 - val_accuracy: 0.8655\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0672 - accuracy: 0.9964 - val_loss: 0.3568 - val_accuracy: 0.8655\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0642 - accuracy: 0.9964 - val_loss: 0.3547 - val_accuracy: 0.8655\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.9964 - val_loss: 0.3552 - val_accuracy: 0.8655\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0594 - accuracy: 0.9964 - val_loss: 0.3549 - val_accuracy: 0.8655\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0568 - accuracy: 0.9964 - val_loss: 0.3631 - val_accuracy: 0.8655\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.9964 - val_loss: 0.3596 - val_accuracy: 0.8655\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9964 - val_loss: 0.3626 - val_accuracy: 0.8655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGyzl5ZaMB8L",
        "outputId": "47d045e0-4812-49a3-9e88-94d1af4f566f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "tf.keras.utils.plot_model(nn, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEcRZGXM8ZD8"
      },
      "source": [
        "###***Deep Learning Neural Netwrok Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2_bXNR4tFKY",
        "outputId": "2b8110c4-e9d4-4503-a833-9b896141353d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 - 0s - loss: 0.6880 - accuracy: 0.7596\n",
            "Loss: 0.6880285739898682, Accuracy: 0.7595628499984741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRFv96XA8ZD8"
      },
      "source": [
        "# # Evaluate the model using the test data\n",
        "# model_loss, FalseNegatives,FalsePositives, TrueNegatives, TruePositives, Precision, Recall = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "# print(f\"\"\"\\t  Loss: {model_loss},\n",
        "#           FalseNegatives: {FalseNegatives},\n",
        "#           FalsePositives: {FalsePositives},\n",
        "#           TrueNegatives: {TrueNegatives},\n",
        "#           TruePositives: {TruePositives},\n",
        "#           Precision: {Precision},\n",
        "#           Recall: {Recall},\"\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNJMznkl8ZEB",
        "outputId": "2f5a8fa0-7c76-4786-c014-4520f66953dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = nn.predict(X_test_scaled)\n",
        "adjusted_predictions = [(100 * x[0]) for x in predictions]\n",
        "adjusted_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.043904781341552734,\n",
              " 0.029334425926208496,\n",
              " 91.6430413722992,\n",
              " 0.003161812128382735,\n",
              " 0.0334620475769043,\n",
              " 99.78984594345093,\n",
              " 94.04258131980896,\n",
              " 46.75445556640625,\n",
              " 84.39652919769287,\n",
              " 2.032110095024109,\n",
              " 0.012883543968200684,\n",
              " 0.1118093729019165,\n",
              " 91.9232726097107,\n",
              " 39.37395215034485,\n",
              " 7.976379990577698,\n",
              " 0.012156269076513126,\n",
              " 81.21455907821655,\n",
              " 93.27882528305054,\n",
              " 0.7442116737365723,\n",
              " 95.82953453063965,\n",
              " 38.24494779109955,\n",
              " 97.90939092636108,\n",
              " 26.9217312335968,\n",
              " 0.2801179885864258,\n",
              " 98.26517105102539,\n",
              " 51.99807286262512,\n",
              " 99.94330406188965,\n",
              " 93.63019466400146,\n",
              " 3.011256456375122,\n",
              " 0.033921003341674805,\n",
              " 0.022599101066589355,\n",
              " 99.78868365287781,\n",
              " 0.20166337490081787,\n",
              " 4.039484262466431,\n",
              " 31.582432985305786,\n",
              " 0.0073143557528965175,\n",
              " 99.85768795013428,\n",
              " 99.8797059059143,\n",
              " 99.96860027313232,\n",
              " 0.1494288444519043,\n",
              " 0.07146298885345459,\n",
              " 0.0002956421212729765,\n",
              " 17.016971111297607,\n",
              " 17.841094732284546,\n",
              " 0.6828397512435913,\n",
              " 99.24421906471252,\n",
              " 30.469143390655518,\n",
              " 33.888885378837585,\n",
              " 16.284269094467163,\n",
              " 99.91817474365234,\n",
              " 11.45850121974945,\n",
              " 95.94495892524719,\n",
              " 99.74297285079956,\n",
              " 5.734741687774658,\n",
              " 99.7602641582489,\n",
              " 4.285866022109985,\n",
              " 93.31036806106567,\n",
              " 1.1154413223266602,\n",
              " 99.97789263725281,\n",
              " 99.2903470993042,\n",
              " 72.79232144355774,\n",
              " 0.3775089979171753,\n",
              " 99.66436624526978,\n",
              " 0.018152594566345215,\n",
              " 91.69698357582092,\n",
              " 53.85777950286865,\n",
              " 39.1124963760376,\n",
              " 94.48695182800293,\n",
              " 99.50054287910461,\n",
              " 12.278690934181213,\n",
              " 58.18149447441101,\n",
              " 99.94031190872192,\n",
              " 0.053372979164123535,\n",
              " 99.94596242904663,\n",
              " 4.500734806060791,\n",
              " 96.36948704719543,\n",
              " 0.04213154315948486,\n",
              " 99.87591505050659,\n",
              " 98.91349077224731,\n",
              " 99.24478530883789,\n",
              " 53.943562507629395,\n",
              " 0.026589632034301758,\n",
              " 0.3475666046142578,\n",
              " 99.16740655899048,\n",
              " 99.80279207229614,\n",
              " 0.002103537190123461,\n",
              " 0.12127161026000977,\n",
              " 0.2594679594039917,\n",
              " 0.1530379056930542,\n",
              " 90.77449440956116,\n",
              " 98.39043021202087,\n",
              " 0.07439255714416504,\n",
              " 5.4804456794954604e-05,\n",
              " 94.33335065841675,\n",
              " 34.66934561729431,\n",
              " 0.08289515972137451,\n",
              " 99.0531325340271,\n",
              " 0.016289949417114258,\n",
              " 99.91816282272339,\n",
              " 99.7663140296936,\n",
              " 0.03421902656555176,\n",
              " 48.68139922618866,\n",
              " 97.64280915260315,\n",
              " 62.33222484588623,\n",
              " 98.76106381416321,\n",
              " 95.07579803466797,\n",
              " 78.45723628997803,\n",
              " 7.791531085968018,\n",
              " 96.31116390228271,\n",
              " 0.9817391633987427,\n",
              " 0.5082190036773682,\n",
              " 0.002276293162140064,\n",
              " 99.39804077148438,\n",
              " 0.21387338638305664,\n",
              " 99.89675283432007,\n",
              " 0.9487837553024292,\n",
              " 1.8876373767852783,\n",
              " 92.29245185852051,\n",
              " 0.004937571793561801,\n",
              " 9.164583683013916,\n",
              " 97.87243604660034,\n",
              " 79.49439287185669,\n",
              " 39.871758222579956,\n",
              " 17.632895708084106,\n",
              " 99.9794602394104,\n",
              " 0.8658915758132935,\n",
              " 11.152231693267822,\n",
              " 0.0356137752532959,\n",
              " 0.1917511224746704,\n",
              " 89.47474956512451,\n",
              " 99.61246252059937,\n",
              " 99.77204203605652,\n",
              " 99.72971677780151,\n",
              " 0.046893954277038574,\n",
              " 99.85737800598145,\n",
              " 74.93072152137756,\n",
              " 99.42036867141724,\n",
              " 0.02263188362121582,\n",
              " 81.71913027763367,\n",
              " 0.013935565948486328,\n",
              " 1.7139315605163574,\n",
              " 97.4811315536499,\n",
              " 99.34441447257996,\n",
              " 0.08495748043060303,\n",
              " 8.169570565223694,\n",
              " 98.09772968292236,\n",
              " 98.41248989105225,\n",
              " 87.51879930496216,\n",
              " 98.8656997680664,\n",
              " 0.0007511050625907956,\n",
              " 99.87267255783081,\n",
              " 3.7271350622177124,\n",
              " 0.011697484296746552,\n",
              " 4.8697590827941895,\n",
              " 0.011919201642740518,\n",
              " 36.32674813270569,\n",
              " 9.546637535095215,\n",
              " 0.02219080924987793,\n",
              " 0.18311738967895508,\n",
              " 7.82618522644043,\n",
              " 0.2578228712081909,\n",
              " 64.64882493019104,\n",
              " 60.86743474006653,\n",
              " 5.189329385757446,\n",
              " 99.94369745254517,\n",
              " 99.12556409835815,\n",
              " 19.54098343849182,\n",
              " 24.06509816646576,\n",
              " 53.6446213722229,\n",
              " 0.13975203037261963,\n",
              " 82.76145458221436,\n",
              " 1.5666216611862183,\n",
              " 99.84069466590881,\n",
              " 0.04203617572784424,\n",
              " 8.354845643043518,\n",
              " 0.3492683172225952,\n",
              " 0.0013439585018204525,\n",
              " 99.71599578857422,\n",
              " 1.8759667873382568,\n",
              " 0.4014521837234497,\n",
              " 99.60731863975525,\n",
              " 96.89821600914001,\n",
              " 0.007130120502552018]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B21n32Y_8ZEI"
      },
      "source": [
        "### ***Random Forest Classifier Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbi4Nt6S8ZEI",
        "outputId": "16470556-ad80-424b-d0ca-d53355c863bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a random forest classifier.\n",
        "rf_model = RandomForestClassifier(n_estimators=256, random_state=32)\n",
        "\n",
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Random forest predictive accuracy: 0.956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ICcqS8oLBMd",
        "outputId": "511c052e-3122-4407-ad70-9170b861f13f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 72   3]\n",
            " [  5 103]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NPfSMqy8ZEO"
      },
      "source": [
        "### ***Logistic Regression Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkpcmGoI8ZEP"
      },
      "source": [
        "# Create a Logistic Regression Model\n",
        "classifier = LogisticRegression(solver='lbfgs',\n",
        "                                max_iter=200,\n",
        "                                random_state=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh5RRLdU8ZEQ",
        "outputId": "26289a05-ff6e-4646-b247-80977020d17b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit (train) or model using the training data\n",
        "classifier.fit(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBrQHR2e8ZER",
        "outputId": "1cff3c6a-eecd-4d3a-8485-cbbcd26b6648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
        "results.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Prediction  Actual\n",
              "0            0       0\n",
              "1            0       0\n",
              "2            1       1\n",
              "3            0       0\n",
              "4            0       0\n",
              "5            1       1\n",
              "6            1       1\n",
              "7            1       1\n",
              "8            1       1\n",
              "9            1       1\n",
              "10           0       0\n",
              "11           0       0\n",
              "12           1       1\n",
              "13           0       0\n",
              "14           0       0\n",
              "15           0       0\n",
              "16           1       0\n",
              "17           1       1\n",
              "18           1       1\n",
              "19           1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXcYvmte8ZET",
        "outputId": "41291f9a-a8d9-4e33-d6d3-41eb38626caa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.907103825136612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IgWEnV9LFQH",
        "outputId": "e07aa08e-736b-4b92-f10f-5005426c32cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[68  7]\n",
            " [10 98]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnWP0hsq8zrQ"
      },
      "source": [
        "## ***Wine & Soil - Drop All weather columns***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zjTIfIy8zrR"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = White_Soil_ML_df[\"quality\"].values\n",
        "X = White_Soil_ML_df.drop([\"quality\",\"is_primeurs\", \"journalist_count\", \"confidence_index_A\",\"confidence_index_A+\", \"confidence_index_B\", \"confidence_index_B+\",\"confidence_index_C\", \"confidence_index_C+\",'avgPrcpFebruary',\n",
        " 'avgTempFebruary',\n",
        " 'avgPrcpMarch',\n",
        " 'avgTempMarch',\n",
        " 'avgPrcpApril',\n",
        " 'avgTempApril',\n",
        " 'avgPrcpMay',\n",
        " 'avgTempMay',\n",
        " 'avgPrcpJune',\n",
        " 'avgTempJune',\n",
        " 'avgPrcpJuly',\n",
        " 'avgTempJuly',\n",
        " 'avgPrcpAugust',\n",
        " 'avgTempAugust',\n",
        " 'avgPrcpSeptember',\n",
        " 'avgTempSeptember',\n",
        " 'avgPrcpOctober',\n",
        " 'avgTempOctober'],1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvoFDc1r8zrV"
      },
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X)\n",
        "X_scaled = X_scaler.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZBWe_JuLLVK"
      },
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, random_state=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLZR5S938zrY"
      },
      "source": [
        "###***Deep Learning Neural Netwrok for training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GH0R3gB8zrZ",
        "outputId": "a75ebc1c-0538-48f4-a496-b02aec32916f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[-1])\n",
        "hidden_nodes_layer1 =  24\n",
        "hidden_nodes_layer2 = 12\n",
        "\n",
        "# metrics = [\n",
        "#     tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "#     tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "#     tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "#     tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "#     tf.keras.metrics.Precision(name=\"precision\"),\n",
        "#     tf.keras.metrics.Recall(name=\"recall\"),\n",
        "# ]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 0.8303 - accuracy: 0.5292 - val_loss: 0.8270 - val_accuracy: 0.5709\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.6022 - val_loss: 0.7633 - val_accuracy: 0.6000\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6216 - accuracy: 0.6861 - val_loss: 0.7168 - val_accuracy: 0.6364\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.7591 - val_loss: 0.6793 - val_accuracy: 0.6618\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.8066 - val_loss: 0.6466 - val_accuracy: 0.6800\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.8285 - val_loss: 0.6199 - val_accuracy: 0.7127\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.8394 - val_loss: 0.5967 - val_accuracy: 0.7273\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8467 - val_loss: 0.5783 - val_accuracy: 0.7491\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8540 - val_loss: 0.5596 - val_accuracy: 0.7564\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8540 - val_loss: 0.5399 - val_accuracy: 0.7673\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3564 - accuracy: 0.8759 - val_loss: 0.5233 - val_accuracy: 0.7891\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8905 - val_loss: 0.5057 - val_accuracy: 0.7964\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3177 - accuracy: 0.8905 - val_loss: 0.4929 - val_accuracy: 0.7964\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3005 - accuracy: 0.8978 - val_loss: 0.4766 - val_accuracy: 0.8000\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2823 - accuracy: 0.9015 - val_loss: 0.4647 - val_accuracy: 0.8036\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2670 - accuracy: 0.9088 - val_loss: 0.4520 - val_accuracy: 0.8145\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2523 - accuracy: 0.9197 - val_loss: 0.4436 - val_accuracy: 0.8145\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2385 - accuracy: 0.9051 - val_loss: 0.4357 - val_accuracy: 0.8036\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2259 - accuracy: 0.8978 - val_loss: 0.4259 - val_accuracy: 0.8109\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2146 - accuracy: 0.9197 - val_loss: 0.4189 - val_accuracy: 0.8218\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2031 - accuracy: 0.9270 - val_loss: 0.4122 - val_accuracy: 0.8291\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1949 - accuracy: 0.9343 - val_loss: 0.4078 - val_accuracy: 0.8327\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.9380 - val_loss: 0.4016 - val_accuracy: 0.8291\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1758 - accuracy: 0.9380 - val_loss: 0.3997 - val_accuracy: 0.8291\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1675 - accuracy: 0.9343 - val_loss: 0.3968 - val_accuracy: 0.8255\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.9526 - val_loss: 0.3938 - val_accuracy: 0.8291\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1537 - accuracy: 0.9562 - val_loss: 0.3920 - val_accuracy: 0.8364\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1478 - accuracy: 0.9526 - val_loss: 0.3861 - val_accuracy: 0.8364\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1414 - accuracy: 0.9635 - val_loss: 0.3856 - val_accuracy: 0.8436\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1359 - accuracy: 0.9562 - val_loss: 0.3863 - val_accuracy: 0.8436\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1323 - accuracy: 0.9526 - val_loss: 0.3823 - val_accuracy: 0.8473\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9562 - val_loss: 0.3835 - val_accuracy: 0.8473\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1222 - accuracy: 0.9599 - val_loss: 0.3843 - val_accuracy: 0.8436\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1187 - accuracy: 0.9635 - val_loss: 0.3831 - val_accuracy: 0.8473\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.9635 - val_loss: 0.3841 - val_accuracy: 0.8509\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1112 - accuracy: 0.9599 - val_loss: 0.3839 - val_accuracy: 0.8545\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1067 - accuracy: 0.9635 - val_loss: 0.3837 - val_accuracy: 0.8618\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9635 - val_loss: 0.3820 - val_accuracy: 0.8691\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0987 - accuracy: 0.9635 - val_loss: 0.3892 - val_accuracy: 0.8545\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9599 - val_loss: 0.3888 - val_accuracy: 0.8655\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9599 - val_loss: 0.3942 - val_accuracy: 0.8509\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.9672 - val_loss: 0.3884 - val_accuracy: 0.8691\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0900 - accuracy: 0.9672 - val_loss: 0.3906 - val_accuracy: 0.8655\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9708 - val_loss: 0.3892 - val_accuracy: 0.8691\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9708 - val_loss: 0.3948 - val_accuracy: 0.8655\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9672 - val_loss: 0.3943 - val_accuracy: 0.8691\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9745 - val_loss: 0.3940 - val_accuracy: 0.8655\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0772 - accuracy: 0.9672 - val_loss: 0.3960 - val_accuracy: 0.8655\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9672 - val_loss: 0.3966 - val_accuracy: 0.8655\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9708 - val_loss: 0.3983 - val_accuracy: 0.8655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ag1d7XoMJF9",
        "outputId": "88a1c694-87ce-40ba-bc35-407130fc934c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "tf.keras.utils.plot_model(nn, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-Cju5lo8zrb"
      },
      "source": [
        "###***Deep Learning Neural Network Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZlaGKpUtLqL",
        "outputId": "f4aa029a-a2d7-4503-982e-3fe55ed9eae7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 - 0s - loss: 0.5856 - accuracy: 0.8087\n",
            "Loss: 0.5856299996376038, Accuracy: 0.8087431788444519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NTSC0Kk8zrc"
      },
      "source": [
        "# # Evaluate the model using the test data\n",
        "# model_loss, FalseNegatives,FalsePositives, TrueNegatives, TruePositives, Precision, Recall = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "# print(f\"\"\"\\t  Loss: {model_loss},\n",
        "#           FalseNegatives: {FalseNegatives},\n",
        "#           FalsePositives: {FalsePositives},\n",
        "#           TrueNegatives: {TrueNegatives},\n",
        "#           TruePositives: {TruePositives},\n",
        "#           Precision: {Precision},\n",
        "#           Recall: {Recall},\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFA_Xo9k8zrg",
        "outputId": "9f03c4b6-97cf-4998-cf7e-6ae894b9c4b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = nn.predict(X_test_scaled)\n",
        "adjusted_predictions = [(100 * x[0]) for x in predictions]\n",
        "adjusted_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1314103603363037,\n",
              " 0.25190114974975586,\n",
              " 71.5301513671875,\n",
              " 0.13625621795654297,\n",
              " 0.27295947074890137,\n",
              " 99.99994039535522,\n",
              " 97.31862545013428,\n",
              " 99.06564354896545,\n",
              " 47.098174691200256,\n",
              " 6.3161700963974,\n",
              " 0.13271570205688477,\n",
              " 0.3419041633605957,\n",
              " 99.8946487903595,\n",
              " 42.031604051589966,\n",
              " 2.3190855979919434,\n",
              " 0.02879202365875244,\n",
              " 95.90299129486084,\n",
              " 95.19756436347961,\n",
              " 4.064315557479858,\n",
              " 99.94652271270752,\n",
              " 34.51756834983826,\n",
              " 96.73072099685669,\n",
              " 99.02543425559998,\n",
              " 1.1518746614456177,\n",
              " 93.73583197593689,\n",
              " 66.52417182922363,\n",
              " 99.97307062149048,\n",
              " 75.2903938293457,\n",
              " 45.51430642604828,\n",
              " 0.29192566871643066,\n",
              " 0.027051568031311035,\n",
              " 99.99842047691345,\n",
              " 0.45310258865356445,\n",
              " 29.487749934196472,\n",
              " 74.55239295959473,\n",
              " 0.004748936771648005,\n",
              " 99.75273609161377,\n",
              " 99.98728036880493,\n",
              " 99.99880790710449,\n",
              " 0.35108327865600586,\n",
              " 99.82049465179443,\n",
              " 0.3305494785308838,\n",
              " 98.36901426315308,\n",
              " 95.92573642730713,\n",
              " 3.6031603813171387,\n",
              " 99.42547082901001,\n",
              " 0.057625770568847656,\n",
              " 46.44273817539215,\n",
              " 86.15636825561523,\n",
              " 99.9410629272461,\n",
              " 1.8330812454223633,\n",
              " 99.84666109085083,\n",
              " 99.79416131973267,\n",
              " 7.90882408618927,\n",
              " 99.30955767631531,\n",
              " 0.1351475715637207,\n",
              " 4.506388306617737,\n",
              " 4.238271713256836,\n",
              " 99.99009370803833,\n",
              " 99.44454431533813,\n",
              " 99.9559223651886,\n",
              " 5.776453018188477,\n",
              " 87.60877847671509,\n",
              " 0.2811312675476074,\n",
              " 98.79019260406494,\n",
              " 97.1367597579956,\n",
              " 37.70395517349243,\n",
              " 97.04140424728394,\n",
              " 99.99362230300903,\n",
              " 99.56334829330444,\n",
              " 91.4342999458313,\n",
              " 99.99712705612183,\n",
              " 91.93605780601501,\n",
              " 99.85560178756714,\n",
              " 1.1182606220245361,\n",
              " 94.82634663581848,\n",
              " 0.38138628005981445,\n",
              " 99.89107847213745,\n",
              " 90.82884788513184,\n",
              " 98.89804124832153,\n",
              " 10.461729764938354,\n",
              " 0.4236549139022827,\n",
              " 0.3960728645324707,\n",
              " 99.7714638710022,\n",
              " 99.77413415908813,\n",
              " 0.4966229200363159,\n",
              " 0.2802908420562744,\n",
              " 94.72326040267944,\n",
              " 1.3954401016235352,\n",
              " 99.92013573646545,\n",
              " 99.44239854812622,\n",
              " 2.4887502193450928,\n",
              " 0.0421673059463501,\n",
              " 5.774927139282227,\n",
              " 0.8330851793289185,\n",
              " 95.4261302947998,\n",
              " 96.86052799224854,\n",
              " 0.26616454124450684,\n",
              " 99.97355937957764,\n",
              " 99.92449283599854,\n",
              " 0.06709694862365723,\n",
              " 99.9261736869812,\n",
              " 99.3161141872406,\n",
              " 58.335429430007935,\n",
              " 99.93643760681152,\n",
              " 78.7117600440979,\n",
              " 90.81112146377563,\n",
              " 17.452627420425415,\n",
              " 94.75406408309937,\n",
              " 56.45703077316284,\n",
              " 1.4623165130615234,\n",
              " 0.2498030662536621,\n",
              " 99.87897872924805,\n",
              " 0.07131397724151611,\n",
              " 99.98661279678345,\n",
              " 2.7160078287124634,\n",
              " 9.27174687385559,\n",
              " 99.93115663528442,\n",
              " 0.030294060707092285,\n",
              " 3.6894232034683228,\n",
              " 6.847912073135376,\n",
              " 99.48898553848267,\n",
              " 96.35359644889832,\n",
              " 0.05156099796295166,\n",
              " 99.99068975448608,\n",
              " 0.3890037536621094,\n",
              " 20.232248306274414,\n",
              " 0.35962462425231934,\n",
              " 25.063806772232056,\n",
              " 93.86180639266968,\n",
              " 99.76825714111328,\n",
              " 99.75259304046631,\n",
              " 99.9972939491272,\n",
              " 0.5244016647338867,\n",
              " 99.8956561088562,\n",
              " 71.80886268615723,\n",
              " 99.75147843360901,\n",
              " 0.4995107650756836,\n",
              " 44.540151953697205,\n",
              " 0.030505657196044922,\n",
              " 32.86967873573303,\n",
              " 99.95089173316956,\n",
              " 99.78679418563843,\n",
              " 0.02930164337158203,\n",
              " 19.1096693277359,\n",
              " 99.97643232345581,\n",
              " 99.98468160629272,\n",
              " 58.17441940307617,\n",
              " 79.25945520401001,\n",
              " 0.07946193218231201,\n",
              " 99.77210760116577,\n",
              " 1.7387539148330688,\n",
              " 0.040027499198913574,\n",
              " 3.974813222885132,\n",
              " 0.046825408935546875,\n",
              " 99.33050274848938,\n",
              " 79.15083169937134,\n",
              " 0.004916778925689869,\n",
              " 0.6047934293746948,\n",
              " 83.62945318222046,\n",
              " 0.9689241647720337,\n",
              " 98.94280433654785,\n",
              " 81.25970959663391,\n",
              " 0.3468364477157593,\n",
              " 99.9359130859375,\n",
              " 98.10056686401367,\n",
              " 11.844795942306519,\n",
              " 42.79522001743317,\n",
              " 10.489410161972046,\n",
              " 0.4800260066986084,\n",
              " 81.34739398956299,\n",
              " 3.7754327058792114,\n",
              " 99.80390667915344,\n",
              " 0.00412917579524219,\n",
              " 98.31135272979736,\n",
              " 0.30114948749542236,\n",
              " 12.294727563858032,\n",
              " 99.40842390060425,\n",
              " 33.919113874435425,\n",
              " 1.6270220279693604,\n",
              " 99.71120357513428,\n",
              " 92.7419900894165,\n",
              " 0.045815110206604004]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scV4Bm6e8zrn"
      },
      "source": [
        "### ***Random Forest Classifier Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2qj25M98zro",
        "outputId": "d3c6bcd9-b4b3-44c7-cfcf-25a2b6417863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a random forest classifier.\n",
        "rf_model = RandomForestClassifier(n_estimators=256, random_state=32)\n",
        "\n",
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Random forest predictive accuracy: 0.978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08o92INxMNQ0",
        "outputId": "2b77c44b-0549-42e6-e106-77735175bb15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 72   3]\n",
            " [  1 107]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN-emBmv8zrv"
      },
      "source": [
        "### ***Logistic Regression Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyhJm6re8zrv"
      },
      "source": [
        "# Create a Logistic Regression Model\n",
        "classifier = LogisticRegression(solver='lbfgs',\n",
        "                                max_iter=200,\n",
        "                                random_state=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V5X1CAc8zry",
        "outputId": "fe17285b-77f7-4d29-f9f9-75960d77e470",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit (train) or model using the training data\n",
        "classifier.fit(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdxN4orO8zr0",
        "outputId": "552b80ba-8c83-4703-b32f-f963a95e96b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
        "results.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Prediction  Actual\n",
              "0            0       0\n",
              "1            0       0\n",
              "2            1       1\n",
              "3            0       0\n",
              "4            0       0\n",
              "5            1       1\n",
              "6            1       1\n",
              "7            1       1\n",
              "8            1       1\n",
              "9            1       1\n",
              "10           0       0\n",
              "11           0       0\n",
              "12           1       1\n",
              "13           0       0\n",
              "14           0       0\n",
              "15           0       0\n",
              "16           1       0\n",
              "17           1       1\n",
              "18           1       1\n",
              "19           1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzHFt7yg8zr1",
        "outputId": "49eb98dc-bf24-407d-ae2e-bbc95dc6c03f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.907103825136612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA9-0QZgMR16",
        "outputId": "acdd4666-d360-4fe3-a95b-54c9b2db58d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[68  7]\n",
            " [10 98]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-KV7kap9ER0"
      },
      "source": [
        "## ***Wine, Weather & Soil***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfFjVq0Z9ER2"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = White_Soil_ML_df[\"quality\"].values\n",
        "X = White_Soil_ML_df.drop([\"quality\",\"is_primeurs\", \"journalist_count\", \"confidence_index_A\",\"confidence_index_A+\", \"confidence_index_B\", \"confidence_index_B+\",\"confidence_index_C\", \"confidence_index_C+\"],1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQIo8cDn9ER5"
      },
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X)\n",
        "X_scaled = X_scaler.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRhr3mgMMbQM"
      },
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, random_state=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MxQ4Kv79ER8"
      },
      "source": [
        "###***Deep Learning Neural Netwrok for training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z82pNgZC9ER9",
        "outputId": "20cca482-7ac2-49b9-e3f2-58417846aa5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[-1])\n",
        "hidden_nodes_layer1 =  24\n",
        "hidden_nodes_layer2 = 12\n",
        "\n",
        "# metrics = [\n",
        "#     tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "#     tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "#     tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "#     tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "#     tf.keras.metrics.Precision(name=\"precision\"),\n",
        "#     tf.keras.metrics.Recall(name=\"recall\"),\n",
        "# ]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.8282 - accuracy: 0.4708 - val_loss: 0.7646 - val_accuracy: 0.5273\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.6058 - val_loss: 0.6870 - val_accuracy: 0.5818\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.6642 - val_loss: 0.6337 - val_accuracy: 0.6473\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5473 - accuracy: 0.7628 - val_loss: 0.6061 - val_accuracy: 0.6764\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.8029 - val_loss: 0.5852 - val_accuracy: 0.7018\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.8248 - val_loss: 0.5670 - val_accuracy: 0.7127\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.8321 - val_loss: 0.5515 - val_accuracy: 0.7309\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8394 - val_loss: 0.5358 - val_accuracy: 0.7382\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8613 - val_loss: 0.5211 - val_accuracy: 0.7491\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.8759 - val_loss: 0.5084 - val_accuracy: 0.7491\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8905 - val_loss: 0.4939 - val_accuracy: 0.7527\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.9051 - val_loss: 0.4852 - val_accuracy: 0.7673\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.9124 - val_loss: 0.4784 - val_accuracy: 0.7709\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2839 - accuracy: 0.9088 - val_loss: 0.4627 - val_accuracy: 0.7818\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2643 - accuracy: 0.9088 - val_loss: 0.4544 - val_accuracy: 0.7964\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2483 - accuracy: 0.9197 - val_loss: 0.4442 - val_accuracy: 0.8036\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2320 - accuracy: 0.9307 - val_loss: 0.4317 - val_accuracy: 0.8073\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9307 - val_loss: 0.4201 - val_accuracy: 0.8182\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2050 - accuracy: 0.9416 - val_loss: 0.4132 - val_accuracy: 0.8145\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1932 - accuracy: 0.9416 - val_loss: 0.4089 - val_accuracy: 0.8182\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9380 - val_loss: 0.3994 - val_accuracy: 0.8145\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1734 - accuracy: 0.9380 - val_loss: 0.3924 - val_accuracy: 0.8145\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1649 - accuracy: 0.9343 - val_loss: 0.3829 - val_accuracy: 0.8255\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1572 - accuracy: 0.9453 - val_loss: 0.3843 - val_accuracy: 0.8255\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9526 - val_loss: 0.3707 - val_accuracy: 0.8327\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1438 - accuracy: 0.9562 - val_loss: 0.3598 - val_accuracy: 0.8436\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1329 - accuracy: 0.9526 - val_loss: 0.3716 - val_accuracy: 0.8364\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9599 - val_loss: 0.3688 - val_accuracy: 0.8473\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1228 - accuracy: 0.9672 - val_loss: 0.3583 - val_accuracy: 0.8473\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1169 - accuracy: 0.9745 - val_loss: 0.3504 - val_accuracy: 0.8545\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1123 - accuracy: 0.9635 - val_loss: 0.3499 - val_accuracy: 0.8582\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1083 - accuracy: 0.9635 - val_loss: 0.3553 - val_accuracy: 0.8509\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1030 - accuracy: 0.9708 - val_loss: 0.3486 - val_accuracy: 0.8582\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1007 - accuracy: 0.9745 - val_loss: 0.3445 - val_accuracy: 0.8582\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9745 - val_loss: 0.3518 - val_accuracy: 0.8545\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0924 - accuracy: 0.9818 - val_loss: 0.3497 - val_accuracy: 0.8545\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.9818 - val_loss: 0.3465 - val_accuracy: 0.8691\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0858 - accuracy: 0.9854 - val_loss: 0.3447 - val_accuracy: 0.8691\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9818 - val_loss: 0.3446 - val_accuracy: 0.8691\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0804 - accuracy: 0.9781 - val_loss: 0.3455 - val_accuracy: 0.8691\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0762 - accuracy: 0.9854 - val_loss: 0.3493 - val_accuracy: 0.8618\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9854 - val_loss: 0.3457 - val_accuracy: 0.8727\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9818 - val_loss: 0.3404 - val_accuracy: 0.8727\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.9891 - val_loss: 0.3575 - val_accuracy: 0.8655\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9927 - val_loss: 0.3440 - val_accuracy: 0.8727\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9927 - val_loss: 0.3420 - val_accuracy: 0.8727\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9927 - val_loss: 0.3515 - val_accuracy: 0.8691\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9927 - val_loss: 0.3570 - val_accuracy: 0.8691\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9891 - val_loss: 0.3592 - val_accuracy: 0.8691\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0525 - accuracy: 0.9964 - val_loss: 0.3462 - val_accuracy: 0.8727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD_aJFLuMu-l",
        "outputId": "85421133-1671-49da-9077-1e3c2a72948a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "tf.keras.utils.plot_model(nn, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkHkpRVZ9ER_"
      },
      "source": [
        "###***Deep Learning Neural Netwrok Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcnZuE7rtSTA",
        "outputId": "95cc85e5-0210-4b22-bdfa-83133202c1a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 - 0s - loss: 0.6191 - accuracy: 0.8087\n",
            "Loss: 0.6190676689147949, Accuracy: 0.8087431788444519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r_lF0JY9ESB"
      },
      "source": [
        "# # Evaluate the model using the test data\n",
        "# model_loss, FalseNegatives,FalsePositives, TrueNegatives, TruePositives, Precision, Recall = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "# print(f\"\"\"\\t  Loss: {model_loss},\n",
        "#           FalseNegatives: {FalseNegatives},\n",
        "#           FalsePositives: {FalsePositives},\n",
        "#           TrueNegatives: {TrueNegatives},\n",
        "#           TruePositives: {TruePositives},\n",
        "#           Precision: {Precision},\n",
        "#           Recall: {Recall},\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZeAxXr7M5i9",
        "outputId": "2aba2284-3039-4592-f24b-7f7aba12f19a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = nn.predict(X_test_scaled)\n",
        "adjusted_predictions = [(100 * x[0]) for x in predictions]\n",
        "adjusted_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7551968097686768,\n",
              " 0.09001791477203369,\n",
              " 91.0678505897522,\n",
              " 0.058776140213012695,\n",
              " 0.008903017442207783,\n",
              " 95.39160132408142,\n",
              " 96.37898206710815,\n",
              " 74.95173215866089,\n",
              " 73.18072319030762,\n",
              " 9.501287341117859,\n",
              " 0.13057589530944824,\n",
              " 1.9862890243530273,\n",
              " 95.48949003219604,\n",
              " 41.312816739082336,\n",
              " 8.16500186920166,\n",
              " 0.002714730908337515,\n",
              " 91.38660430908203,\n",
              " 95.50076723098755,\n",
              " 2.324974536895752,\n",
              " 95.87653279304504,\n",
              " 44.90754306316376,\n",
              " 99.21322464942932,\n",
              " 95.06949782371521,\n",
              " 0.1942276954650879,\n",
              " 99.18720722198486,\n",
              " 35.01598536968231,\n",
              " 99.92094039916992,\n",
              " 86.67412400245667,\n",
              " 29.010701179504395,\n",
              " 0.0576704740524292,\n",
              " 0.23818910121917725,\n",
              " 99.98061656951904,\n",
              " 0.19733011722564697,\n",
              " 18.669503927230835,\n",
              " 15.047121047973633,\n",
              " 0.02174079418182373,\n",
              " 99.97625350952148,\n",
              " 98.86667728424072,\n",
              " 99.90462064743042,\n",
              " 0.1504838466644287,\n",
              " 86.84561252593994,\n",
              " 10.590049624443054,\n",
              " 65.48576951026917,\n",
              " 55.24299740791321,\n",
              " 2.119046449661255,\n",
              " 99.6598482131958,\n",
              " 1.4432340860366821,\n",
              " 37.65724301338196,\n",
              " 56.44679069519043,\n",
              " 99.67517256736755,\n",
              " 50.370633602142334,\n",
              " 94.18461322784424,\n",
              " 99.17182326316833,\n",
              " 6.108304858207703,\n",
              " 99.96581077575684,\n",
              " 0.014415383338928223,\n",
              " 99.34080839157104,\n",
              " 1.3685613870620728,\n",
              " 99.94773864746094,\n",
              " 99.37434196472168,\n",
              " 98.90682697296143,\n",
              " 29.40102219581604,\n",
              " 99.58069324493408,\n",
              " 0.07813572883605957,\n",
              " 42.81349182128906,\n",
              " 16.627636551856995,\n",
              " 32.64567255973816,\n",
              " 98.62922430038452,\n",
              " 99.76876378059387,\n",
              " 94.35060024261475,\n",
              " 53.188031911849976,\n",
              " 99.14474487304688,\n",
              " 11.654776334762573,\n",
              " 98.09419512748718,\n",
              " 6.009289622306824,\n",
              " 98.73514771461487,\n",
              " 2.7014344930648804,\n",
              " 97.62726426124573,\n",
              " 94.14215683937073,\n",
              " 99.89270567893982,\n",
              " 25.36279857158661,\n",
              " 0.11129379272460938,\n",
              " 0.5532681941986084,\n",
              " 99.84036087989807,\n",
              " 99.13888573646545,\n",
              " 0.10618269443511963,\n",
              " 0.05939900875091553,\n",
              " 31.516724824905396,\n",
              " 0.5370229482650757,\n",
              " 98.79891276359558,\n",
              " 99.723881483078,\n",
              " 2.53121554851532,\n",
              " 0.04048645496368408,\n",
              " 99.85793828964233,\n",
              " 0.2620428800582886,\n",
              " 71.17859125137329,\n",
              " 99.29423332214355,\n",
              " 0.1419156789779663,\n",
              " 99.89961981773376,\n",
              " 99.48999881744385,\n",
              " 0.008498900569975376,\n",
              " 54.304224252700806,\n",
              " 98.7070083618164,\n",
              " 76.65969133377075,\n",
              " 99.52392578125,\n",
              " 91.7252779006958,\n",
              " 85.04692316055298,\n",
              " 21.135777235031128,\n",
              " 98.93708229064941,\n",
              " 0.0667273998260498,\n",
              " 10.22111177444458,\n",
              " 0.21752417087554932,\n",
              " 99.47628974914551,\n",
              " 0.5267441272735596,\n",
              " 99.70364570617676,\n",
              " 2.5532305240631104,\n",
              " 2.126723527908325,\n",
              " 96.39304876327515,\n",
              " 0.2737760543823242,\n",
              " 5.463433265686035,\n",
              " 1.045265793800354,\n",
              " 64.34293389320374,\n",
              " 14.923834800720215,\n",
              " 0.11029541492462158,\n",
              " 99.94480013847351,\n",
              " 1.324605941772461,\n",
              " 22.678419947624207,\n",
              " 0.06864070892333984,\n",
              " 12.569603323936462,\n",
              " 93.45105290412903,\n",
              " 98.08213710784912,\n",
              " 99.6311902999878,\n",
              " 99.93422627449036,\n",
              " 0.1764059066772461,\n",
              " 99.70697164535522,\n",
              " 67.21850633621216,\n",
              " 99.71587061882019,\n",
              " 0.08505582809448242,\n",
              " 74.24330115318298,\n",
              " 0.4976630210876465,\n",
              " 14.65618908405304,\n",
              " 99.31665658950806,\n",
              " 99.64410066604614,\n",
              " 0.04868507385253906,\n",
              " 21.678951382637024,\n",
              " 98.49697351455688,\n",
              " 97.91381359100342,\n",
              " 87.92273998260498,\n",
              " 98.5642671585083,\n",
              " 0.10901093482971191,\n",
              " 95.69551944732666,\n",
              " 2.6824474334716797,\n",
              " 0.05128979682922363,\n",
              " 1.3161778450012207,\n",
              " 0.4462778568267822,\n",
              " 18.93792152404785,\n",
              " 2.3945480585098267,\n",
              " 0.002839678927557543,\n",
              " 1.024162769317627,\n",
              " 62.65215277671814,\n",
              " 0.8282870054244995,\n",
              " 58.28086733818054,\n",
              " 56.55214786529541,\n",
              " 11.93087100982666,\n",
              " 99.90586042404175,\n",
              " 99.90953803062439,\n",
              " 47.96285331249237,\n",
              " 2.106499671936035,\n",
              " 67.424476146698,\n",
              " 0.5911171436309814,\n",
              " 87.3356580734253,\n",
              " 3.382861614227295,\n",
              " 99.85067248344421,\n",
              " 0.016370415687561035,\n",
              " 94.12827491760254,\n",
              " 0.6250768899917603,\n",
              " 0.0848621129989624,\n",
              " 99.92614984512329,\n",
              " 16.728124022483826,\n",
              " 6.600585579872131,\n",
              " 99.62611198425293,\n",
              " 97.41647243499756,\n",
              " 0.23527443408966064]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc-m16Nr9ESK"
      },
      "source": [
        "### ***Random Forest Classifier Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3Td-0zH9ESK",
        "outputId": "bfb22567-35f4-48af-cd35-48980a6216e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a random forest classifier.\n",
        "rf_model = RandomForestClassifier(n_estimators=256, random_state=32)\n",
        "\n",
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Random forest predictive accuracy: 0.945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xj8nt8cM-oW",
        "outputId": "d6b1dcd9-9cde-49d2-b921-daf4cf37c3ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 72   3]\n",
            " [  7 101]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZfEmRyi9ESQ"
      },
      "source": [
        "### ***Logistic Regression Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXiMrIEp9ESQ"
      },
      "source": [
        "# Create a Logistic Regression Model\n",
        "classifier = LogisticRegression(solver='lbfgs',\n",
        "                                max_iter=200,\n",
        "                                random_state=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM1hI9zp9ESS",
        "outputId": "e57f9360-b701-459a-804c-f7449a8795c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit (train) or model using the training data\n",
        "classifier.fit(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nVPSP459EST",
        "outputId": "75c7705c-2963-4377-b5a0-47c13f965b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
        "results.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Prediction  Actual\n",
              "0            0       0\n",
              "1            0       0\n",
              "2            1       1\n",
              "3            0       0\n",
              "4            0       0\n",
              "5            1       1\n",
              "6            1       1\n",
              "7            1       1\n",
              "8            1       1\n",
              "9            1       1\n",
              "10           0       0\n",
              "11           0       0\n",
              "12           1       1\n",
              "13           0       0\n",
              "14           0       0\n",
              "15           0       0\n",
              "16           1       0\n",
              "17           1       1\n",
              "18           1       1\n",
              "19           1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84DZ0DjH9ESU",
        "outputId": "d0db014f-a6d7-4b6f-8439-f634ccb1dd3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.907103825136612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkCsJSTGNDw2",
        "outputId": "a2cbe7b0-8a93-478a-b59f-0762bd72b33d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[68  7]\n",
            " [10 98]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}