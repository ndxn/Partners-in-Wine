{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the requests library.\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import the requests library.\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "# Dependencies for the wine API\n",
    "import urllib\n",
    "import json\n",
    "# Import the API key.\n",
    "from config import Token_NOAA\n",
    "from config import API_Token\n",
    "import calendar\n",
    "#Suppress Warnings\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "#Display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/crvaden/NOAA_API_v2\n",
    "# https://towardsdatascience.com/getting-weather-data-in-3-easy-steps-8dc10cc5c859\n",
    "# https://cran.r-project.org/web/packages/rnoaa/rnoaa.pdf\n",
    "# file:///C:/Users/15124/Downloads/GHCND_documentation.pdf\n",
    "# https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This JN finds the weather by the zip code. \n",
    "# This is not in a for loop is because some zip codes have better data than others.\n",
    "# To find the best zip code for the best area we had to run this multiple times and it took too long to run on our computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data By Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "napadf = pd.DataFrame()\n",
    "states = {\n",
    "    'Napa': {\n",
    "        'zip': '95472',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97013',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if napadf.empty:\n",
    "        napadf = small_df\n",
    "    else:\n",
    "        napadf = pd.merge(napadf,small_df)\n",
    "napadf.to_csv( 'Napa_Max_Min.csv', index = False)\n",
    "# napadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "walladf = pd.DataFrame()\n",
    "states = {\n",
    "#     'Napa': {\n",
    "#         'zip': '95472',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "    'Walla': {\n",
    "        'zip': '99362',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97013',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if walladf.empty:\n",
    "        walladf = small_df\n",
    "    else:\n",
    "        walladf = pd.merge(walladf,small_df)\n",
    "walladf.to_csv( 'Walla_Max_Min.csv', index = False)\n",
    "# walladf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "columbiadf = pd.DataFrame()\n",
    "states = {\n",
    "#     'Napa': {\n",
    "#         'zip': '95472',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "    'Columbia': {\n",
    "        'zip': '98813',\n",
    "        'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97013',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if columbiadf.empty:\n",
    "        columbiadf = small_df\n",
    "    else:\n",
    "        columbiadf = pd.merge(columbiadf,small_df)\n",
    "columbiadf.to_csv( 'Columbia_Max_Min.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonomadf = pd.DataFrame()\n",
    "states = {\n",
    "#     'Napa': {\n",
    "#         'zip': '95472',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "    'Sonoma': {\n",
    "        'zip': '95476',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97013',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if sonomadf.empty:\n",
    "        sonomadf = small_df\n",
    "    else:\n",
    "        sonomadf = pd.merge(sonomadf,small_df)\n",
    "sonomadf.to_csv( 'Sonoma_Max_Min.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "santadf = pd.DataFrame()\n",
    "states = {\n",
    "#     'Napa': {\n",
    "#         'zip': '95472',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "    'Santa': {\n",
    "        'zip': '95062',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97013',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if santadf.empty:\n",
    "        santadf = small_df\n",
    "    else:\n",
    "        santadf = pd.merge(sonomadf,small_df)\n",
    "santadf.to_csv( 'Santa_Max_Min.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "yakimadf = pd.DataFrame()\n",
    "states = {\n",
    "#     'Napa': {\n",
    "#         'zip': '95472',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "    'Yakima': {\n",
    "        'zip': '98903',\n",
    "        'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97013',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if yakimadf.empty:\n",
    "        yakimadf = small_df\n",
    "    else:\n",
    "        yakimadf = pd.merge(yakimadf,small_df)\n",
    "yakimadf.to_csv( 'Yakima_Max_Min.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dundeedf = pd.DataFrame()\n",
    "states = {\n",
    "#     'Napa': {\n",
    "#         'zip': '95472',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "    'Dundee': {\n",
    "        'zip': '97045',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97013',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if dundeedf.empty:\n",
    "        dundeedf = small_df\n",
    "    else:\n",
    "        dundeedf = pd.merge(dundeedf,small_df)\n",
    "dundeedf.to_csv( 'Dundee_Max_Min.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "willamettedf = pd.DataFrame()\n",
    "states = {\n",
    "#     'Napa': {\n",
    "#         'zip': '95472',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "    'Willamette': {\n",
    "        'zip': '97302',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if willamettedf.empty:\n",
    "        willamettedf = small_df\n",
    "    else:\n",
    "        willamettedf = pd.merge(willamettedf,small_df)\n",
    "willamettedf.to_csv( 'Will_Max_Min.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "willamettedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
