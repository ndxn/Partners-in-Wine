{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "White_Wine_ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhwv0JVk4OYf",
        "outputId": "f4b7f20f-280f-4a7a-f810-0f7035a8fc87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.0'\n",
        "spark_version = 'spark-3.0.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install psycopg2-binary\n",
        "!pip install keras-tuner\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sqlalchemy import create_engine\n",
        "from kerastuner.tuners import RandomSearch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.6/dist-packages (2.8.6)\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.4.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.5)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA2YiP5p4diM",
        "outputId": "ad2acc23-dc22-4895-9192-06abb680a3dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# enter the following code to download a Postgres driver that will allow Spark to interact with Postgres:\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-02 02:29:38--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar.6’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  5.46MB/s    in 0.2s    \n",
            "\n",
            "2020-11-02 02:29:38 (5.46 MB/s) - ‘postgresql-42.2.16.jar.6’ saved [1002883/1002883]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Dpxt-P4eci"
      },
      "source": [
        "# start a Spark session with an additional option that adds the driver to Spark:\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Wine_Weather\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufHy0SIvYK7W"
      },
      "source": [
        "##***White Wine Machine Learning Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5cDkhQuDASb",
        "outputId": "6abd1f9f-7132-4c3e-e6e8-e6b073e02031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "#Read white wine sql table into a dataframe\n",
        "White_Soil_ML_df = pd.read_sql_table('white_soil_table', 'postgresql://postgres:postgres@database-1.cslpjur96f9r.us-east-2.rds.amazonaws.com:5432') \n",
        "White_Soil_ML_df.head() "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appellation</th>\n",
              "      <th>wine</th>\n",
              "      <th>wine_id</th>\n",
              "      <th>color</th>\n",
              "      <th>regions</th>\n",
              "      <th>country</th>\n",
              "      <th>vintage</th>\n",
              "      <th>is_primeurs</th>\n",
              "      <th>score</th>\n",
              "      <th>confidence_index</th>\n",
              "      <th>journalist_count</th>\n",
              "      <th>avgPrcpFebruary</th>\n",
              "      <th>avgTempFebruary</th>\n",
              "      <th>avgPrcpMarch</th>\n",
              "      <th>avgTempMarch</th>\n",
              "      <th>avgPrcpApril</th>\n",
              "      <th>avgTempApril</th>\n",
              "      <th>avgPrcpMay</th>\n",
              "      <th>avgTempMay</th>\n",
              "      <th>avgPrcpJune</th>\n",
              "      <th>avgTempJune</th>\n",
              "      <th>avgPrcpJuly</th>\n",
              "      <th>avgTempJuly</th>\n",
              "      <th>avgPrcpAugust</th>\n",
              "      <th>avgTempAugust</th>\n",
              "      <th>avgPrcpSeptember</th>\n",
              "      <th>avgTempSeptember</th>\n",
              "      <th>avgPrcpOctober</th>\n",
              "      <th>avgTempOctober</th>\n",
              "      <th>bdod_0-100cm</th>\n",
              "      <th>bdod_100-200cm</th>\n",
              "      <th>cec_0-100cm</th>\n",
              "      <th>cec_100-200cm</th>\n",
              "      <th>cfvo_0-100cm</th>\n",
              "      <th>cfvo_100-200cm</th>\n",
              "      <th>clay_0-100cm</th>\n",
              "      <th>clay_100-200cm</th>\n",
              "      <th>nitrogen_0-100cm</th>\n",
              "      <th>nitrogen_100-200cm</th>\n",
              "      <th>ocd_0-100cm</th>\n",
              "      <th>ocd_100-200cm</th>\n",
              "      <th>ocs_0-30cm</th>\n",
              "      <th>phh2o_0-100cm</th>\n",
              "      <th>phh2o_100-200cm</th>\n",
              "      <th>sand_0-100cm</th>\n",
              "      <th>sand_100-200cm</th>\n",
              "      <th>silt_0-100cm</th>\n",
              "      <th>silt_100-200cm</th>\n",
              "      <th>soc_0-100cm</th>\n",
              "      <th>soc_100-200cm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Santa Cruz Mountains</td>\n",
              "      <td>Mount Eden Vineyards, Chardonnay, White, Santa...</td>\n",
              "      <td>107658</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.22</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>0.174747</td>\n",
              "      <td>58</td>\n",
              "      <td>0.018630</td>\n",
              "      <td>60</td>\n",
              "      <td>0.096254</td>\n",
              "      <td>59</td>\n",
              "      <td>0.002989</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>65</td>\n",
              "      <td>0.001132</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000947</td>\n",
              "      <td>70</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>68</td>\n",
              "      <td>0.005581</td>\n",
              "      <td>66</td>\n",
              "      <td>139.75</td>\n",
              "      <td>149</td>\n",
              "      <td>153.4</td>\n",
              "      <td>145</td>\n",
              "      <td>183.5</td>\n",
              "      <td>245</td>\n",
              "      <td>197.50</td>\n",
              "      <td>193</td>\n",
              "      <td>145.7</td>\n",
              "      <td>60</td>\n",
              "      <td>124.95</td>\n",
              "      <td>25</td>\n",
              "      <td>60</td>\n",
              "      <td>5.50206</td>\n",
              "      <td>5.9</td>\n",
              "      <td>442.10</td>\n",
              "      <td>468</td>\n",
              "      <td>324.85</td>\n",
              "      <td>283</td>\n",
              "      <td>128.55</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Napa Valley</td>\n",
              "      <td>Pahlmeyer, Napa Valley Chardonnay, White, Napa...</td>\n",
              "      <td>111897</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.83</td>\n",
              "      <td>C+</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.5</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.6</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>418.85</td>\n",
              "      <td>410</td>\n",
              "      <td>84.00</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sonoma Coast</td>\n",
              "      <td>Marcassin, Lorenzo Vineyard Chardonnay, White,...</td>\n",
              "      <td>101640</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1993</td>\n",
              "      <td>False</td>\n",
              "      <td>92.07</td>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "      <td>0.275357</td>\n",
              "      <td>58</td>\n",
              "      <td>0.086129</td>\n",
              "      <td>67</td>\n",
              "      <td>0.050667</td>\n",
              "      <td>68</td>\n",
              "      <td>0.068929</td>\n",
              "      <td>73</td>\n",
              "      <td>0.029333</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85</td>\n",
              "      <td>0.058710</td>\n",
              "      <td>77</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.5</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.5</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>319.20</td>\n",
              "      <td>251</td>\n",
              "      <td>98.60</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sonoma Coast</td>\n",
              "      <td>Marcassin, Lorenzo Vineyard Chardonnay, White,...</td>\n",
              "      <td>101640</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1998</td>\n",
              "      <td>False</td>\n",
              "      <td>91.74</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>0.674643</td>\n",
              "      <td>57</td>\n",
              "      <td>0.074516</td>\n",
              "      <td>64</td>\n",
              "      <td>0.060345</td>\n",
              "      <td>68</td>\n",
              "      <td>0.125806</td>\n",
              "      <td>67</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>76</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>83</td>\n",
              "      <td>0.027419</td>\n",
              "      <td>75</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.5</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.5</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>319.20</td>\n",
              "      <td>251</td>\n",
              "      <td>98.60</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Napa Valley</td>\n",
              "      <td>Kongsgaard, The Judge Chardonnay, White, Napa ...</td>\n",
              "      <td>91591</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>97.27</td>\n",
              "      <td>B+</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.5</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.6</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>418.85</td>\n",
              "      <td>410</td>\n",
              "      <td>84.00</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            appellation  ... soc_100-200cm\n",
              "0  Santa Cruz Mountains  ...            38\n",
              "1           Napa Valley  ...            27\n",
              "2          Sonoma Coast  ...            18\n",
              "3          Sonoma Coast  ...            18\n",
              "4           Napa Valley  ...            27\n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NORZgQZO59u",
        "outputId": "ea2f7695-85bf-46bb-fed2-394bbb369d69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "White_Soil_ML_df.dtypes"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "appellation            object\n",
              "wine                   object\n",
              "wine_id                 int64\n",
              "color                  object\n",
              "regions                object\n",
              "country                object\n",
              "vintage                 int64\n",
              "is_primeurs              bool\n",
              "score                 float64\n",
              "confidence_index       object\n",
              "journalist_count        int64\n",
              "avgPrcpFebruary       float64\n",
              "avgTempFebruary         int64\n",
              "avgPrcpMarch          float64\n",
              "avgTempMarch            int64\n",
              "avgPrcpApril          float64\n",
              "avgTempApril            int64\n",
              "avgPrcpMay            float64\n",
              "avgTempMay              int64\n",
              "avgPrcpJune           float64\n",
              "avgTempJune             int64\n",
              "avgPrcpJuly           float64\n",
              "avgTempJuly             int64\n",
              "avgPrcpAugust         float64\n",
              "avgTempAugust           int64\n",
              "avgPrcpSeptember      float64\n",
              "avgTempSeptember        int64\n",
              "avgPrcpOctober        float64\n",
              "avgTempOctober          int64\n",
              "bdod_0-100cm          float64\n",
              "bdod_100-200cm          int64\n",
              "cec_0-100cm           float64\n",
              "cec_100-200cm           int64\n",
              "cfvo_0-100cm          float64\n",
              "cfvo_100-200cm          int64\n",
              "clay_0-100cm          float64\n",
              "clay_100-200cm          int64\n",
              "nitrogen_0-100cm      float64\n",
              "nitrogen_100-200cm      int64\n",
              "ocd_0-100cm           float64\n",
              "ocd_100-200cm           int64\n",
              "ocs_0-30cm              int64\n",
              "phh2o_0-100cm         float64\n",
              "phh2o_100-200cm       float64\n",
              "sand_0-100cm          float64\n",
              "sand_100-200cm          int64\n",
              "silt_0-100cm          float64\n",
              "silt_100-200cm          int64\n",
              "soc_0-100cm           float64\n",
              "soc_100-200cm           int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yFuv7s1O59y",
        "outputId": "6c0469db-59e5-41dc-e271-d4807b006698",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "White_Soil_ML_df[\"score\"].astype(int) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      92\n",
              "1      92\n",
              "2      92\n",
              "3      91\n",
              "4      97\n",
              "       ..\n",
              "727    87\n",
              "728    91\n",
              "729    93\n",
              "730    86\n",
              "731    88\n",
              "Name: score, Length: 732, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFRIEoeWO590"
      },
      "source": [
        "#Splitting score into good(1) and bad(0) and making it it's own column \"quality\"\n",
        "quality = []\n",
        "\n",
        "for x in White_Soil_ML_df[\"score\"]:\n",
        "  if x >= 91:\n",
        "    quality.append(1)\n",
        "  else:\n",
        "    quality.append(0)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUx-ic_fO592"
      },
      "source": [
        "White_Soil_ML_df[\"quality\"] = quality"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvx4qNPNO594",
        "outputId": "06289668-b179-403f-90b7-b9c3de1b6214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "White_Soil_ML_df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appellation</th>\n",
              "      <th>wine</th>\n",
              "      <th>wine_id</th>\n",
              "      <th>color</th>\n",
              "      <th>regions</th>\n",
              "      <th>country</th>\n",
              "      <th>vintage</th>\n",
              "      <th>is_primeurs</th>\n",
              "      <th>score</th>\n",
              "      <th>confidence_index</th>\n",
              "      <th>journalist_count</th>\n",
              "      <th>avgPrcpFebruary</th>\n",
              "      <th>avgTempFebruary</th>\n",
              "      <th>avgPrcpMarch</th>\n",
              "      <th>avgTempMarch</th>\n",
              "      <th>avgPrcpApril</th>\n",
              "      <th>avgTempApril</th>\n",
              "      <th>avgPrcpMay</th>\n",
              "      <th>avgTempMay</th>\n",
              "      <th>avgPrcpJune</th>\n",
              "      <th>avgTempJune</th>\n",
              "      <th>avgPrcpJuly</th>\n",
              "      <th>avgTempJuly</th>\n",
              "      <th>avgPrcpAugust</th>\n",
              "      <th>avgTempAugust</th>\n",
              "      <th>avgPrcpSeptember</th>\n",
              "      <th>avgTempSeptember</th>\n",
              "      <th>avgPrcpOctober</th>\n",
              "      <th>avgTempOctober</th>\n",
              "      <th>bdod_0-100cm</th>\n",
              "      <th>bdod_100-200cm</th>\n",
              "      <th>cec_0-100cm</th>\n",
              "      <th>cec_100-200cm</th>\n",
              "      <th>cfvo_0-100cm</th>\n",
              "      <th>cfvo_100-200cm</th>\n",
              "      <th>clay_0-100cm</th>\n",
              "      <th>clay_100-200cm</th>\n",
              "      <th>nitrogen_0-100cm</th>\n",
              "      <th>nitrogen_100-200cm</th>\n",
              "      <th>ocd_0-100cm</th>\n",
              "      <th>ocd_100-200cm</th>\n",
              "      <th>ocs_0-30cm</th>\n",
              "      <th>phh2o_0-100cm</th>\n",
              "      <th>phh2o_100-200cm</th>\n",
              "      <th>sand_0-100cm</th>\n",
              "      <th>sand_100-200cm</th>\n",
              "      <th>silt_0-100cm</th>\n",
              "      <th>silt_100-200cm</th>\n",
              "      <th>soc_0-100cm</th>\n",
              "      <th>soc_100-200cm</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Santa Cruz Mountains</td>\n",
              "      <td>Mount Eden Vineyards, Chardonnay, White, Santa...</td>\n",
              "      <td>107658</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.22</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>0.174747</td>\n",
              "      <td>58</td>\n",
              "      <td>0.018630</td>\n",
              "      <td>60</td>\n",
              "      <td>0.096254</td>\n",
              "      <td>59</td>\n",
              "      <td>0.002989</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>65</td>\n",
              "      <td>0.001132</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000947</td>\n",
              "      <td>70</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>68</td>\n",
              "      <td>0.005581</td>\n",
              "      <td>66</td>\n",
              "      <td>139.75</td>\n",
              "      <td>149</td>\n",
              "      <td>153.4</td>\n",
              "      <td>145</td>\n",
              "      <td>183.50</td>\n",
              "      <td>245</td>\n",
              "      <td>197.50</td>\n",
              "      <td>193</td>\n",
              "      <td>145.70</td>\n",
              "      <td>60</td>\n",
              "      <td>124.95</td>\n",
              "      <td>25</td>\n",
              "      <td>60</td>\n",
              "      <td>5.50206</td>\n",
              "      <td>5.9</td>\n",
              "      <td>442.10</td>\n",
              "      <td>468</td>\n",
              "      <td>324.85</td>\n",
              "      <td>283</td>\n",
              "      <td>128.55</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Napa Valley</td>\n",
              "      <td>Pahlmeyer, Napa Valley Chardonnay, White, Napa...</td>\n",
              "      <td>111897</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.83</td>\n",
              "      <td>C+</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.50</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.60</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>418.85</td>\n",
              "      <td>410</td>\n",
              "      <td>84.00</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sonoma Coast</td>\n",
              "      <td>Marcassin, Lorenzo Vineyard Chardonnay, White,...</td>\n",
              "      <td>101640</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1993</td>\n",
              "      <td>False</td>\n",
              "      <td>92.07</td>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "      <td>0.275357</td>\n",
              "      <td>58</td>\n",
              "      <td>0.086129</td>\n",
              "      <td>67</td>\n",
              "      <td>0.050667</td>\n",
              "      <td>68</td>\n",
              "      <td>0.068929</td>\n",
              "      <td>73</td>\n",
              "      <td>0.029333</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85</td>\n",
              "      <td>0.058710</td>\n",
              "      <td>77</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.50</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.50</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>319.20</td>\n",
              "      <td>251</td>\n",
              "      <td>98.60</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sonoma Coast</td>\n",
              "      <td>Marcassin, Lorenzo Vineyard Chardonnay, White,...</td>\n",
              "      <td>101640</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1998</td>\n",
              "      <td>False</td>\n",
              "      <td>91.74</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>0.674643</td>\n",
              "      <td>57</td>\n",
              "      <td>0.074516</td>\n",
              "      <td>64</td>\n",
              "      <td>0.060345</td>\n",
              "      <td>68</td>\n",
              "      <td>0.125806</td>\n",
              "      <td>67</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>76</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>83</td>\n",
              "      <td>0.027419</td>\n",
              "      <td>75</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.50</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.50</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>319.20</td>\n",
              "      <td>251</td>\n",
              "      <td>98.60</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Napa Valley</td>\n",
              "      <td>Kongsgaard, The Judge Chardonnay, White, Napa ...</td>\n",
              "      <td>91591</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>97.27</td>\n",
              "      <td>B+</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.50</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.60</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>418.85</td>\n",
              "      <td>410</td>\n",
              "      <td>84.00</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>Carneros</td>\n",
              "      <td>Truchard Vineyards, Chardonnay, White, Carneros</td>\n",
              "      <td>136966</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1996</td>\n",
              "      <td>False</td>\n",
              "      <td>87.68</td>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "      <td>0.312000</td>\n",
              "      <td>62</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>68</td>\n",
              "      <td>0.116333</td>\n",
              "      <td>71</td>\n",
              "      <td>0.108710</td>\n",
              "      <td>76</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90</td>\n",
              "      <td>0.005667</td>\n",
              "      <td>83</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>76</td>\n",
              "      <td>160.40</td>\n",
              "      <td>161</td>\n",
              "      <td>215.4</td>\n",
              "      <td>233</td>\n",
              "      <td>30.15</td>\n",
              "      <td>25</td>\n",
              "      <td>216.10</td>\n",
              "      <td>219</td>\n",
              "      <td>60.15</td>\n",
              "      <td>36</td>\n",
              "      <td>117.25</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>5.80206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>317.75</td>\n",
              "      <td>340</td>\n",
              "      <td>408.60</td>\n",
              "      <td>401</td>\n",
              "      <td>57.90</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>Sonoma County</td>\n",
              "      <td>Peter Michael Winery, Belle Cote Chardonnay, W...</td>\n",
              "      <td>114819</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1996</td>\n",
              "      <td>False</td>\n",
              "      <td>91.76</td>\n",
              "      <td>C+</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>145.00</td>\n",
              "      <td>150</td>\n",
              "      <td>184.4</td>\n",
              "      <td>190</td>\n",
              "      <td>105.50</td>\n",
              "      <td>110</td>\n",
              "      <td>262.80</td>\n",
              "      <td>298</td>\n",
              "      <td>84.70</td>\n",
              "      <td>36</td>\n",
              "      <td>121.60</td>\n",
              "      <td>29</td>\n",
              "      <td>55</td>\n",
              "      <td>5.20206</td>\n",
              "      <td>5.7</td>\n",
              "      <td>352.40</td>\n",
              "      <td>337</td>\n",
              "      <td>371.65</td>\n",
              "      <td>346</td>\n",
              "      <td>110.95</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>Carneros</td>\n",
              "      <td>Kistler Vineyards, Hudson Vineyard Chardonnay,...</td>\n",
              "      <td>91298</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1995</td>\n",
              "      <td>False</td>\n",
              "      <td>93.90</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "      <td>0.029286</td>\n",
              "      <td>63</td>\n",
              "      <td>0.428710</td>\n",
              "      <td>63</td>\n",
              "      <td>0.044333</td>\n",
              "      <td>68</td>\n",
              "      <td>0.060968</td>\n",
              "      <td>72</td>\n",
              "      <td>0.034667</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80</td>\n",
              "      <td>160.40</td>\n",
              "      <td>161</td>\n",
              "      <td>215.4</td>\n",
              "      <td>233</td>\n",
              "      <td>30.15</td>\n",
              "      <td>25</td>\n",
              "      <td>216.10</td>\n",
              "      <td>219</td>\n",
              "      <td>60.15</td>\n",
              "      <td>36</td>\n",
              "      <td>117.25</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>5.80206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>317.75</td>\n",
              "      <td>340</td>\n",
              "      <td>408.60</td>\n",
              "      <td>401</td>\n",
              "      <td>57.90</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>Los Carneros</td>\n",
              "      <td>Joseph Phelps Vineyards, Carneros Chardonnay, ...</td>\n",
              "      <td>89562</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1996</td>\n",
              "      <td>False</td>\n",
              "      <td>86.86</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "      <td>0.368800</td>\n",
              "      <td>52</td>\n",
              "      <td>0.087500</td>\n",
              "      <td>54</td>\n",
              "      <td>0.127000</td>\n",
              "      <td>56</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>64</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>63</td>\n",
              "      <td>0.062581</td>\n",
              "      <td>60</td>\n",
              "      <td>158.50</td>\n",
              "      <td>160</td>\n",
              "      <td>218.4</td>\n",
              "      <td>224</td>\n",
              "      <td>80.25</td>\n",
              "      <td>60</td>\n",
              "      <td>196.15</td>\n",
              "      <td>190</td>\n",
              "      <td>60.85</td>\n",
              "      <td>35</td>\n",
              "      <td>118.15</td>\n",
              "      <td>37</td>\n",
              "      <td>34</td>\n",
              "      <td>5.60206</td>\n",
              "      <td>6.2</td>\n",
              "      <td>353.05</td>\n",
              "      <td>365</td>\n",
              "      <td>362.85</td>\n",
              "      <td>391</td>\n",
              "      <td>63.50</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>731</th>\n",
              "      <td>Sonoma County</td>\n",
              "      <td>Ferrari-Carano, Fume Blanc, White, Sonoma County</td>\n",
              "      <td>73121</td>\n",
              "      <td>White</td>\n",
              "      <td>California</td>\n",
              "      <td>Usa</td>\n",
              "      <td>1993</td>\n",
              "      <td>False</td>\n",
              "      <td>88.14</td>\n",
              "      <td>B+</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>145.00</td>\n",
              "      <td>150</td>\n",
              "      <td>184.4</td>\n",
              "      <td>190</td>\n",
              "      <td>105.50</td>\n",
              "      <td>110</td>\n",
              "      <td>262.80</td>\n",
              "      <td>298</td>\n",
              "      <td>84.70</td>\n",
              "      <td>36</td>\n",
              "      <td>121.60</td>\n",
              "      <td>29</td>\n",
              "      <td>55</td>\n",
              "      <td>5.20206</td>\n",
              "      <td>5.7</td>\n",
              "      <td>352.40</td>\n",
              "      <td>337</td>\n",
              "      <td>371.65</td>\n",
              "      <td>346</td>\n",
              "      <td>110.95</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>732 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              appellation  ... quality\n",
              "0    Santa Cruz Mountains  ...       1\n",
              "1             Napa Valley  ...       1\n",
              "2            Sonoma Coast  ...       1\n",
              "3            Sonoma Coast  ...       1\n",
              "4             Napa Valley  ...       1\n",
              "..                    ...  ...     ...\n",
              "727              Carneros  ...       0\n",
              "728         Sonoma County  ...       1\n",
              "729              Carneros  ...       1\n",
              "730          Los Carneros  ...       0\n",
              "731         Sonoma County  ...       0\n",
              "\n",
              "[732 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FBb4KAPO596",
        "outputId": "ad0bd28d-a22d-470c-affd-72c34b5e4082",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Generate our categorical variable list\n",
        "White_Wine_cat = White_Soil_ML_df.dtypes[White_Soil_ML_df.dtypes == \"object\"].index.tolist()\n",
        "\n",
        "# Check the number of unique values in each column\n",
        "White_Soil_ML_df[White_Wine_cat].nunique()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "appellation          22\n",
              "wine                163\n",
              "color                 1\n",
              "regions               3\n",
              "country               1\n",
              "confidence_index      6\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4mB3r6TO598",
        "outputId": "7a7c3dae-eced-4ccf-f09f-8b165a60ca85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the unique value counts to see if binning is required for Appellation\n",
        "Appellation_Count = White_Soil_ML_df.appellation.value_counts()\n",
        "Appellation_Count.head(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Napa Valley             229\n",
              "Carneros                112\n",
              "Russian River Valley     92\n",
              "Sonoma County            80\n",
              "Knights Valley           49\n",
              "Sonoma Coast             37\n",
              "Sonoma Mountain          29\n",
              "Santa Cruz Mountains     19\n",
              "Columbia Valley          17\n",
              "Eola-Amity Hills         13\n",
              "Name: appellation, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg62g5TjO5-A",
        "outputId": "08d5e2f7-4623-4d27-b85b-86fd3092ec6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Visualize the Appellation_Count\n",
        "Appellation_Count.plot.density()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6d70d15a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pTwMSKWO5-C"
      },
      "source": [
        "# Determine which values to replace for \n",
        "Appellation_Bin =  list(Appellation_Count[Appellation_Count < 200].index)\n",
        "# Replace in DataFrame\n",
        "for type in Appellation_Bin:\n",
        "    White_Soil_ML_df.appellation = White_Soil_ML_df.appellation.replace(type,\"Other\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55cb4HnEO5-G",
        "outputId": "2862ae84-1586-49cb-d4a3-2036bc4a9445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check to make sure binning was successful for Appellation\n",
        "White_Soil_ML_df.appellation.value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Other          503\n",
              "Napa Valley    229\n",
              "Name: appellation, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoMqlVkUO5-I"
      },
      "source": [
        "# White_Soil_ML_df[White_Soil_ML_df.appellation != 'Other']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLCf6JriO5-L",
        "outputId": "f9a4fe55-5910-46e3-90b9-48cbce35f0b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "# Create the OneHotEncoder instance\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit the encoder and produce encoded DataFrame\n",
        "White_Wine_encode_df = pd.DataFrame(enc.fit_transform(White_Soil_ML_df[White_Wine_cat]))\n",
        "\n",
        "# Rename encoded columns\n",
        "White_Wine_encode_df.columns = enc.get_feature_names(White_Wine_cat)\n",
        "White_Wine_encode_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appellation_Napa Valley</th>\n",
              "      <th>appellation_Other</th>\n",
              "      <th>wine_Alpha Omega, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Alpha Omega, Reserve Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Apsara Cellars, 'Rivers Reach' Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Araujo Estate, Eisele Vineyard Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Aubert Wines, Hudson Vineyard Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Aubert Wines, Larry Hyde &amp; Sons Vineyard Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Aubert Wines, Ritchie Vineyard Chardonnay, White, Sonoma Coast</th>\n",
              "      <th>wine_Aubert Wines, Sugar Shack Estate Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Aubert Wines, Uv-Sl Vineyards Chardonnay, White, Sonoma Coast</th>\n",
              "      <th>wine_Beaulieu Vineyard Bv, Reserve Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Beringer Vineyards, 'Luminus' Chardonnay, White, Oak Knoll District</th>\n",
              "      <th>wine_Beringer Vineyards, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Beringer Vineyards, Private Reserve Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Cakebread Cellars, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Cakebread Cellars, Reserve Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Cakebread Cellars, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Chappellet, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Charles Krug Peter Mondavi Family, Sauvignon Blanc, White, St Helena</th>\n",
              "      <th>wine_Chateau Montelena, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Cliff Lede Vineyards, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Clos Du Val, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Clos Du Val, Winemaker'S Signature Series Three Graces White Blend, White, Napa Valley</th>\n",
              "      <th>wine_Crossbarn By Paul Hobbs, Chardonnay, White, Sonoma Coast</th>\n",
              "      <th>wine_Cuvaison, Ats Selection Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Cuvaison, Carneros Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Delille Cellars, Chaleur Estate Blanc, White, Columbia Valley</th>\n",
              "      <th>wine_Delille Cellars, Doyenne Metier Blanc, White, Red Mountain</th>\n",
              "      <th>wine_Delille Cellars, Doyenne Roussanne, White, Red Mountain</th>\n",
              "      <th>wine_Domaine Serene, 'Dijon Clones - Cote Sud Vineyard' Chardonnay, White, Willamette Valley</th>\n",
              "      <th>wine_Domaine Serene, 'Evenstad Reserve' Chardonnay, White, Dundee Hills</th>\n",
              "      <th>wine_Domaine Serene, Clos Du Soleil Vineyard Chardonnay, White, Dundee Hills</th>\n",
              "      <th>wine_Domaine Serene, Etoile Vineyard Chardonnay, White, Dundee Hills</th>\n",
              "      <th>wine_Duckhorn Vineyards, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Duckhorn Vineyards, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Dumol, Clare Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Etude, Grace Benoist Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Etude, Pinot Gris, White, Carneros</th>\n",
              "      <th>wine_Evening Land, Gold Label Seven Springs Vineyard Chardonnay, White, Eola-Amity Hills</th>\n",
              "      <th>...</th>\n",
              "      <th>wine_Robert Foley Vineyards, Pinot Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Robert Mondavi Winery, Carneros Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Robert Mondavi Winery, Napa Valley Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Rombauer Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Rudd, Bacigalupi Vineyard Chardonnay, White, Russian River Valley</th>\n",
              "      <th>wine_Rudd, Mount Veeder Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Saintsbury, Brown Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Saintsbury, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Saintsbury, Reserve Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Screaming Eagle, Sauvignon Blanc, White, Oakville</th>\n",
              "      <th>wine_Shafer Vineyards, Red Shoulder Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards Estate, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards, 'Vineburg Vineyard' Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards, Miller Ranch Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Smith Madrone, Riesling, White, Spring Mountain District</th>\n",
              "      <th>wine_Spottswoode, Sauvignon Blanc, White, Napa County</th>\n",
              "      <th>wine_St. Clement Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Arcadia Vineyard Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Aveta Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Karia Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Stags' Leap Winery, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Trefethen Family Vineyards, Chardonnay, White, Oak Knoll District</th>\n",
              "      <th>wine_Truchard Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Truchard Vineyards, Roussanne, White, Carneros</th>\n",
              "      <th>wine_Turnbull Wine Cellars, Sauvignon Blanc, White, Oakville</th>\n",
              "      <th>wine_Twomey Cellars, Sauvignon Blanc, White, Napa County</th>\n",
              "      <th>wine_Venge Vineyards, Maldonado Vineyard Dijon Clones Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Vine Cliff Winery, Chardonnay, White, Los Carneros</th>\n",
              "      <th>color_White</th>\n",
              "      <th>regions_California</th>\n",
              "      <th>regions_Oregon</th>\n",
              "      <th>regions_Washington</th>\n",
              "      <th>country_Usa</th>\n",
              "      <th>confidence_index_A</th>\n",
              "      <th>confidence_index_A+</th>\n",
              "      <th>confidence_index_B</th>\n",
              "      <th>confidence_index_B+</th>\n",
              "      <th>confidence_index_C</th>\n",
              "      <th>confidence_index_C+</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 176 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   appellation_Napa Valley  ...  confidence_index_C+\n",
              "0                      0.0  ...                  0.0\n",
              "1                      1.0  ...                  1.0\n",
              "2                      0.0  ...                  0.0\n",
              "3                      0.0  ...                  0.0\n",
              "4                      1.0  ...                  0.0\n",
              "\n",
              "[5 rows x 176 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF4QT7qzO5-N",
        "outputId": "0f7f9a56-a631-4082-8683-4b0c7a92d5d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "# Merge one-hot encoded features and drop the originals\n",
        "White_Soil_ML_df = White_Soil_ML_df.merge(White_Wine_encode_df,left_index=True, right_index=True)\n",
        "White_Soil_ML_df = White_Soil_ML_df.drop(White_Wine_cat,1)\n",
        "White_Soil_ML_df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wine_id</th>\n",
              "      <th>vintage</th>\n",
              "      <th>is_primeurs</th>\n",
              "      <th>score</th>\n",
              "      <th>journalist_count</th>\n",
              "      <th>avgPrcpFebruary</th>\n",
              "      <th>avgTempFebruary</th>\n",
              "      <th>avgPrcpMarch</th>\n",
              "      <th>avgTempMarch</th>\n",
              "      <th>avgPrcpApril</th>\n",
              "      <th>avgTempApril</th>\n",
              "      <th>avgPrcpMay</th>\n",
              "      <th>avgTempMay</th>\n",
              "      <th>avgPrcpJune</th>\n",
              "      <th>avgTempJune</th>\n",
              "      <th>avgPrcpJuly</th>\n",
              "      <th>avgTempJuly</th>\n",
              "      <th>avgPrcpAugust</th>\n",
              "      <th>avgTempAugust</th>\n",
              "      <th>avgPrcpSeptember</th>\n",
              "      <th>avgTempSeptember</th>\n",
              "      <th>avgPrcpOctober</th>\n",
              "      <th>avgTempOctober</th>\n",
              "      <th>bdod_0-100cm</th>\n",
              "      <th>bdod_100-200cm</th>\n",
              "      <th>cec_0-100cm</th>\n",
              "      <th>cec_100-200cm</th>\n",
              "      <th>cfvo_0-100cm</th>\n",
              "      <th>cfvo_100-200cm</th>\n",
              "      <th>clay_0-100cm</th>\n",
              "      <th>clay_100-200cm</th>\n",
              "      <th>nitrogen_0-100cm</th>\n",
              "      <th>nitrogen_100-200cm</th>\n",
              "      <th>ocd_0-100cm</th>\n",
              "      <th>ocd_100-200cm</th>\n",
              "      <th>ocs_0-30cm</th>\n",
              "      <th>phh2o_0-100cm</th>\n",
              "      <th>phh2o_100-200cm</th>\n",
              "      <th>sand_0-100cm</th>\n",
              "      <th>sand_100-200cm</th>\n",
              "      <th>...</th>\n",
              "      <th>wine_Robert Foley Vineyards, Pinot Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Robert Mondavi Winery, Carneros Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Robert Mondavi Winery, Napa Valley Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Rombauer Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Rudd, Bacigalupi Vineyard Chardonnay, White, Russian River Valley</th>\n",
              "      <th>wine_Rudd, Mount Veeder Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Saintsbury, Brown Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Saintsbury, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Saintsbury, Reserve Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Screaming Eagle, Sauvignon Blanc, White, Oakville</th>\n",
              "      <th>wine_Shafer Vineyards, Red Shoulder Ranch Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards Estate, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards, 'Vineburg Vineyard' Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Silverado Vineyards, Miller Ranch Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Smith Madrone, Riesling, White, Spring Mountain District</th>\n",
              "      <th>wine_Spottswoode, Sauvignon Blanc, White, Napa County</th>\n",
              "      <th>wine_St. Clement Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Arcadia Vineyard Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Aveta Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Karia Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Stag'S Leap Wine Cellars, Sauvignon Blanc, White, Napa Valley</th>\n",
              "      <th>wine_Stags' Leap Winery, Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Trefethen Family Vineyards, Chardonnay, White, Oak Knoll District</th>\n",
              "      <th>wine_Truchard Vineyards, Chardonnay, White, Carneros</th>\n",
              "      <th>wine_Truchard Vineyards, Roussanne, White, Carneros</th>\n",
              "      <th>wine_Turnbull Wine Cellars, Sauvignon Blanc, White, Oakville</th>\n",
              "      <th>wine_Twomey Cellars, Sauvignon Blanc, White, Napa County</th>\n",
              "      <th>wine_Venge Vineyards, Maldonado Vineyard Dijon Clones Chardonnay, White, Napa Valley</th>\n",
              "      <th>wine_Vine Cliff Winery, Chardonnay, White, Los Carneros</th>\n",
              "      <th>color_White</th>\n",
              "      <th>regions_California</th>\n",
              "      <th>regions_Oregon</th>\n",
              "      <th>regions_Washington</th>\n",
              "      <th>country_Usa</th>\n",
              "      <th>confidence_index_A</th>\n",
              "      <th>confidence_index_A+</th>\n",
              "      <th>confidence_index_B</th>\n",
              "      <th>confidence_index_B+</th>\n",
              "      <th>confidence_index_C</th>\n",
              "      <th>confidence_index_C+</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>107658</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.22</td>\n",
              "      <td>4</td>\n",
              "      <td>0.174747</td>\n",
              "      <td>58</td>\n",
              "      <td>0.018630</td>\n",
              "      <td>60</td>\n",
              "      <td>0.096254</td>\n",
              "      <td>59</td>\n",
              "      <td>0.002989</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>65</td>\n",
              "      <td>0.001132</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000947</td>\n",
              "      <td>70</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>68</td>\n",
              "      <td>0.005581</td>\n",
              "      <td>66</td>\n",
              "      <td>139.75</td>\n",
              "      <td>149</td>\n",
              "      <td>153.4</td>\n",
              "      <td>145</td>\n",
              "      <td>183.5</td>\n",
              "      <td>245</td>\n",
              "      <td>197.50</td>\n",
              "      <td>193</td>\n",
              "      <td>145.7</td>\n",
              "      <td>60</td>\n",
              "      <td>124.95</td>\n",
              "      <td>25</td>\n",
              "      <td>60</td>\n",
              "      <td>5.50206</td>\n",
              "      <td>5.9</td>\n",
              "      <td>442.10</td>\n",
              "      <td>468</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>111897</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>92.83</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.5</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.6</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101640</td>\n",
              "      <td>1993</td>\n",
              "      <td>False</td>\n",
              "      <td>92.07</td>\n",
              "      <td>3</td>\n",
              "      <td>0.275357</td>\n",
              "      <td>58</td>\n",
              "      <td>0.086129</td>\n",
              "      <td>67</td>\n",
              "      <td>0.050667</td>\n",
              "      <td>68</td>\n",
              "      <td>0.068929</td>\n",
              "      <td>73</td>\n",
              "      <td>0.029333</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85</td>\n",
              "      <td>0.058710</td>\n",
              "      <td>77</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.5</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.5</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>101640</td>\n",
              "      <td>1998</td>\n",
              "      <td>False</td>\n",
              "      <td>91.74</td>\n",
              "      <td>4</td>\n",
              "      <td>0.674643</td>\n",
              "      <td>57</td>\n",
              "      <td>0.074516</td>\n",
              "      <td>64</td>\n",
              "      <td>0.060345</td>\n",
              "      <td>68</td>\n",
              "      <td>0.125806</td>\n",
              "      <td>67</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>76</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>83</td>\n",
              "      <td>0.027419</td>\n",
              "      <td>75</td>\n",
              "      <td>145.70</td>\n",
              "      <td>156</td>\n",
              "      <td>180.8</td>\n",
              "      <td>198</td>\n",
              "      <td>39.5</td>\n",
              "      <td>55</td>\n",
              "      <td>200.65</td>\n",
              "      <td>205</td>\n",
              "      <td>77.5</td>\n",
              "      <td>36</td>\n",
              "      <td>121.65</td>\n",
              "      <td>24</td>\n",
              "      <td>52</td>\n",
              "      <td>5.40206</td>\n",
              "      <td>5.8</td>\n",
              "      <td>441.75</td>\n",
              "      <td>477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91591</td>\n",
              "      <td>2015</td>\n",
              "      <td>False</td>\n",
              "      <td>97.27</td>\n",
              "      <td>4</td>\n",
              "      <td>0.176970</td>\n",
              "      <td>56</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>57</td>\n",
              "      <td>0.101661</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>140.80</td>\n",
              "      <td>150</td>\n",
              "      <td>290.2</td>\n",
              "      <td>289</td>\n",
              "      <td>153.5</td>\n",
              "      <td>150</td>\n",
              "      <td>282.55</td>\n",
              "      <td>273</td>\n",
              "      <td>72.6</td>\n",
              "      <td>40</td>\n",
              "      <td>109.20</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>5.90206</td>\n",
              "      <td>6.4</td>\n",
              "      <td>203.00</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 221 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   wine_id  vintage  ...  confidence_index_C  confidence_index_C+\n",
              "0   107658     2015  ...                 0.0                  0.0\n",
              "1   111897     2015  ...                 0.0                  1.0\n",
              "2   101640     1993  ...                 1.0                  0.0\n",
              "3   101640     1998  ...                 0.0                  0.0\n",
              "4    91591     2015  ...                 0.0                  0.0\n",
              "\n",
              "[5 rows x 221 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uPm_kDc8Fon"
      },
      "source": [
        "## ***Wine Only - Drop All weather and soil columns***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCbZATbmO5-Q"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = White_Soil_ML_df[\"quality\"].values\n",
        "X = White_Soil_ML_df.drop([\"quality\", \"is_primeurs\", \"journalist_count\", \"confidence_index_A\",\"confidence_index_A+\", \"confidence_index_B\", \"confidence_index_B+\",\"confidence_index_C\", \"confidence_index_C+\", 'avgPrcpFebruary',\n",
        " 'avgTempFebruary',\n",
        " 'avgPrcpMarch',\n",
        " 'avgTempMarch',\n",
        " 'avgPrcpApril',\n",
        " 'avgTempApril',\n",
        " 'avgPrcpMay',\n",
        " 'avgTempMay',\n",
        " 'avgPrcpJune',\n",
        " 'avgTempJune',\n",
        " 'avgPrcpJuly',\n",
        " 'avgTempJuly',\n",
        " 'avgPrcpAugust',\n",
        " 'avgTempAugust',\n",
        " 'avgPrcpSeptember',\n",
        " 'avgTempSeptember',\n",
        " 'avgPrcpOctober',\n",
        " 'avgTempOctober',\n",
        " 'bdod_0-100cm',\n",
        " 'bdod_100-200cm',\n",
        " 'cec_0-100cm',\n",
        " 'cec_100-200cm',\n",
        " 'cfvo_0-100cm',\n",
        " 'cfvo_100-200cm',\n",
        " 'clay_0-100cm',\n",
        " 'clay_100-200cm',\n",
        " 'nitrogen_0-100cm',\n",
        " 'nitrogen_100-200cm',\n",
        " 'ocd_0-100cm',\n",
        " 'ocd_100-200cm',\n",
        " 'ocs_0-30cm',\n",
        " 'phh2o_0-100cm',\n",
        " 'phh2o_100-200cm',\n",
        " 'sand_0-100cm',\n",
        " 'sand_100-200cm',\n",
        " 'silt_0-100cm',\n",
        " 'silt_100-200cm',\n",
        " 'soc_0-100cm',\n",
        " 'soc_100-200cm'],1).values"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcVEIlvIO5-S"
      },
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X)\n",
        "X_scaled = X_scaler.transform(X)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE4Fr6BaJ-Ep"
      },
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, random_state=45)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G73C39aiO5-V"
      },
      "source": [
        "###***Deep Learning Neural Netwrok for training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u7Lvg2HO5-V",
        "outputId": "5f329d7a-7eb4-43ae-fd0d-6e5f6a92e816",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[-1])\n",
        "hidden_nodes_layer1 =  24\n",
        "hidden_nodes_layer2 = 12\n",
        "\n",
        "# metrics = [\n",
        "#     tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "#     tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "#     tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "#     tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "#     tf.keras.metrics.Precision(name=\"precision\"),\n",
        "#     tf.keras.metrics.Recall(name=\"recall\"),\n",
        "# ]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.5,verbose=2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 - 0s - loss: 0.8455 - accuracy: 0.5036 - val_loss: 0.8186 - val_accuracy: 0.5673\n",
            "Epoch 2/50\n",
            "9/9 - 0s - loss: 0.7276 - accuracy: 0.5657 - val_loss: 0.7628 - val_accuracy: 0.5964\n",
            "Epoch 3/50\n",
            "9/9 - 0s - loss: 0.6459 - accuracy: 0.6350 - val_loss: 0.7224 - val_accuracy: 0.5855\n",
            "Epoch 4/50\n",
            "9/9 - 0s - loss: 0.5874 - accuracy: 0.7007 - val_loss: 0.6868 - val_accuracy: 0.6036\n",
            "Epoch 5/50\n",
            "9/9 - 0s - loss: 0.5393 - accuracy: 0.7591 - val_loss: 0.6526 - val_accuracy: 0.6436\n",
            "Epoch 6/50\n",
            "9/9 - 0s - loss: 0.4981 - accuracy: 0.7920 - val_loss: 0.6247 - val_accuracy: 0.6691\n",
            "Epoch 7/50\n",
            "9/9 - 0s - loss: 0.4645 - accuracy: 0.8175 - val_loss: 0.5998 - val_accuracy: 0.7127\n",
            "Epoch 8/50\n",
            "9/9 - 0s - loss: 0.4335 - accuracy: 0.8467 - val_loss: 0.5783 - val_accuracy: 0.7164\n",
            "Epoch 9/50\n",
            "9/9 - 0s - loss: 0.4066 - accuracy: 0.8540 - val_loss: 0.5592 - val_accuracy: 0.7200\n",
            "Epoch 10/50\n",
            "9/9 - 0s - loss: 0.3834 - accuracy: 0.8504 - val_loss: 0.5421 - val_accuracy: 0.7200\n",
            "Epoch 11/50\n",
            "9/9 - 0s - loss: 0.3611 - accuracy: 0.8504 - val_loss: 0.5257 - val_accuracy: 0.7200\n",
            "Epoch 12/50\n",
            "9/9 - 0s - loss: 0.3409 - accuracy: 0.8577 - val_loss: 0.5125 - val_accuracy: 0.7382\n",
            "Epoch 13/50\n",
            "9/9 - 0s - loss: 0.3226 - accuracy: 0.8796 - val_loss: 0.4994 - val_accuracy: 0.7418\n",
            "Epoch 14/50\n",
            "9/9 - 0s - loss: 0.3061 - accuracy: 0.8796 - val_loss: 0.4860 - val_accuracy: 0.7455\n",
            "Epoch 15/50\n",
            "9/9 - 0s - loss: 0.2902 - accuracy: 0.8942 - val_loss: 0.4755 - val_accuracy: 0.7564\n",
            "Epoch 16/50\n",
            "9/9 - 0s - loss: 0.2761 - accuracy: 0.8978 - val_loss: 0.4668 - val_accuracy: 0.7636\n",
            "Epoch 17/50\n",
            "9/9 - 0s - loss: 0.2630 - accuracy: 0.9051 - val_loss: 0.4602 - val_accuracy: 0.7636\n",
            "Epoch 18/50\n",
            "9/9 - 0s - loss: 0.2514 - accuracy: 0.9088 - val_loss: 0.4526 - val_accuracy: 0.7636\n",
            "Epoch 19/50\n",
            "9/9 - 0s - loss: 0.2412 - accuracy: 0.9051 - val_loss: 0.4459 - val_accuracy: 0.7600\n",
            "Epoch 20/50\n",
            "9/9 - 0s - loss: 0.2304 - accuracy: 0.9124 - val_loss: 0.4408 - val_accuracy: 0.7745\n",
            "Epoch 21/50\n",
            "9/9 - 0s - loss: 0.2214 - accuracy: 0.9161 - val_loss: 0.4358 - val_accuracy: 0.7855\n",
            "Epoch 22/50\n",
            "9/9 - 0s - loss: 0.2131 - accuracy: 0.9197 - val_loss: 0.4315 - val_accuracy: 0.7964\n",
            "Epoch 23/50\n",
            "9/9 - 0s - loss: 0.2056 - accuracy: 0.9197 - val_loss: 0.4269 - val_accuracy: 0.8036\n",
            "Epoch 24/50\n",
            "9/9 - 0s - loss: 0.1980 - accuracy: 0.9234 - val_loss: 0.4226 - val_accuracy: 0.8073\n",
            "Epoch 25/50\n",
            "9/9 - 0s - loss: 0.1924 - accuracy: 0.9234 - val_loss: 0.4181 - val_accuracy: 0.8073\n",
            "Epoch 26/50\n",
            "9/9 - 0s - loss: 0.1860 - accuracy: 0.9197 - val_loss: 0.4158 - val_accuracy: 0.8109\n",
            "Epoch 27/50\n",
            "9/9 - 0s - loss: 0.1786 - accuracy: 0.9270 - val_loss: 0.4139 - val_accuracy: 0.8145\n",
            "Epoch 28/50\n",
            "9/9 - 0s - loss: 0.1723 - accuracy: 0.9270 - val_loss: 0.4118 - val_accuracy: 0.8182\n",
            "Epoch 29/50\n",
            "9/9 - 0s - loss: 0.1673 - accuracy: 0.9380 - val_loss: 0.4091 - val_accuracy: 0.8182\n",
            "Epoch 30/50\n",
            "9/9 - 0s - loss: 0.1619 - accuracy: 0.9380 - val_loss: 0.4065 - val_accuracy: 0.8255\n",
            "Epoch 31/50\n",
            "9/9 - 0s - loss: 0.1577 - accuracy: 0.9416 - val_loss: 0.4050 - val_accuracy: 0.8291\n",
            "Epoch 32/50\n",
            "9/9 - 0s - loss: 0.1529 - accuracy: 0.9489 - val_loss: 0.4043 - val_accuracy: 0.8218\n",
            "Epoch 33/50\n",
            "9/9 - 0s - loss: 0.1475 - accuracy: 0.9562 - val_loss: 0.4036 - val_accuracy: 0.8255\n",
            "Epoch 34/50\n",
            "9/9 - 0s - loss: 0.1433 - accuracy: 0.9562 - val_loss: 0.4035 - val_accuracy: 0.8291\n",
            "Epoch 35/50\n",
            "9/9 - 0s - loss: 0.1395 - accuracy: 0.9599 - val_loss: 0.4014 - val_accuracy: 0.8327\n",
            "Epoch 36/50\n",
            "9/9 - 0s - loss: 0.1349 - accuracy: 0.9635 - val_loss: 0.3996 - val_accuracy: 0.8364\n",
            "Epoch 37/50\n",
            "9/9 - 0s - loss: 0.1304 - accuracy: 0.9599 - val_loss: 0.3979 - val_accuracy: 0.8364\n",
            "Epoch 38/50\n",
            "9/9 - 0s - loss: 0.1266 - accuracy: 0.9635 - val_loss: 0.3975 - val_accuracy: 0.8436\n",
            "Epoch 39/50\n",
            "9/9 - 0s - loss: 0.1220 - accuracy: 0.9672 - val_loss: 0.3972 - val_accuracy: 0.8473\n",
            "Epoch 40/50\n",
            "9/9 - 0s - loss: 0.1187 - accuracy: 0.9599 - val_loss: 0.3950 - val_accuracy: 0.8473\n",
            "Epoch 41/50\n",
            "9/9 - 0s - loss: 0.1157 - accuracy: 0.9562 - val_loss: 0.3945 - val_accuracy: 0.8473\n",
            "Epoch 42/50\n",
            "9/9 - 0s - loss: 0.1115 - accuracy: 0.9599 - val_loss: 0.3948 - val_accuracy: 0.8473\n",
            "Epoch 43/50\n",
            "9/9 - 0s - loss: 0.1078 - accuracy: 0.9599 - val_loss: 0.3939 - val_accuracy: 0.8473\n",
            "Epoch 44/50\n",
            "9/9 - 0s - loss: 0.1052 - accuracy: 0.9672 - val_loss: 0.3925 - val_accuracy: 0.8436\n",
            "Epoch 45/50\n",
            "9/9 - 0s - loss: 0.1012 - accuracy: 0.9708 - val_loss: 0.3929 - val_accuracy: 0.8473\n",
            "Epoch 46/50\n",
            "9/9 - 0s - loss: 0.0984 - accuracy: 0.9708 - val_loss: 0.3933 - val_accuracy: 0.8400\n",
            "Epoch 47/50\n",
            "9/9 - 0s - loss: 0.0958 - accuracy: 0.9708 - val_loss: 0.3913 - val_accuracy: 0.8436\n",
            "Epoch 48/50\n",
            "9/9 - 0s - loss: 0.0931 - accuracy: 0.9708 - val_loss: 0.3913 - val_accuracy: 0.8400\n",
            "Epoch 49/50\n",
            "9/9 - 0s - loss: 0.0902 - accuracy: 0.9745 - val_loss: 0.3924 - val_accuracy: 0.8327\n",
            "Epoch 50/50\n",
            "9/9 - 0s - loss: 0.0886 - accuracy: 0.9745 - val_loss: 0.3922 - val_accuracy: 0.8364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rYkzjY0Jpn4",
        "outputId": "bc1c718e-9e8b-4edb-9e96-19ba0db66013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "tf.keras.utils.plot_model(nn, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw6xMQP-O5-X"
      },
      "source": [
        "###***Deep Learning Neural Netwrok Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-6Z3XUQsali",
        "outputId": "18a11c74-7773-4c70-8a7a-74c4e0e5ef08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.7541\n",
            "Loss: 0.6879385709762573, Accuracy: 0.7540983557701111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uQLqejXO5-Z"
      },
      "source": [
        "# # Evaluate the model using the test data\n",
        "# model_loss, FalseNegatives,FalsePositives, TrueNegatives, TruePositives, Precision, Recall = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "# print(f\"\"\"\\t  Loss: {model_loss},\n",
        "#           FalseNegatives: {FalseNegatives},\n",
        "#           FalsePositives: {FalsePositives},\n",
        "#           TrueNegatives: {TrueNegatives},\n",
        "#           TruePositives: {TruePositives},\n",
        "#           Precision: {Precision},\n",
        "#           Recall: {Recall},\"\"\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qdKZ89DiBfB",
        "outputId": "0b93338d-5a0a-40bd-984d-8c5e2c22dcd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = nn.predict(X_test_scaled)\n",
        "adjusted_predictions = [(100 * x[0]) for x in predictions]\n",
        "adjusted_predictions"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4835476875305176,\n",
              " 0.07703602313995361,\n",
              " 69.29945945739746,\n",
              " 0.05128979682922363,\n",
              " 0.22085905075073242,\n",
              " 99.98170137405396,\n",
              " 92.97350645065308,\n",
              " 42.05390810966492,\n",
              " 59.36252474784851,\n",
              " 12.79757022857666,\n",
              " 0.03257095813751221,\n",
              " 58.124178647994995,\n",
              " 94.3682610988617,\n",
              " 43.0270254611969,\n",
              " 5.711886286735535,\n",
              " 0.0023514481654274277,\n",
              " 71.32728099822998,\n",
              " 97.96807765960693,\n",
              " 3.5053223371505737,\n",
              " 95.56105732917786,\n",
              " 50.37722587585449,\n",
              " 95.37705183029175,\n",
              " 12.711238861083984,\n",
              " 1.6170889139175415,\n",
              " 96.30218148231506,\n",
              " 51.63050889968872,\n",
              " 99.52477216720581,\n",
              " 80.93265295028687,\n",
              " 46.289852261543274,\n",
              " 0.015917420387268066,\n",
              " 0.18815398216247559,\n",
              " 99.79380369186401,\n",
              " 0.14780163764953613,\n",
              " 25.289276242256165,\n",
              " 5.9810250997543335,\n",
              " 0.0597149133682251,\n",
              " 99.92300271987915,\n",
              " 99.96616840362549,\n",
              " 99.96033906936646,\n",
              " 0.07332265377044678,\n",
              " 34.566107392311096,\n",
              " 0.0021940220904070884,\n",
              " 19.673889875411987,\n",
              " 24.55814480781555,\n",
              " 3.3669233322143555,\n",
              " 99.94915723800659,\n",
              " 0.3693908452987671,\n",
              " 26.224350929260254,\n",
              " 9.061470627784729,\n",
              " 99.72978830337524,\n",
              " 3.3217251300811768,\n",
              " 81.6593587398529,\n",
              " 99.23834800720215,\n",
              " 6.715843081474304,\n",
              " 99.39700961112976,\n",
              " 0.17714202404022217,\n",
              " 99.08525943756104,\n",
              " 6.569153070449829,\n",
              " 99.7796356678009,\n",
              " 98.21722507476807,\n",
              " 99.53473806381226,\n",
              " 0.03721415996551514,\n",
              " 97.1549928188324,\n",
              " 0.22515356540679932,\n",
              " 35.39988994598389,\n",
              " 48.01376163959503,\n",
              " 39.84915614128113,\n",
              " 94.65023875236511,\n",
              " 91.54901504516602,\n",
              " 22.259145975112915,\n",
              " 0.6512194871902466,\n",
              " 99.98046159744263,\n",
              " 3.2799571752548218,\n",
              " 99.32581186294556,\n",
              " 0.20945072174072266,\n",
              " 92.73262619972229,\n",
              " 1.951327919960022,\n",
              " 96.00592851638794,\n",
              " 83.32828283309937,\n",
              " 98.14399480819702,\n",
              " 5.206272006034851,\n",
              " 0.16037523746490479,\n",
              " 1.4551401138305664,\n",
              " 96.95056676864624,\n",
              " 99.28832054138184,\n",
              " 0.6010204553604126,\n",
              " 0.08633732795715332,\n",
              " 15.963959693908691,\n",
              " 0.7145285606384277,\n",
              " 99.20909404754639,\n",
              " 96.36461734771729,\n",
              " 5.714631080627441,\n",
              " 0.005747419709223323,\n",
              " 99.18110370635986,\n",
              " 7.929116487503052,\n",
              " 5.231046676635742,\n",
              " 99.88400340080261,\n",
              " 0.19880235195159912,\n",
              " 99.93658065795898,\n",
              " 99.7112512588501,\n",
              " 0.014153122901916504,\n",
              " 99.99977350234985,\n",
              " 96.6109573841095,\n",
              " 61.81823015213013,\n",
              " 99.75711107254028,\n",
              " 72.85569310188293,\n",
              " 95.44968605041504,\n",
              " 9.544852375984192,\n",
              " 92.50192642211914,\n",
              " 2.0246297121047974,\n",
              " 75.01828670501709,\n",
              " 0.13827085494995117,\n",
              " 99.38162565231323,\n",
              " 3.7988364696502686,\n",
              " 99.87214803695679,\n",
              " 1.0307073593139648,\n",
              " 3.7715405225753784,\n",
              " 95.20865082740784,\n",
              " 0.022915005683898926,\n",
              " 0.4200965166091919,\n",
              " 2.4300336837768555,\n",
              " 23.352622985839844,\n",
              " 15.316838026046753,\n",
              " 0.27844011783599854,\n",
              " 99.9687910079956,\n",
              " 3.3226877450942993,\n",
              " 20.926901698112488,\n",
              " 0.17231106758117676,\n",
              " 0.3053605556488037,\n",
              " 97.74022102355957,\n",
              " 98.60836267471313,\n",
              " 99.61954355239868,\n",
              " 99.80200529098511,\n",
              " 0.28483569622039795,\n",
              " 99.82309341430664,\n",
              " 65.31929969787598,\n",
              " 99.97611045837402,\n",
              " 0.14744997024536133,\n",
              " 59.503161907196045,\n",
              " 0.01551210880279541,\n",
              " 40.28016924858093,\n",
              " 91.59249067306519,\n",
              " 99.97757077217102,\n",
              " 0.010122836829395965,\n",
              " 21.576660871505737,\n",
              " 99.13150072097778,\n",
              " 97.3183274269104,\n",
              " 45.44421434402466,\n",
              " 89.74665403366089,\n",
              " 1.5948623418807983,\n",
              " 90.7496452331543,\n",
              " 6.0232579708099365,\n",
              " 0.31748414039611816,\n",
              " 8.504849672317505,\n",
              " 1.353996992111206,\n",
              " 43.906036019325256,\n",
              " 9.555250406265259,\n",
              " 0.255054235458374,\n",
              " 1.053139567375183,\n",
              " 75.55679082870483,\n",
              " 1.1261194944381714,\n",
              " 17.942512035369873,\n",
              " 79.76377010345459,\n",
              " 4.511693120002747,\n",
              " 99.86305236816406,\n",
              " 99.79573488235474,\n",
              " 17.601308226585388,\n",
              " 51.12091898918152,\n",
              " 25.243830680847168,\n",
              " 0.4286438226699829,\n",
              " 78.2353401184082,\n",
              " 1.6632169485092163,\n",
              " 99.10335540771484,\n",
              " 0.1690983772277832,\n",
              " 9.230735898017883,\n",
              " 1.3956248760223389,\n",
              " 33.73233079910278,\n",
              " 99.85541105270386,\n",
              " 42.69186854362488,\n",
              " 8.668312430381775,\n",
              " 99.84976053237915,\n",
              " 95.35661935806274,\n",
              " 0.10553896427154541]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_6G4L1TO5-d"
      },
      "source": [
        "### ***Random Forest Classifier Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stnp4Ep3O5-d",
        "outputId": "36a1369c-eeee-4788-bf0f-cfba220e6ead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a random forest classifier.\n",
        "rf_model = RandomForestClassifier(n_estimators=256, random_state=32)\n",
        "\n",
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Random forest predictive accuracy: 1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_pG1RM0JDwr",
        "outputId": "5800d268-3cc2-4de2-afc3-5e76f87e55c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 75   0]\n",
            " [  0 108]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkIB9d0lslob"
      },
      "source": [
        "### ***Logistic Regression Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baU-hliossZ1"
      },
      "source": [
        "# Create a Logistic Regression Model\n",
        "classifier = LogisticRegression(solver='lbfgs',\n",
        "                                max_iter=200,\n",
        "                                random_state=1)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAiKwCp4suyg",
        "outputId": "2f28bbd9-4889-41fd-c323-cca094e3485a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit (train) or model using the training data\n",
        "classifier.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiOZe0KQtHm1",
        "outputId": "194aff07-ce9d-4e2e-da94-3ae6b7fcd279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
        "results.head(20)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Prediction  Actual\n",
              "0            0       0\n",
              "1            0       0\n",
              "2            1       1\n",
              "3            0       0\n",
              "4            0       0\n",
              "5            1       1\n",
              "6            1       1\n",
              "7            1       1\n",
              "8            1       1\n",
              "9            1       1\n",
              "10           0       0\n",
              "11           0       0\n",
              "12           1       1\n",
              "13           0       0\n",
              "14           0       0\n",
              "15           0       0\n",
              "16           1       0\n",
              "17           1       1\n",
              "18           1       1\n",
              "19           1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUKD1EJUtLhy",
        "outputId": "6fe0fad2-d075-476c-8381-d4286441705b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.907103825136612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp_KzZnUJQg_",
        "outputId": "7b4ccff9-7091-43ca-dee3-7e0ca432b12e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[68  7]\n",
            " [10 98]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QIUMu-a8ZDw"
      },
      "source": [
        "## ***Wine & Weather - Drop All soil columns***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl3c8lXV8ZDx"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = White_Soil_ML_df[\"quality\"].values\n",
        "X = White_Soil_ML_df.drop([\"quality\", \"is_primeurs\", \"journalist_count\", \"confidence_index_A\",\"confidence_index_A+\", \"confidence_index_B\", \"confidence_index_B+\",\"confidence_index_C\", \"confidence_index_C+\",'avgPrcpFebruary',\n",
        " 'bdod_0-100cm',\n",
        " 'bdod_100-200cm',\n",
        " 'cec_0-100cm',\n",
        " 'cec_100-200cm',\n",
        " 'cfvo_0-100cm',\n",
        " 'cfvo_100-200cm',\n",
        " 'clay_0-100cm',\n",
        " 'clay_100-200cm',\n",
        " 'nitrogen_0-100cm',\n",
        " 'nitrogen_100-200cm',\n",
        " 'ocd_0-100cm',\n",
        " 'ocd_100-200cm',\n",
        " 'ocs_0-30cm',\n",
        " 'phh2o_0-100cm',\n",
        " 'phh2o_100-200cm',\n",
        " 'sand_0-100cm',\n",
        " 'sand_100-200cm',\n",
        " 'silt_0-100cm',\n",
        " 'silt_100-200cm',\n",
        " 'soc_0-100cm',\n",
        " 'soc_100-200cm',],1).values"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgW_GLNG8ZD1"
      },
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X)\n",
        "X_scaled = X_scaler.transform(X)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naWidjg3K2Be"
      },
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, random_state=45)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDkDyjKx8ZD4"
      },
      "source": [
        "###***Deep Learning Neural Netwrok for training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbMo7m578ZD4",
        "outputId": "e4164878-acf3-4758-ee95-b4e8605bd81c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[-1])\n",
        "hidden_nodes_layer1 =  24\n",
        "hidden_nodes_layer2 = 12\n",
        "\n",
        "# metrics = [\n",
        "#     tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "#     tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "#     tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "#     tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "#     tf.keras.metrics.Precision(name=\"precision\"),\n",
        "#     tf.keras.metrics.Recall(name=\"recall\"),\n",
        "# ]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.5)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1.2744 - accuracy: 0.4854 - val_loss: 1.0271 - val_accuracy: 0.5418\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0292 - accuracy: 0.4854 - val_loss: 0.8997 - val_accuracy: 0.5527\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8424 - accuracy: 0.5182 - val_loss: 0.8144 - val_accuracy: 0.6073\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7354 - accuracy: 0.5876 - val_loss: 0.7514 - val_accuracy: 0.6509\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6607 - accuracy: 0.6423 - val_loss: 0.7079 - val_accuracy: 0.6873\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6004 - accuracy: 0.7117 - val_loss: 0.6756 - val_accuracy: 0.6909\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5587 - accuracy: 0.7482 - val_loss: 0.6475 - val_accuracy: 0.6945\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5227 - accuracy: 0.7701 - val_loss: 0.6224 - val_accuracy: 0.7236\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7920 - val_loss: 0.5992 - val_accuracy: 0.7455\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7993 - val_loss: 0.5772 - val_accuracy: 0.7564\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.8175 - val_loss: 0.5572 - val_accuracy: 0.7673\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8504 - val_loss: 0.5384 - val_accuracy: 0.7855\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.8759 - val_loss: 0.5215 - val_accuracy: 0.8109\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8832 - val_loss: 0.5066 - val_accuracy: 0.8145\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.9051 - val_loss: 0.4911 - val_accuracy: 0.8109\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.9124 - val_loss: 0.4796 - val_accuracy: 0.8109\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.9197 - val_loss: 0.4680 - val_accuracy: 0.8073\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.9307 - val_loss: 0.4552 - val_accuracy: 0.8036\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2756 - accuracy: 0.9380 - val_loss: 0.4457 - val_accuracy: 0.8109\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2614 - accuracy: 0.9343 - val_loss: 0.4349 - val_accuracy: 0.8109\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2471 - accuracy: 0.9453 - val_loss: 0.4285 - val_accuracy: 0.8145\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2344 - accuracy: 0.9453 - val_loss: 0.4196 - val_accuracy: 0.8182\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2222 - accuracy: 0.9453 - val_loss: 0.4141 - val_accuracy: 0.8255\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2122 - accuracy: 0.9453 - val_loss: 0.4113 - val_accuracy: 0.8291\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2007 - accuracy: 0.9453 - val_loss: 0.4036 - val_accuracy: 0.8255\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1897 - accuracy: 0.9453 - val_loss: 0.3980 - val_accuracy: 0.8364\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9489 - val_loss: 0.3927 - val_accuracy: 0.8436\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1709 - accuracy: 0.9562 - val_loss: 0.3902 - val_accuracy: 0.8400\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1622 - accuracy: 0.9562 - val_loss: 0.3846 - val_accuracy: 0.8509\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9526 - val_loss: 0.3842 - val_accuracy: 0.8400\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9562 - val_loss: 0.3793 - val_accuracy: 0.8436\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1393 - accuracy: 0.9599 - val_loss: 0.3770 - val_accuracy: 0.8327\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1318 - accuracy: 0.9672 - val_loss: 0.3721 - val_accuracy: 0.8436\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1254 - accuracy: 0.9781 - val_loss: 0.3705 - val_accuracy: 0.8473\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9818 - val_loss: 0.3668 - val_accuracy: 0.8582\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1133 - accuracy: 0.9818 - val_loss: 0.3642 - val_accuracy: 0.8618\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1085 - accuracy: 0.9818 - val_loss: 0.3640 - val_accuracy: 0.8545\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1039 - accuracy: 0.9818 - val_loss: 0.3616 - val_accuracy: 0.8655\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0997 - accuracy: 0.9854 - val_loss: 0.3597 - val_accuracy: 0.8618\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9854 - val_loss: 0.3620 - val_accuracy: 0.8655\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 0.9891 - val_loss: 0.3605 - val_accuracy: 0.8618\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0875 - accuracy: 0.9854 - val_loss: 0.3570 - val_accuracy: 0.8618\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9891 - val_loss: 0.3588 - val_accuracy: 0.8618\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.9891 - val_loss: 0.3551 - val_accuracy: 0.8618\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0773 - accuracy: 0.9891 - val_loss: 0.3530 - val_accuracy: 0.8691\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0750 - accuracy: 0.9927 - val_loss: 0.3562 - val_accuracy: 0.8655\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9927 - val_loss: 0.3528 - val_accuracy: 0.8691\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9854 - val_loss: 0.3502 - val_accuracy: 0.8764\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0667 - accuracy: 0.9891 - val_loss: 0.3534 - val_accuracy: 0.8800\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9964 - val_loss: 0.3514 - val_accuracy: 0.8800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGyzl5ZaMB8L",
        "outputId": "ba477faa-b978-41a7-995f-a9094d2a35a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "tf.keras.utils.plot_model(nn, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEcRZGXM8ZD8"
      },
      "source": [
        "###***Deep Learning Neural Netwrok Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2_bXNR4tFKY",
        "outputId": "8f85191d-4d76-48da-e05d-9fae67e27adb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 - 0s - loss: 0.5745 - accuracy: 0.8033\n",
            "Loss: 0.5745446085929871, Accuracy: 0.8032786846160889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRFv96XA8ZD8"
      },
      "source": [
        "# # Evaluate the model using the test data\n",
        "# model_loss, FalseNegatives,FalsePositives, TrueNegatives, TruePositives, Precision, Recall = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "# print(f\"\"\"\\t  Loss: {model_loss},\n",
        "#           FalseNegatives: {FalseNegatives},\n",
        "#           FalsePositives: {FalsePositives},\n",
        "#           TrueNegatives: {TrueNegatives},\n",
        "#           TruePositives: {TruePositives},\n",
        "#           Precision: {Precision},\n",
        "#           Recall: {Recall},\"\"\")\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNJMznkl8ZEB",
        "outputId": "4c8c73fc-b756-4410-c5f4-d12867173817",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = nn.predict(X_test_scaled)\n",
        "adjusted_predictions = [(100 * x[0]) for x in predictions]\n",
        "adjusted_predictions"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0064141262555494905,\n",
              " 0.2206563949584961,\n",
              " 85.21192073822021,\n",
              " 0.006905828195158392,\n",
              " 1.7796099185943604,\n",
              " 99.97845888137817,\n",
              " 88.3445143699646,\n",
              " 64.17838335037231,\n",
              " 71.88423871994019,\n",
              " 32.619017362594604,\n",
              " 0.00033867488582473015,\n",
              " 0.22704899311065674,\n",
              " 96.6750979423523,\n",
              " 42.34113693237305,\n",
              " 2.8525084257125854,\n",
              " 0.13698339462280273,\n",
              " 68.86023283004761,\n",
              " 91.7477011680603,\n",
              " 17.077529430389404,\n",
              " 95.29946446418762,\n",
              " 26.6656756401062,\n",
              " 99.16309118270874,\n",
              " 95.23217678070068,\n",
              " 0.2637207508087158,\n",
              " 98.49535822868347,\n",
              " 53.82574796676636,\n",
              " 99.82576370239258,\n",
              " 95.355224609375,\n",
              " 99.66058731079102,\n",
              " 0.0592648983001709,\n",
              " 0.005503244756255299,\n",
              " 98.95365238189697,\n",
              " 0.0921398401260376,\n",
              " 5.287057161331177,\n",
              " 85.90685725212097,\n",
              " 0.0010101442057930399,\n",
              " 99.8742163181305,\n",
              " 98.03924560546875,\n",
              " 99.6018648147583,\n",
              " 0.10984838008880615,\n",
              " 99.75764751434326,\n",
              " 0.14682412147521973,\n",
              " 18.347156047821045,\n",
              " 70.65609693527222,\n",
              " 15.585222840309143,\n",
              " 98.00025820732117,\n",
              " 1.7791330814361572,\n",
              " 47.67730534076691,\n",
              " 94.96074914932251,\n",
              " 97.87572622299194,\n",
              " 0.03921985626220703,\n",
              " 85.68670749664307,\n",
              " 97.15970754623413,\n",
              " 9.094437956809998,\n",
              " 99.92631673812866,\n",
              " 0.04825294017791748,\n",
              " 96.85529470443726,\n",
              " 8.10224711894989,\n",
              " 99.72162246704102,\n",
              " 95.69520950317383,\n",
              " 94.16838884353638,\n",
              " 35.658663511276245,\n",
              " 98.65835309028625,\n",
              " 0.028240680694580078,\n",
              " 96.1399495601654,\n",
              " 33.6184024810791,\n",
              " 40.11476933956146,\n",
              " 98.32442998886108,\n",
              " 98.89165163040161,\n",
              " 89.69781398773193,\n",
              " 97.23187685012817,\n",
              " 98.73640537261963,\n",
              " 98.43775033950806,\n",
              " 92.82142519950867,\n",
              " 2.6852011680603027,\n",
              " 98.48999977111816,\n",
              " 0.4931628704071045,\n",
              " 80.50987720489502,\n",
              " 93.49411725997925,\n",
              " 99.82531070709229,\n",
              " 69.14669275283813,\n",
              " 0.19416511058807373,\n",
              " 4.353505373001099,\n",
              " 99.73374605178833,\n",
              " 96.02748155593872,\n",
              " 0.03923177719116211,\n",
              " 0.011348797852406278,\n",
              " 98.85629415512085,\n",
              " 1.6155540943145752,\n",
              " 99.9690294265747,\n",
              " 99.56989288330078,\n",
              " 4.168877005577087,\n",
              " 0.007359254959737882,\n",
              " 96.65234088897705,\n",
              " 7.396805286407471,\n",
              " 90.35694599151611,\n",
              " 97.82096743583679,\n",
              " 0.036394596099853516,\n",
              " 99.68680143356323,\n",
              " 98.72908592224121,\n",
              " 0.0016931257050600834,\n",
              " 81.73985481262207,\n",
              " 96.1527943611145,\n",
              " 62.25820183753967,\n",
              " 95.9674596786499,\n",
              " 86.26645803451538,\n",
              " 77.13311314582825,\n",
              " 27.77908444404602,\n",
              " 98.6440896987915,\n",
              " 89.03814554214478,\n",
              " 1.2707173824310303,\n",
              " 1.3291418552398682,\n",
              " 94.30629014968872,\n",
              " 6.774923205375671,\n",
              " 99.0311861038208,\n",
              " 3.084680438041687,\n",
              " 0.6470680236816406,\n",
              " 96.47153615951538,\n",
              " 0.011489223106764257,\n",
              " 22.327154874801636,\n",
              " 36.005836725234985,\n",
              " 7.759585976600647,\n",
              " 39.95465040206909,\n",
              " 1.9922226667404175,\n",
              " 99.8550534248352,\n",
              " 0.21391212940216064,\n",
              " 24.419087171554565,\n",
              " 0.1049339771270752,\n",
              " 5.0378113985061646,\n",
              " 88.768869638443,\n",
              " 98.6331045627594,\n",
              " 99.32733178138733,\n",
              " 99.20774698257446,\n",
              " 0.2948880195617676,\n",
              " 99.70117807388306,\n",
              " 59.86396670341492,\n",
              " 99.70771074295044,\n",
              " 0.14781057834625244,\n",
              " 74.10759925842285,\n",
              " 0.1548856496810913,\n",
              " 99.41997528076172,\n",
              " 89.07413482666016,\n",
              " 99.78660345077515,\n",
              " 0.0017234566257684492,\n",
              " 22.07282781600952,\n",
              " 98.1363832950592,\n",
              " 96.97999954223633,\n",
              " 80.66465854644775,\n",
              " 97.70386815071106,\n",
              " 1.7062634229660034,\n",
              " 73.57493042945862,\n",
              " 1.109573245048523,\n",
              " 0.5222141742706299,\n",
              " 3.6442220211029053,\n",
              " 0.0017489483070676215,\n",
              " 48.82303178310394,\n",
              " 10.788136720657349,\n",
              " 4.258736968040466,\n",
              " 1.3639450073242188,\n",
              " 84.77134704589844,\n",
              " 0.47506988048553467,\n",
              " 4.222303628921509,\n",
              " 57.15108513832092,\n",
              " 2.440965175628662,\n",
              " 99.76822137832642,\n",
              " 99.40065145492554,\n",
              " 12.418785691261292,\n",
              " 40.29923677444458,\n",
              " 47.64072299003601,\n",
              " 0.037869811058044434,\n",
              " 80.64824342727661,\n",
              " 3.1618356704711914,\n",
              " 95.7158088684082,\n",
              " 2.6454538106918335,\n",
              " 39.04922902584076,\n",
              " 4.222002625465393,\n",
              " 96.30095958709717,\n",
              " 99.76253509521484,\n",
              " 99.47590827941895,\n",
              " 1.6552865505218506,\n",
              " 99.0747332572937,\n",
              " 97.72422313690186,\n",
              " 0.02117455005645752]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B21n32Y_8ZEI"
      },
      "source": [
        "### ***Random Forest Classifier Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbi4Nt6S8ZEI",
        "outputId": "7c77d302-f198-42c2-abba-9335e1aabab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a random forest classifier.\n",
        "rf_model = RandomForestClassifier(n_estimators=256, random_state=32)\n",
        "\n",
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Random forest predictive accuracy: 0.956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ICcqS8oLBMd",
        "outputId": "2f6ee9d6-e873-43e1-f20d-3046e5e9c4ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 72   3]\n",
            " [  5 103]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NPfSMqy8ZEO"
      },
      "source": [
        "### ***Logistic Regression Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkpcmGoI8ZEP"
      },
      "source": [
        "# Create a Logistic Regression Model\n",
        "classifier = LogisticRegression(solver='lbfgs',\n",
        "                                max_iter=200,\n",
        "                                random_state=1)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh5RRLdU8ZEQ",
        "outputId": "17109e9c-6d5b-4163-ca25-619c1d224057",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit (train) or model using the training data\n",
        "classifier.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBrQHR2e8ZER",
        "outputId": "b0133134-82c6-4551-a20c-65d0803c414f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
        "results.head(20)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Prediction  Actual\n",
              "0            0       0\n",
              "1            0       0\n",
              "2            1       1\n",
              "3            0       0\n",
              "4            0       0\n",
              "5            1       1\n",
              "6            1       1\n",
              "7            1       1\n",
              "8            1       1\n",
              "9            1       1\n",
              "10           0       0\n",
              "11           0       0\n",
              "12           1       1\n",
              "13           0       0\n",
              "14           0       0\n",
              "15           0       0\n",
              "16           1       0\n",
              "17           1       1\n",
              "18           1       1\n",
              "19           1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXcYvmte8ZET",
        "outputId": "7c5da35d-03ff-4143-b887-67c032ee9ba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.907103825136612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IgWEnV9LFQH",
        "outputId": "9a8bba0c-2e7e-402f-9b1a-13a16ee9ac6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[68  7]\n",
            " [10 98]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnWP0hsq8zrQ"
      },
      "source": [
        "## ***Wine & Soil - Drop All weather columns***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zjTIfIy8zrR"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = White_Soil_ML_df[\"quality\"].values\n",
        "X = White_Soil_ML_df.drop([\"quality\",\"is_primeurs\", \"journalist_count\", \"confidence_index_A\",\"confidence_index_A+\", \"confidence_index_B\", \"confidence_index_B+\",\"confidence_index_C\", \"confidence_index_C+\",'avgPrcpFebruary',\n",
        " 'avgTempFebruary',\n",
        " 'avgPrcpMarch',\n",
        " 'avgTempMarch',\n",
        " 'avgPrcpApril',\n",
        " 'avgTempApril',\n",
        " 'avgPrcpMay',\n",
        " 'avgTempMay',\n",
        " 'avgPrcpJune',\n",
        " 'avgTempJune',\n",
        " 'avgPrcpJuly',\n",
        " 'avgTempJuly',\n",
        " 'avgPrcpAugust',\n",
        " 'avgTempAugust',\n",
        " 'avgPrcpSeptember',\n",
        " 'avgTempSeptember',\n",
        " 'avgPrcpOctober',\n",
        " 'avgTempOctober'],1).values"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvoFDc1r8zrV"
      },
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X)\n",
        "X_scaled = X_scaler.transform(X)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZBWe_JuLLVK"
      },
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, random_state=45)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLZR5S938zrY"
      },
      "source": [
        "###***Deep Learning Neural Netwrok for training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GH0R3gB8zrZ",
        "outputId": "e38be405-4266-4f24-f019-a990e2b07cec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[-1])\n",
        "hidden_nodes_layer1 =  24\n",
        "hidden_nodes_layer2 = 12\n",
        "\n",
        "# metrics = [\n",
        "#     tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "#     tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "#     tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "#     tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "#     tf.keras.metrics.Precision(name=\"precision\"),\n",
        "#     tf.keras.metrics.Recall(name=\"recall\"),\n",
        "# ]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.5)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.7567 - accuracy: 0.4964 - val_loss: 0.7231 - val_accuracy: 0.5636\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.5912 - val_loss: 0.6692 - val_accuracy: 0.6436\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6112 - accuracy: 0.6642 - val_loss: 0.6271 - val_accuracy: 0.6982\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.6971 - val_loss: 0.5919 - val_accuracy: 0.7309\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7299 - val_loss: 0.5639 - val_accuracy: 0.7636\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7628 - val_loss: 0.5404 - val_accuracy: 0.7600\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7920 - val_loss: 0.5179 - val_accuracy: 0.7600\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7993 - val_loss: 0.4955 - val_accuracy: 0.7636\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8102 - val_loss: 0.4780 - val_accuracy: 0.7745\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8285 - val_loss: 0.4605 - val_accuracy: 0.7782\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3567 - accuracy: 0.8394 - val_loss: 0.4443 - val_accuracy: 0.7927\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8467 - val_loss: 0.4304 - val_accuracy: 0.8000\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3221 - accuracy: 0.8540 - val_loss: 0.4201 - val_accuracy: 0.8182\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8650 - val_loss: 0.4111 - val_accuracy: 0.8182\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2914 - accuracy: 0.8723 - val_loss: 0.4006 - val_accuracy: 0.8182\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2788 - accuracy: 0.8759 - val_loss: 0.3916 - val_accuracy: 0.8145\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2654 - accuracy: 0.8905 - val_loss: 0.3838 - val_accuracy: 0.8255\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2517 - accuracy: 0.9051 - val_loss: 0.3776 - val_accuracy: 0.8255\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2407 - accuracy: 0.9197 - val_loss: 0.3710 - val_accuracy: 0.8364\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.9161 - val_loss: 0.3658 - val_accuracy: 0.8436\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2198 - accuracy: 0.9197 - val_loss: 0.3604 - val_accuracy: 0.8509\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2114 - accuracy: 0.9161 - val_loss: 0.3563 - val_accuracy: 0.8582\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2036 - accuracy: 0.9234 - val_loss: 0.3505 - val_accuracy: 0.8691\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1955 - accuracy: 0.9380 - val_loss: 0.3478 - val_accuracy: 0.8618\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1858 - accuracy: 0.9453 - val_loss: 0.3413 - val_accuracy: 0.8727\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9416 - val_loss: 0.3388 - val_accuracy: 0.8691\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1714 - accuracy: 0.9416 - val_loss: 0.3356 - val_accuracy: 0.8800\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1675 - accuracy: 0.9453 - val_loss: 0.3304 - val_accuracy: 0.8764\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1588 - accuracy: 0.9416 - val_loss: 0.3285 - val_accuracy: 0.8836\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1541 - accuracy: 0.9489 - val_loss: 0.3276 - val_accuracy: 0.8764\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9526 - val_loss: 0.3260 - val_accuracy: 0.8800\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1447 - accuracy: 0.9453 - val_loss: 0.3222 - val_accuracy: 0.8800\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1397 - accuracy: 0.9453 - val_loss: 0.3210 - val_accuracy: 0.8836\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1330 - accuracy: 0.9526 - val_loss: 0.3202 - val_accuracy: 0.8764\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1276 - accuracy: 0.9562 - val_loss: 0.3182 - val_accuracy: 0.8800\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9599 - val_loss: 0.3188 - val_accuracy: 0.8764\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1193 - accuracy: 0.9562 - val_loss: 0.3197 - val_accuracy: 0.8836\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1156 - accuracy: 0.9672 - val_loss: 0.3195 - val_accuracy: 0.8800\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1114 - accuracy: 0.9745 - val_loss: 0.3201 - val_accuracy: 0.8800\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1101 - accuracy: 0.9708 - val_loss: 0.3219 - val_accuracy: 0.8836\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1052 - accuracy: 0.9745 - val_loss: 0.3201 - val_accuracy: 0.8873\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1027 - accuracy: 0.9745 - val_loss: 0.3211 - val_accuracy: 0.8800\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9745 - val_loss: 0.3211 - val_accuracy: 0.8873\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0960 - accuracy: 0.9708 - val_loss: 0.3220 - val_accuracy: 0.8800\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 0.9781 - val_loss: 0.3246 - val_accuracy: 0.8836\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9781 - val_loss: 0.3241 - val_accuracy: 0.8836\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9781 - val_loss: 0.3208 - val_accuracy: 0.8909\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9854 - val_loss: 0.3260 - val_accuracy: 0.8836\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9781 - val_loss: 0.3242 - val_accuracy: 0.8836\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9781 - val_loss: 0.3229 - val_accuracy: 0.8909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ag1d7XoMJF9",
        "outputId": "5aab540b-84e6-48e1-bebd-308bec97785c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "tf.keras.utils.plot_model(nn, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-Cju5lo8zrb"
      },
      "source": [
        "###***Deep Learning Neural Network Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZlaGKpUtLqL",
        "outputId": "709c2d59-8fc6-441d-c358-21dedf892378",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 - 0s - loss: 0.6127 - accuracy: 0.7978\n",
            "Loss: 0.6127098798751831, Accuracy: 0.7978141903877258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NTSC0Kk8zrc"
      },
      "source": [
        "# # Evaluate the model using the test data\n",
        "# model_loss, FalseNegatives,FalsePositives, TrueNegatives, TruePositives, Precision, Recall = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "# print(f\"\"\"\\t  Loss: {model_loss},\n",
        "#           FalseNegatives: {FalseNegatives},\n",
        "#           FalsePositives: {FalsePositives},\n",
        "#           TrueNegatives: {TrueNegatives},\n",
        "#           TruePositives: {TruePositives},\n",
        "#           Precision: {Precision},\n",
        "#           Recall: {Recall},\"\"\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFA_Xo9k8zrg",
        "outputId": "55279033-5cd3-41fc-984b-a6578ad924f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = nn.predict(X_test_scaled)\n",
        "adjusted_predictions = [(100 * x[0]) for x in predictions]\n",
        "adjusted_predictions"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08802711963653564,\n",
              " 0.004111057933187112,\n",
              " 43.98035407066345,\n",
              " 0.0699758529663086,\n",
              " 0.3606259822845459,\n",
              " 99.72503185272217,\n",
              " 96.42541408538818,\n",
              " 95.63031196594238,\n",
              " 35.41777729988098,\n",
              " 35.78028082847595,\n",
              " 0.0037421472370624542,\n",
              " 0.613752007484436,\n",
              " 97.2659707069397,\n",
              " 25.32595992088318,\n",
              " 2.024403214454651,\n",
              " 0.1269906759262085,\n",
              " 41.35856628417969,\n",
              " 95.60009241104126,\n",
              " 10.830429196357727,\n",
              " 98.11418056488037,\n",
              " 18.72793436050415,\n",
              " 98.96997809410095,\n",
              " 96.90864086151123,\n",
              " 1.6222864389419556,\n",
              " 82.6221227645874,\n",
              " 3.7910133600234985,\n",
              " 99.99443292617798,\n",
              " 67.18054413795471,\n",
              " 67.53334999084473,\n",
              " 2.6472091674804688,\n",
              " 0.04284381866455078,\n",
              " 99.98641014099121,\n",
              " 0.01868307590484619,\n",
              " 26.19236707687378,\n",
              " 52.23735570907593,\n",
              " 0.0029922963221906684,\n",
              " 99.9768316745758,\n",
              " 99.91686344146729,\n",
              " 99.89306926727295,\n",
              " 3.372824192047119,\n",
              " 2.7604877948760986,\n",
              " 0.3530770540237427,\n",
              " 93.67771744728088,\n",
              " 95.60966491699219,\n",
              " 10.538670420646667,\n",
              " 99.95580911636353,\n",
              " 0.13417601585388184,\n",
              " 34.633809328079224,\n",
              " 66.59884452819824,\n",
              " 99.96137619018555,\n",
              " 63.4846031665802,\n",
              " 98.02182912826538,\n",
              " 99.87547397613525,\n",
              " 7.334154844284058,\n",
              " 99.78471994400024,\n",
              " 0.13865232467651367,\n",
              " 89.58277702331543,\n",
              " 0.38009583950042725,\n",
              " 99.99812841415405,\n",
              " 99.6659517288208,\n",
              " 99.60825443267822,\n",
              " 0.037679076194763184,\n",
              " 94.82331871986389,\n",
              " 0.2838701009750366,\n",
              " 96.19523286819458,\n",
              " 95.53180932998657,\n",
              " 46.614548563957214,\n",
              " 93.67161989212036,\n",
              " 94.96805667877197,\n",
              " 98.46481084823608,\n",
              " 82.75160789489746,\n",
              " 99.95414018630981,\n",
              " 6.994667649269104,\n",
              " 99.88832473754883,\n",
              " 11.18505597114563,\n",
              " 98.06692600250244,\n",
              " 0.0948488712310791,\n",
              " 99.50119256973267,\n",
              " 79.44221496582031,\n",
              " 99.95405673980713,\n",
              " 8.057013154029846,\n",
              " 0.04066824913024902,\n",
              " 0.11627078056335449,\n",
              " 98.14847707748413,\n",
              " 99.85243082046509,\n",
              " 0.0006632652457483346,\n",
              " 0.008274871652247384,\n",
              " 11.927446722984314,\n",
              " 3.3016979694366455,\n",
              " 99.24840927124023,\n",
              " 97.25620746612549,\n",
              " 0.0059297322877682745,\n",
              " 0.0026719853849499486,\n",
              " 92.25713610649109,\n",
              " 0.6030917167663574,\n",
              " 18.30439567565918,\n",
              " 99.86879825592041,\n",
              " 0.25132298469543457,\n",
              " 99.98501539230347,\n",
              " 99.1976261138916,\n",
              " 0.0011510142030601855,\n",
              " 3.831249475479126,\n",
              " 96.98877334594727,\n",
              " 61.52021884918213,\n",
              " 99.95389580726624,\n",
              " 65.48455357551575,\n",
              " 84.64256525039673,\n",
              " 21.17958664894104,\n",
              " 98.32531213760376,\n",
              " 58.9928925037384,\n",
              " 1.932525634765625,\n",
              " 0.010368409130023792,\n",
              " 99.7512698173523,\n",
              " 0.5123406648635864,\n",
              " 99.7055172920227,\n",
              " 2.555203437805176,\n",
              " 10.883843898773193,\n",
              " 97.86814451217651,\n",
              " 0.016424059867858887,\n",
              " 3.9146363735198975,\n",
              " 0.08435547351837158,\n",
              " 38.13287615776062,\n",
              " 86.61545515060425,\n",
              " 0.11347532272338867,\n",
              " 99.99352097511292,\n",
              " 0.10047554969787598,\n",
              " 16.828230023384094,\n",
              " 0.04562735557556152,\n",
              " 2.6301592588424683,\n",
              " 94.0964937210083,\n",
              " 98.42519164085388,\n",
              " 99.90952014923096,\n",
              " 99.97948408126831,\n",
              " 0.0819087028503418,\n",
              " 99.95776414871216,\n",
              " 64.06033039093018,\n",
              " 99.91925954818726,\n",
              " 1.1329501867294312,\n",
              " 35.08222997188568,\n",
              " 0.0012371081538731232,\n",
              " 64.88557457923889,\n",
              " 98.2414960861206,\n",
              " 99.9295711517334,\n",
              " 0.023290514945983887,\n",
              " 16.85299575328827,\n",
              " 99.69522953033447,\n",
              " 98.98826479911804,\n",
              " 42.332205176353455,\n",
              " 85.84438562393188,\n",
              " 0.034999847412109375,\n",
              " 99.17242527008057,\n",
              " 0.8334964513778687,\n",
              " 0.004088774949195795,\n",
              " 1.7290323972702026,\n",
              " 0.023812055587768555,\n",
              " 4.598557949066162,\n",
              " 67.59240627288818,\n",
              " 0.0243455171585083,\n",
              " 1.232960820198059,\n",
              " 75.47927498817444,\n",
              " 1.250600814819336,\n",
              " 16.661009192466736,\n",
              " 85.91192960739136,\n",
              " 1.3335376977920532,\n",
              " 99.97146725654602,\n",
              " 99.77659583091736,\n",
              " 11.532798409461975,\n",
              " 46.21060788631439,\n",
              " 21.986764669418335,\n",
              " 0.009535143180983141,\n",
              " 79.82646822929382,\n",
              " 3.6199957132339478,\n",
              " 99.70744848251343,\n",
              " 0.013116002082824707,\n",
              " 95.16972303390503,\n",
              " 0.10296106338500977,\n",
              " 0.0018529211956774816,\n",
              " 99.93904829025269,\n",
              " 63.905006647109985,\n",
              " 3.500223159790039,\n",
              " 99.78941082954407,\n",
              " 81.90140724182129,\n",
              " 0.007876180461607873]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scV4Bm6e8zrn"
      },
      "source": [
        "### ***Random Forest Classifier Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2qj25M98zro",
        "outputId": "94cd9ced-d381-4f84-d7ab-8dcec7a64ecf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a random forest classifier.\n",
        "rf_model = RandomForestClassifier(n_estimators=256, random_state=32)\n",
        "\n",
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Random forest predictive accuracy: 0.978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08o92INxMNQ0",
        "outputId": "665c8ae0-b650-4489-d978-098411401907",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 72   3]\n",
            " [  1 107]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN-emBmv8zrv"
      },
      "source": [
        "### ***Logistic Regression Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyhJm6re8zrv"
      },
      "source": [
        "# Create a Logistic Regression Model\n",
        "classifier = LogisticRegression(solver='lbfgs',\n",
        "                                max_iter=200,\n",
        "                                random_state=1)\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V5X1CAc8zry",
        "outputId": "ecd2c1e6-fabc-4a1e-fa0b-1fdf96b7f3c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit (train) or model using the training data\n",
        "classifier.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdxN4orO8zr0",
        "outputId": "b5e7e426-ab41-4ac7-f1e0-a85955b61190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
        "results.head(20)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Prediction  Actual\n",
              "0            0       0\n",
              "1            0       0\n",
              "2            1       1\n",
              "3            0       0\n",
              "4            0       0\n",
              "5            1       1\n",
              "6            1       1\n",
              "7            1       1\n",
              "8            1       1\n",
              "9            1       1\n",
              "10           0       0\n",
              "11           0       0\n",
              "12           1       1\n",
              "13           0       0\n",
              "14           0       0\n",
              "15           0       0\n",
              "16           1       0\n",
              "17           1       1\n",
              "18           1       1\n",
              "19           1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzHFt7yg8zr1",
        "outputId": "914b1df4-fac4-418f-e47d-998fc8ce2759",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.907103825136612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA9-0QZgMR16",
        "outputId": "8e78c4c3-59dc-4764-ec85-28a7a2240102",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[68  7]\n",
            " [10 98]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-KV7kap9ER0"
      },
      "source": [
        "## ***Wine, Weather & Soil***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfFjVq0Z9ER2"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = White_Soil_ML_df[\"quality\"].values\n",
        "X = White_Soil_ML_df.drop([\"quality\",\"is_primeurs\", \"journalist_count\", \"confidence_index_A\",\"confidence_index_A+\", \"confidence_index_B\", \"confidence_index_B+\",\"confidence_index_C\", \"confidence_index_C+\"],1).values"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQIo8cDn9ER5"
      },
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X)\n",
        "X_scaled = X_scaler.transform(X)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRhr3mgMMbQM"
      },
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, random_state=45)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MxQ4Kv79ER8"
      },
      "source": [
        "###***Deep Learning Neural Netwrok for training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z82pNgZC9ER9",
        "outputId": "8918b133-dd10-498c-d917-a6a3577a5f7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[-1])\n",
        "hidden_nodes_layer1 =  24\n",
        "hidden_nodes_layer2 = 12\n",
        "\n",
        "# metrics = [\n",
        "#     tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "#     tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "#     tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "#     tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "#     tf.keras.metrics.Precision(name=\"precision\"),\n",
        "#     tf.keras.metrics.Recall(name=\"recall\"),\n",
        "# ]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.5)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 0.8498 - accuracy: 0.4745 - val_loss: 0.7536 - val_accuracy: 0.5345\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7145 - accuracy: 0.5584 - val_loss: 0.6853 - val_accuracy: 0.6145\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6321 - accuracy: 0.6679 - val_loss: 0.6511 - val_accuracy: 0.6400\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5803 - accuracy: 0.7080 - val_loss: 0.6198 - val_accuracy: 0.6582\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7336 - val_loss: 0.5936 - val_accuracy: 0.6873\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5101 - accuracy: 0.7737 - val_loss: 0.5737 - val_accuracy: 0.7164\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.8029 - val_loss: 0.5564 - val_accuracy: 0.7200\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.8358 - val_loss: 0.5380 - val_accuracy: 0.7236\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8540 - val_loss: 0.5163 - val_accuracy: 0.7455\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8577 - val_loss: 0.4957 - val_accuracy: 0.7491\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8613 - val_loss: 0.4792 - val_accuracy: 0.7564\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8686 - val_loss: 0.4667 - val_accuracy: 0.7600\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.8832 - val_loss: 0.4531 - val_accuracy: 0.7709\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3013 - accuracy: 0.8869 - val_loss: 0.4393 - val_accuracy: 0.7636\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2814 - accuracy: 0.8905 - val_loss: 0.4304 - val_accuracy: 0.7782\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2630 - accuracy: 0.9015 - val_loss: 0.4256 - val_accuracy: 0.7855\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2478 - accuracy: 0.9051 - val_loss: 0.4203 - val_accuracy: 0.7927\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2342 - accuracy: 0.9051 - val_loss: 0.4086 - val_accuracy: 0.8036\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2201 - accuracy: 0.9088 - val_loss: 0.4045 - val_accuracy: 0.8109\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2110 - accuracy: 0.9197 - val_loss: 0.4117 - val_accuracy: 0.8218\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1989 - accuracy: 0.9307 - val_loss: 0.4014 - val_accuracy: 0.8145\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1872 - accuracy: 0.9270 - val_loss: 0.3981 - val_accuracy: 0.8182\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1765 - accuracy: 0.9343 - val_loss: 0.3969 - val_accuracy: 0.8182\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1690 - accuracy: 0.9380 - val_loss: 0.3964 - val_accuracy: 0.8291\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1603 - accuracy: 0.9380 - val_loss: 0.3849 - val_accuracy: 0.8364\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1534 - accuracy: 0.9380 - val_loss: 0.3811 - val_accuracy: 0.8436\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1456 - accuracy: 0.9453 - val_loss: 0.3838 - val_accuracy: 0.8364\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1398 - accuracy: 0.9489 - val_loss: 0.3863 - val_accuracy: 0.8400\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1335 - accuracy: 0.9562 - val_loss: 0.3819 - val_accuracy: 0.8400\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1272 - accuracy: 0.9562 - val_loss: 0.3783 - val_accuracy: 0.8473\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1199 - accuracy: 0.9599 - val_loss: 0.3794 - val_accuracy: 0.8509\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9708 - val_loss: 0.3830 - val_accuracy: 0.8618\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.9781 - val_loss: 0.3760 - val_accuracy: 0.8691\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9708 - val_loss: 0.3755 - val_accuracy: 0.8691\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1002 - accuracy: 0.9745 - val_loss: 0.3783 - val_accuracy: 0.8691\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9854 - val_loss: 0.3849 - val_accuracy: 0.8655\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9818 - val_loss: 0.3741 - val_accuracy: 0.8727\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0895 - accuracy: 0.9854 - val_loss: 0.3746 - val_accuracy: 0.8691\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9854 - val_loss: 0.3720 - val_accuracy: 0.8691\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9818 - val_loss: 0.3780 - val_accuracy: 0.8691\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 0.9891 - val_loss: 0.3782 - val_accuracy: 0.8727\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9927 - val_loss: 0.3790 - val_accuracy: 0.8727\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0738 - accuracy: 0.9927 - val_loss: 0.3829 - val_accuracy: 0.8727\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9891 - val_loss: 0.3691 - val_accuracy: 0.8727\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.9891 - val_loss: 0.3797 - val_accuracy: 0.8691\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9927 - val_loss: 0.3850 - val_accuracy: 0.8727\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9927 - val_loss: 0.3806 - val_accuracy: 0.8727\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9927 - val_loss: 0.3717 - val_accuracy: 0.8764\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9927 - val_loss: 0.3916 - val_accuracy: 0.8764\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.9927 - val_loss: 0.3921 - val_accuracy: 0.8727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD_aJFLuMu-l",
        "outputId": "01332d60-b4d2-4df8-8a75-0ea3effaf140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "tf.keras.utils.plot_model(nn, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0sAAABoCAYAAAAglGtzAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3de3RM5/oH8O/E5DaRSVxCIkFDtErp5aBJcGi7nCqtFrkVx8FpS3UVraqW0lbRpXFrXY6ldZxVPSUJGvfqQgU9iaanrTjUvS6RkiASkZDb8/vDb4aRScxkLnvPzPez1vxhz569n/08+3kzr5m9RyMiAiIiIiIiIrpTmpfSERAREREREakRJ0tERERERERmcLJERERERERkBidLREREREREZmjvXpCZmYn58+crEQsR3UNMTAzefPNNpcOol/nz5yMzM1PpMMhDvPnmm4iJiVE6jHqJj49XOgRyc+wPIvPS0tJqLKvxydK5c+ewdu1apwRERJbLyspy6clGZmYmsrKylA6DPMDatWtx7tw5pcOot7Vr1yI3N1fpMMhNsT+IasrNza11/lPjkyUDczMrIlKOO/xvWnR0NMcWcjiNRqN0CDZ74403kJCQoHQY5IbYH0Q1paamIjEx0exzvGaJiIiIiIjIDE6WiIiIiIiIzOBkiYiIiIiIyAxOloiIiIiIiMzgZImIiIiIiMgMh0yWXnrpJQQGBkKj0eDXX391xC4crqKiAtOnT0ebNm3g4+OD8PBwvPXWWygrK6vX9rZu3YqgoCBs2rTJzpE6T1ZWFh588EF4eXlBo9GgefPmmDlzptJhmVi3bh3atGkDjUYDjUaD0NBQDBs2TOmwyME45pi6uw8MDx8fHzRr1gy9e/dGcnIyCgsLHXAkpDR36AeD6upqLFiwALGxsbWus2/fPnTv3h06nQ5hYWGYPHkybt68afW+2DeewdP6w5J17sXje0PukpKSImYWW2316tUCQH755Rebt6WEsWPHip+fn6xevVqKi4vl+++/F71eL0OGDKnX9jZv3ix6vV42btxo50id7+mnnxYAUlhYqHQotWrbtq0EBQUpHYZdxcXFSVxcnNJh1Juj4+eYU9OdfVBdXS2FhYXy/fffy4gRI0Sj0UhYWJhkZ2fb6xBUA4CkpKQoHUa92SN+V+8HEZFjx45J9+7dBYA8/PDDZtf53//+J/7+/jJt2jQpKSmR//znP9K0aVMZOXJkvffr7n3D/vCc/rBkHWu4c2/UMf9J5dfwzDh16hSWLVuG4cOHIykpCYGBgejduzfGjRuHr7/+Gr/99pvV2+zfvz+Kiorw3HPPOSBi65SVldn0Pwxq4k7HQp7LEWPO3TQaDYKDg9G7d2+sXLkSqampuHjxonFsIlKTAwcO4J133sGrr76KRx55pNb1PvroI4SGhuLDDz9EQEAAYmJiMHnyZPzrX//CkSNHbI6DfUNqZEl/WNpD9eVJveGwyZIr/+hZdnY2qqur8fjjj5ss79u3LwBg+/btSoRlNytWrEB+fr7SYdiFOx0L2YZjjnXi4uIwYsQI5OfnY9myZXbfPinLlfsBAB5++GGsW7cOQ4cOha+vr9l1KisrsWXLFvTq1cvkeJ955hmICDZs2GD3uNg37sET+sOSdezJnXvDLpMlEUFycjIeeOAB+Pr6IigoCJMmTaqxXlVVFaZPn45WrVrB398fnTt3RkpKCgBg6dKlCAgIgE6nw4YNG/DMM89Ar9cjIiICq1evNtlORkYGunXrBp1OB71ej06dOqG4uPie+7CUl9ettPj7+5ssb9euHQBY/b+8+/btQ6tWraDRaLB48WKrjvezzz6Dn58fmjVrhjFjxiAsLAx+fn6IjY3F/v37jeuNGzcOPj4+CA0NNS577bXXEBAQAI1Gg0uXLgEAJkyYgIkTJ+LkyZPQaDSIiooCAHz77bfQ6/WYNWuWVcemxmOx1t69e9GhQwcEBQXBz88PnTp1Mr45femll4zfzW3bti1++eUXAMDIkSOh0+kQFBSEjRs3Aqj73Pvkk0+g0+kQGBiI/Px8TJw4EeHh4Th69Gi9YvZ0njzm2NKrdxsxYgQAYNu2bcZlrpIzus3d+sFSp06dQklJCVq1amWyvG3btgCAnJwc4zL2jefy1P6wFHvDAlZ8Z69WU6dOFY1GI/PmzZPCwkIpLS2VJUuW1Pg+6FtvvSW+vr6ydu1aKSwslClTpoiXl5fx+41Tp04VALJz504pKiqS/Px86dmzpwQEBEh5ebmIiJSUlIher5c5c+ZIWVmZXLhwQQYNGiQFBQUW7cMSOTk5AkCmTZtmsryyslIAyMCBA63Kj4jIuXPnBIAsWrTIJG/3Ol4RkdGjR0tAQIAcPnxYbty4IYcOHZKuXbtKYGCgnD171rje0KFDpXnz5ib7TU5OFgDG/IiIDB48WNq2bWuy3ubNmyUwMFBmzJhxz2Mxd82Smo5FxLprltLS0uSDDz6QK1euyOXLlyU6OlqaNGliso8GDRrI+fPnTV43ZMgQk2vQLD2/x48fL4sWLZJBgwbJb7/9ZlGMIrxm6U6ePOZY06v36oPi4mIBIC1btnS5nNUFHnZNhrv1w90ef/xxs9dbZGRkCABJTk6u8Zy/v7889dRTxn+zb25jf3hGf1i6DnvjlrquWbJ5slRaWio6nU769Oljsvzui+fKyspEp9NJUlKSyWt9fX1l7NixInI7YWVlZcZ1DCf0iRMnROTWxZwAZPPmzTVisWQflurbt680btxYdu7cKWVlZfLHH39IamqqaDQaefbZZ63alkjdk6W6jlfk1gTj7pMzOztbAMiHH35oXGbrBMNSdU2W1HIsttzgYfbs2QJA8vPzRURkx44dAkBmzpxpXKeoqEjatWsnlZWVIlL/89sanCzdwjHHcpb0gUajkeDgYBFxvZzVxpPeDLprP9yptjd63333nQCQ+fPn13hOr9dLbGxsvfbn7n3D/vCM/rB2HUu4c2849AYPJ06cQGlpKZ566qk61zt69ChKS0vx0EMPGZf5+/sjNDS0zoswfXx8ANy6rS4AtGnTBs2aNcOwYcPwwQcf4PTp0zbvw5w1a9YgPj4ew4cPR+PGjdG9e3d88803EBE0adLEqm1Z4+7jrU2XLl2g0+nscgGro7jqsXh7ewO49bEuADz55JO4//778c9//hMiAuDW+ZGUlIQGDRoAsO+5R3XjmGM/169fh4hAr9cDcL2ckfv2gyX8/PwA3Lp26W7l5eU1vtZqL+wb1+HJ/aEEd+0NmydLubm5AICQkJA617t+/ToA4L333jO5R/uZM2dQWlpq8f78/f2xa9cu9OjRA7NmzUKbNm2QlJSEsrIyu+0DAIKCgrBs2TLk5uaitLQUJ0+exLx58wAALVq0sGpbjuLr64uCggKlw7ALJY9ly5Yt6N27N0JCQuDr64u3337b5HmNRoMxY8bg1KlT2LlzJwDgyy+/xN///nfjOvY896huHHPs59ixYwCA9u3bA3C9nJH79oMlDNe1Gq5bMCgtLcWNGzcQFhZm930C7BtX4sn9oQR37Q2bJ0uG/9m51w/AGU7UBQsWQERMHpmZmVbts2PHjti0aRPy8vIwefJkpKSkYO7cuXbdhznZ2dkAgCeeeMLmbdmqoqICV69eRUREhNKh2MzZx7Jnzx4sWLAAAHD27FkMHDgQoaGh2L9/P4qKijBnzpwarxkxYgT8/PzwxRdf4OjRo9Dr9WjdurXxeUefe3Qbxxz7+fbbbwHcunsY4B458zSe1A93i4yMRGBgIM6cOWOy/MSJEwCAzp07232fAPvGlXhyfyjBXXvD5snSQw89BC8vL2RkZNS5XsuWLeHn52fzryXn5eXh8OHDAG4V4eOPP8Zjjz2Gw4cP220ftfn8888RGRmJXr16OWT71ti9ezdEBNHR0cZlWq32nl95UyNnH8t///tfBAQEAAAOHjyIiooKjB07Fm3atIGfn5/ZW4o2atQIiYmJSE9Px9y5c/Hyyy+bPO/oc49u45hjHxcuXMCCBQsQERGBUaNGAXCPnHkaT+qHu2m1WvTr1w979uxBdXW1cfm2bdug0WgwYMAAu++TfeNaPLk/nM2de8PmyVJISAgGDx6MtWvXYsWKFSguLkZOTg6WL19usp6fnx9GjhyJ1atXY+nSpSguLkZVVRVyc3Pxxx9/WLy/vLw8jBkzBkeOHEF5eTl++eUXnDlzBtHR0XbbBwB069YNZ86cQWVlJU6fPo233noLO3bswIoVK4zfpXSm6upqFBYWorKyEjk5OZgwYQJatWplvE0jAERFReHKlStIT09HRUUFCgoKavyPGwA0btwYeXl5OH36NK5du4aKigps27bNbreOVPpYalNRUYGLFy9i9+7dxsmS4ZazO3bswI0bN3D8+HGT25jf6dVXX8XNmzexefPmGj8ubM9zj+rm6WOOtb0qIigpKUF1dTVEBAUFBUhJSUH37t3RoEEDpKenG79f7mo5I/ftB0tNmzYNFy9exPvvv4/r168jMzMTycnJGDFiBB544AHjeuwbz+Tp/WEJ9oZlB23p3SBqde3aNXnppZekSZMm0rBhQ+nRo4dMnz5dAEhERIQcOHBARERu3rwpkydPllatWolWq5WQkBAZPHiwHDp0SJYsWSI6nU4ASLt27eTkyZOyfPly0ev1AkBat24tx44dk9OnT0tsbKw0atRIGjRoIC1atJCpU6ca70pW1z6s0adPHwkODhatViuNGjWS/v371/vWjosWLZLQ0FABIDqdTgYMGGDx8YrcuoOct7e3hIeHi1arFb1eLy+88IKcPHnSZD+XL1+WJ554Qvz8/CQyMlJef/11mTRpkgCQqKgo4625f/75Z2ndurX4+/tLjx495MKFC7J161YJDAw0uePb3bKysqRjx47i5eUlACQ0NFRmzZqlqmP5xz/+IW3bthUAdT7Wr19v3NfkyZOlcePGEhwcLPHx8bJ48WIBIG3btjW5nbmIyKOPPirvvvuu2fzUde7NmTNH/P39jbfUXLVqlSWnjgneDe82Tx5zLOnVjRs3SufOnUWn04mPj4+xZw13KerWrZvMmDFDLl++XOO1rpSz2sCD7vYl4p79kJmZKd27d5ewsDDjuB0aGiqxsbGSkZFhsm5GRoZ069ZNfH19JSwsTCZNmiQ3btwwWYd9cxv7wzP6w9IeYm/cUtfd8DQi/397r/+XmpqKxMRE3LWYFDRmzBikpaXh8uXLSodiM1c/lv79+2Px4sWIjIx0+r7j4+MBAGlpaU7ftz24evzkOjQaDVJSUpCQkKB0KPXi6vGTurn6+eXq8ZM61TH/SbP5a3jkHIbbWLsDVzqWO7/Wl5OTAz8/P0UmSkRERETkfB4zWTpy5IjJLQVreyQlJSmyPVKnyZMn4/jx4zh27BhGjhyJjz76SOmQyEVwjCC6jf1AVDv2h7pplQ7AWdq3b2/Xrxbae3u1mTJlClauXIny8nJERkYiOTkZcXFxDt+vI7jiseh0OrRv3x7h4eFYsmQJOnTooHRI5CKcNUYQuQL2A1Ht2B/q5jGfLLmq2bNn4+bNmxAR/P7776qfXNTFFY9l5syZqKqqwtmzZ2vcAY+IiIiI3BsnS0RERERERGZwskRERERERGQGJ0tERERERERmcLJERERERERkBidLREREREREZtR663CNRuPMOIjIAq5wB8G6rF27lmMLkQUSExORmJiodBhEqsT+IGeqdbKUkpLizDjIRomJiZgwYQJiYmKUDoUcZMGCBUqHYLPo6Gi88cYbSoehSob6Mj+2c4c3URzPa8rMzMTChQv5/sRG7A/3w78ftjOML+bUOllKSEhwWEBkf4mJiYiJiWHd3FhaWprSIdgsIiKC52gtDPVlfmznDm8GOZ6bt3DhQubFRuwP98O/H/ZR22SJ1ywRERERERGZwckSERERERGRGZwsERERERERmcHJEhERERERkRmcLBEREREREZmh2snS1q1bERQUhE2bNikdChEpjOMB0b2xT4hqx/6g+lLtZElElA6BiFSC4wHRvbFPiGrH/qD6Uu1kqX///igqKsJzzz2ndCgoKytDbGys0mF4JGfknvW1zokTJ5CSkoLS0lKn7ZPjgXOx7+zjm2++wU8//eS0/bFPnIc9YrslS5YgLy/PaftjfziHO/aGaidLarJixQrk5+crHYZHckbuWV/rnDt3DklJSWjatCmGDh2KLVu2oKKiQumwnMYTzhf2nX2sW7cOXbt2xX333Yf3338fR44cUTokp3H3+rJHbDdx4kRERETgz3/+M7744gsUFhYqHZLTuHNt3bI35C4pKSliZrFT7d27V1q2bCkAZNGiRSIismTJEtHpdOLv7y/p6enSt29fCQwMlPDwcPn666+Nr/3000/F19dXQkJCZPTo0RIaGiq+vr4SExMjWVlZxvVef/118fb2lubNmxuXjR07VnQ6nQCQgoICEREZP368+Pj4CAABIG3bthURkW3btklgYKDMnDnTGSm5JwCSkpKidBhSXV0t8+bNk/bt24uPj48EBwfL888/L7/99ptxHVty76n1FRGJi4uTuLg4pcOQXbt2GfOl1WoFgOj1ehkzZoxkZGRIVVWV2dfVN35PGQ9sqS/7zpRaxsOhQ4eKRqMx6ZWOHTtKcnKynD17ttbX1Sd+T+gTW96fsEduU0t/GI7Py8tLGjRoIFqtVvr16yerV6+W69ev1/o69kdN/Pvh0PElVZWTJRGRc+fOmZzUIiJTp04VALJz504pKiqS/Px86dmzpwQEBEh5eblxvdGjR0tAQIAcPnxYbty4IYcOHZKuXbtKYGCgyR+ooUOHmhRFRCQ5OdmkKCIigwcPNhbDYPPmzRIYGCgzZsyw96HXi1oGv+nTp4uPj4+sWrVKrl69Kjk5OfLYY49J06ZN5cKFC8b1bMm9J9ZXRJ2TpTsfhsErJCRExo0bJ3v37jV5nS3xe8J4YEt+2Hem1DIeDh06VLy8vEz6RKPRiLe3t2g0GunWrZssXLhQLl68aPK6+sbv7n1iy/sT9shtaumPO9/wGh4NGjQQLy8v8fHxkf79+0tqaqrcvHnT5HXsj5r498Oh40uqS34NLzY2Fnq9HiEhIUhKSsL169dx9uxZk3W0Wi0efPBB+Pr6okOHDli6dCmuXbuGlStX2iWG/v37o7i4GNOmTbPL9txBWVkZ5s+fj0GDBmHYsGEICgpCp06dsGzZMly6dAnLly+3275YX/UpLy8HABQUFGDZsmXo2bMnIiIi8M477+Do0aMO26+njwfsO9ciIqioqICIIDs7GxMnTkRYWBiefPJJfPnll7h27ZpD9uvJfcIecR1VVVWorq5GeXk5vvvuOyQkJKBJkyYYPnw4Nm3ahKqqKofs11P7g71hGa3dt+hkPj4+AHDPaya6dOkCnU7nUd8Zd7ZDhw6hpKQEXbp0MVnetWtX+Pj4YP/+/Q7bt6fU96effkJCQoKiMVjyPWHDxOn8+fOYN28e5syZg+DgYLRu3Rp5eXlo0aKFQ2LzxPGAfWfeqlWrsHbtWkVjOHToUJ3Pi4jxzV9GRgZ2796NV155BcCtXn/hhReM57Q9eVqfsEdq+vLLLxXvj+rq6jqfN5yfJSUlWLNmDVatWoVmzZoBAE6fPu2wuDypP9gblnHJT5bqy9fXFwUFBUqH4bauXr0KAGjYsGGN54KDgx32P6YGrC9Zw13OF/YdOZI71Jc9Qo7i6rVlb1jG5T9ZslRFRQWuXr2KiIgIpUNxW8HBwQBgtrkcnXtPqW+XLl2QmpqqaAzff/89nnzyyTrX8fHxQXl5OcLDwzFs2DCMHDkS7733HgA47FMla7jT+cK+M++vf/2r4p/CDhs2rM7/NdVoNPDy8oKIoFevXhgxYgQGDhwIvV6PLl26OORTJWuoub7WYI/UNHz4cMX7w9fXt87nvb29UVFRgYYNG2LgwIGIj49Hv379oNVqcd999zknyDqotbbWYG9YxmMmS7t374aIIDo62rhMq9V61C2PHe2hhx5Cw4YNa/yuyP79+1FeXo4//elPxmX2zj3rqzzDBCkkJAQvvvgi4uPj0aNHD6XDMsudzhf2nWvRaDTQarWorKxE165dMWTIELz44ovGrxepibvUlz3iOho0aAARgVarRZ8+ffC3v/0Nzz//vOL/cWCOO9SWvWEZt/0aXnV1NQoLC1FZWYmcnBxMmDABrVq1wogRI4zrREVF4cqVK0hPT0dFRQUKCgpw5syZGttq3Lgx8vLycPr0aVy7dg0VFRXYtm0b9Ho9Zs2a5cSjUjc/Pz9MnDgR69evx1dffYXi4mIcPHgQr776KsLCwjB69GjjurbkHmB91UKrvfX/LXq9HqNGjUJGRgYuXLiATz/9VFUTJXc+X9h36iYiAG73SocOHTB79mycOXMG+/fvx/jx41UzUXLX+rJH1M3LywsNGjSAVqvF008/jX//+98oLCzE5s2bER8fr5qJkjvWlr1hIStunec0ixYtktDQUAEgOp1OBgwYYLwfPgBp166dnDx5UpYvXy56vV4ASOvWreXYsWMicusWhd7e3hIeHi5arVb0er288MILcvLkSZP9XL58WZ544gnx8/OTyMhIef3112XSpEkCQKKiooy3M/z555+ldevW4u/vLz169JALFy7I1q1bVfU7PFDJrUCrq6slOTlZ2rVrJ97e3tKoUSMZOHCgHD161GQ9W3LvifUVUd+tw/39/WXIkCGyefNmk1us1qa+8XvKeGDr72Sw725Ty3g4dOhQ4/k4ffp0k98tqUt94veEPrH1d5bYI7eopT98fX1Fo9FIz5495fPPP5crV65Y9Dr2R038++HQ8UW9v7Nki9GjR0vjxo2VDsOp1DL4OYMn1ldEPZOl48ePy5o1a+r80UBzlIrfVc4XtdS3Nq6SRxH1jIfr16+X7Oxsq1+nRPyuUF+1vz9xhRyKqKc/Fi9eLOfPn7f6deyPmvj3w3Z1TZbc9polR92Ln9SB9VVOVFQUoqKilA7DKjxf7IN5tM7AgQOVDsEqrK/tmEPLvfbaa0qHYBXW1jaunD+3vWaJiIiIiIjIFm43WZoyZQpWrlyJoqIiREZGKv6ja2RfrC9Zg+eLfTCP7o31tR1z6L5YW9u4Q/7c7mt4s2fPxuzZs5UOgxyE9SVr8HyxD+bRvbG+tmMO3Rdraxt3yJ/bfbJERERERERkD5wsERERERERmcHJEhERERERkRmcLBEREREREZlR6w0eUlNTnRkH2UFmZqbSIZAD5ebmIiIiQukwbJKbm8uxpRa5ubkAOPbSLRzPazLkhD1C7A9T/PthuzrPqdp+wZYPPvhQ30PNv9B9L3FxcYrnjw/PeaSkpCh9yteb0rnjw/0f7A8++DD/MCO11k+Wbp2P5Mri4+MBAGlpaQpHQvZgqKcri4uL4/loBxqNBikpKUhISFA6FFXSaDRKh2Az1tdy7AfrsD88G/vFvNTUVCQmJpp9jtcsERERERERmcHJEhERERERkRmcLBEREREREZnByRIREREREZEZnCwRERERERGZwckSERERERGRGU6dLI0ZMwYajcb4GDZsWI11duzYgXfffRfV1dUYOHAgWrVqBT8/P4SHh+P5559HTk6O1fudMWMGOnToAL1eD19fX0RFReHtt99GSUmJ2fWrq6uxYMECxMbG1nt7GzduxJw5c1BVVWXy2vT0dJMcNG3a1OrjUQPW0n1q6Src/XxyFjXk0eDGjRto37493nvvPeMypfPjLlhn6zgiXwbuMG64K9bdNkrlz+l5ufuXlww/SusIo0ePlsaNG8u2bdvk6NGjcuPGDZPnp0+fLs8995wUFxdLRUWFNGnSRPbu3SvXr1+XU6dOSZ8+fSQoKEjOnz9v1X579eolS5YskcuXL0txcbGkpKSIt7e39O3bt8a6x44dk+7duwsAefjhh23a3sKFC6VXr15SWFhoXFZdXS25ubmyZ88e6devnzRp0sSqY7FGXFycw37ElLV0bi1FHFtPZ7Alfk84n6wB1O9HJdWQxzu9+eabAkCmTp1qslyp/KiFrfF7Sp0N1JovEXWNGwae3h8GnlZ3A3fJn73zUsf8J9Xpk6Xw8HCzz3388cdy//33S1lZmYiIVFRUyLPPPmuyzo8//igAZNasWVbtt3///lJZWWmyLCEhQQDI2bNnjct+/fVXGTRokHz11VfyyCOP1FogS7cnIjJu3DiJiYmRioqKGtsZP368S0+WWMvbHF1LEc+dLHni+XQv9fljp4Y83umHH36Qv/zlL2bfRIs4Pz9qYkv8nlRnA7XmS23jhoEn94eBJ9bdwF3yJ2LfvKh+snT8+HHRarWyevXqOl9/6dIlASCjRo2yOZaxY8cKADly5IjZ5x9//PE6C2Tp9q5cuSL+/v6SnJxc4zXuOFliLR3HEydLnno+3Yu1f+zUlsfS0lKJjY2Vw4cP1/om2pn5UZv6xu9pdTZwhXypYdww8NT+MPDUuhu4U/7smZe6JkuquMHDZ599BhHBgAED6lyvrKwMAKDX623e5/nz5+Hv74/IyEibt1XX9ho1aoRevXph4cKFEBG77EvNWEuyJ55P9qG2PE6dOhWvvfYaQkJCan09+816rLN1lMiXpdQwbrgr1t02asqfs/KiisnSli1b8MADD0Cn09W53o8//ggA6NGjh037Ky0txa5du/Dyyy/Dx8fHpm1Zsr1HH30U58+fx4EDB2zel9qxlmRPPJ/sQ015/OGHH3Dy5EkMGTLkntthv1mHdbaOs/NlKbWMG+6KdbeN2vLnjLwoPlm6fv06fv/9d7Rt27bWdS5evIg1a9Zg/PjxiImJueds9l5mz56NsLAwzJw506btWLq9du3aAQAOHjxol/2pFWtJ9sTzyT7UlMeysjJMmDABS5cutWg77DfLsc7WUSJfllLDuOGuWHfbqDF/zsiL1mFbtlB+fj5EpM4ZakxMDK5fv46EhATMnDkT3t7e9d7f+vXrkZqaiu+++w6BgYH13o412zMc28WLF23en5qxlmRPPJ/sQ015nDJlCl555RWEh4dbtC32m+VYZ+s4O1+WUsu44a5Yd9uoMX/OyIvik6UbN24AAHx9fWtdp1mzZlixYgU6duW08GsAAAT6SURBVOxo077WrFmD+fPnY/fu3WjRooVN27Jme/7+/gBuH6u7Yi3Jnng+2Yda8rhv3z4cPHgQ8+fPt3h77DfLsc7WcWa+LKWmccNdse62UWP+nJEXxSdLhoOs64elQkJCEBwcbNN+Fi1ahO3bt2PXrl1o2LChTduydnvl5eUAbh+ru2ItyZ54PtmHWvK4YsUK7Ny5E15eNb/9PWvWLMyaNQvZ2dno0qWLcTn7zXKss3WclS9LqW3ccFesu23Ulj/AOXlRfLLUrFkzaDQaFBUV1brOpk2b6r19EcE777yDwsJCpKenQ6u17ZDrsz3DsTVv3tymfasda0n2xPPJPtSSx5UrV2LlypUmyy5duoSQkBBMnTrV7Pf02W+WY52t4+h8WUqt44a7Yt1to5b83ckZeVH8Bg86nQ5t2rRBbm6u2edPnDiB5s2bIzExscZzSUlJaN68OX7++edat3/48GF88skn+Pzzz+Ht7Q2NRmPymDt3rlXx1md7hmPr1KmTVftyNawl2RPPJ/twtTzeif1mOdbZOo7Ol6XUOm64K9bdNmrJ352ckRfFJ0sA0L9/fxw6dMh4T/Y71XXf9PLycuTn52PDhg21rmPNfdezsrLQo0cPtGjRAvv378eBAwcQFhaG7t27Y8+ePVZvzyA7Oxvh4eHo3Lmz1a91Nawl2RPPJ/tQSx6txX6zDutsHUfmC3D9ccNdse62UUP+7uSUvFjxC7Y2Gz16tISHh9dYbvg14FWrVlm1vaqqKunZs6esWLHCXiHa3aVLl8TPz0/mzp1b47nx48dLkyZNHLbvuLg4iYuLc8i2WUtTjq6liGPr6Qz1id9Tz6d7gZW/wO6KeXRmftSmvvF7Wp0NmC/reGp/GHhq3Q3cKX/2zEsd859Up3+yVFZWhu3bt+P48ePGi7KioqIwY8YMzJgxAyUlJRZtp6qqCunp6bh27RqSkpIcGbJNPvjgAzzyyCMYN24cgFuz7ry8POzbtw8nTpxQODrbsJbuU0u18qTzyZFcMY/OzI+7YJ2tw3x5JtbdNmrKn7Py4vTJ0pUrV9C3b1/cf//9GDVqlHH5u+++i/j4eCQlJdV54ZjB7t27sW7dOmzbtu2evyKslPnz5+PXX3/F1q1bjfeZ37BhA8LDw9GzZ09s2bJF4Qhtw1q6Ty3VzFPOJ0dzpTwqkR93wTpbh/nyTKy7bdSQP6fmxYqPoZxi+/btMnnyZMX2by/p6ekye/ZsqaysVCwGpb+2xVral9L1tJWt8fN8ug02fI1C7XlUOj9qYI/4PaHOBsyXddgft3lS3Q3cIX+OyEtdX8PTiJhejZWamorExESHXsxJzhEfHw8ASEtLUzgSsgdXr6erx68mGo0GKSkpSEhIUDoUVXL1/Lh6/M7GfFnH1fPl6vErjfkzr475T5oq7oZHRERERESkNpwsERERERERmcHJEhERERERkRmcLBEREREREZmhre0Jw8XY5LqysrIAsJbuIisrC9HR0UqHYZOsrCyej3ayYMEC3izDjbG+1mG+PAvrbRvmr6bc3Nxan6sxWWrZsiXi4uIcGhA5h6u/sSZT0dHRiImJUTqMenPl2NWGY3Td4uLi0LJlS6XDqDfW1zrMl3XYH56N+TMvIiKi1tzUuHU4ERERERER8dbhREREREREZnGyREREREREZAYnS0RERERERGZwskRERERERGTG/wHHI8JuudQ+UgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkHkpRVZ9ER_"
      },
      "source": [
        "###***Deep Learning Neural Netwrok Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcnZuE7rtSTA",
        "outputId": "0784661f-83a2-4f0c-bbc2-eeeaf93b6b42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 - 0s - loss: 0.7145 - accuracy: 0.8033\n",
            "Loss: 0.7144671082496643, Accuracy: 0.8032786846160889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r_lF0JY9ESB"
      },
      "source": [
        "# # Evaluate the model using the test data\n",
        "# model_loss, FalseNegatives,FalsePositives, TrueNegatives, TruePositives, Precision, Recall = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "# print(f\"\"\"\\t  Loss: {model_loss},\n",
        "#           FalseNegatives: {FalseNegatives},\n",
        "#           FalsePositives: {FalsePositives},\n",
        "#           TrueNegatives: {TrueNegatives},\n",
        "#           TruePositives: {TruePositives},\n",
        "#           Precision: {Precision},\n",
        "#           Recall: {Recall},\"\"\")"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZeAxXr7M5i9",
        "outputId": "836b5d1a-7aa4-42bf-9f51-8ae9b5284a44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = nn.predict(X_test_scaled)\n",
        "adjusted_predictions = [(100 * x[0]) for x in predictions]\n",
        "adjusted_predictions"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02815425395965576,\n",
              " 0.005695317668141797,\n",
              " 80.66374063491821,\n",
              " 0.011793423618655652,\n",
              " 0.0022423877453547902,\n",
              " 99.9942421913147,\n",
              " 96.89832925796509,\n",
              " 45.278555154800415,\n",
              " 67.20733046531677,\n",
              " 1.559630036354065,\n",
              " 4.361480474472046,\n",
              " 0.9572595357894897,\n",
              " 83.74871015548706,\n",
              " 34.33014750480652,\n",
              " 5.747807025909424,\n",
              " 0.014030933380126953,\n",
              " 91.26483201980591,\n",
              " 93.90217661857605,\n",
              " 0.3431260585784912,\n",
              " 77.74291038513184,\n",
              " 24.002936482429504,\n",
              " 98.6578106880188,\n",
              " 99.70828890800476,\n",
              " 0.5833327770233154,\n",
              " 99.60113763809204,\n",
              " 79.42137718200684,\n",
              " 99.89848732948303,\n",
              " 91.67826175689697,\n",
              " 95.2355146408081,\n",
              " 0.0930100679397583,\n",
              " 0.14748871326446533,\n",
              " 99.98944997787476,\n",
              " 0.2110123634338379,\n",
              " 9.462511539459229,\n",
              " 76.98593139648438,\n",
              " 0.011180355068063363,\n",
              " 99.96813535690308,\n",
              " 98.31074476242065,\n",
              " 99.63759183883667,\n",
              " 0.2407282590866089,\n",
              " 78.60758304595947,\n",
              " 0.015082955360412598,\n",
              " 37.966519594192505,\n",
              " 26.919785141944885,\n",
              " 0.34071505069732666,\n",
              " 97.08819389343262,\n",
              " 0.07821917533874512,\n",
              " 33.44128727912903,\n",
              " 35.34709811210632,\n",
              " 99.94786381721497,\n",
              " 3.082096576690674,\n",
              " 98.87720346450806,\n",
              " 99.74436163902283,\n",
              " 3.446251153945923,\n",
              " 99.92974996566772,\n",
              " 0.0849306583404541,\n",
              " 94.76901292800903,\n",
              " 0.4349350929260254,\n",
              " 99.945068359375,\n",
              " 99.46290850639343,\n",
              " 99.73630905151367,\n",
              " 0.16833245754241943,\n",
              " 88.12549114227295,\n",
              " 0.06932616233825684,\n",
              " 97.62400388717651,\n",
              " 58.50454568862915,\n",
              " 29.51069176197052,\n",
              " 98.44846725463867,\n",
              " 99.95150566101074,\n",
              " 99.76375102996826,\n",
              " 43.33640933036804,\n",
              " 99.1375207901001,\n",
              " 1.2404054403305054,\n",
              " 99.66813325881958,\n",
              " 1.3924777507781982,\n",
              " 97.07335233688354,\n",
              " 0.19515752792358398,\n",
              " 98.49627017974854,\n",
              " 95.97541689872742,\n",
              " 99.82534050941467,\n",
              " 52.90401577949524,\n",
              " 0.057578086853027344,\n",
              " 0.30334293842315674,\n",
              " 99.95703101158142,\n",
              " 99.85053539276123,\n",
              " 0.8504003286361694,\n",
              " 0.0688403844833374,\n",
              " 2.6486188173294067,\n",
              " 0.10328292846679688,\n",
              " 98.84666204452515,\n",
              " 99.84077215194702,\n",
              " 0.36888420581817627,\n",
              " 0.06116926670074463,\n",
              " 96.54386043548584,\n",
              " 44.15339529514313,\n",
              " 6.863957643508911,\n",
              " 97.19682931900024,\n",
              " 0.06051957607269287,\n",
              " 99.91514682769775,\n",
              " 98.59226942062378,\n",
              " 0.012110551324440166,\n",
              " 94.85493898391724,\n",
              " 97.61884808540344,\n",
              " 49.81141686439514,\n",
              " 99.75112676620483,\n",
              " 75.37503242492676,\n",
              " 83.66771936416626,\n",
              " 8.941599726676941,\n",
              " 97.06913828849792,\n",
              " 9.981977939605713,\n",
              " 6.022113561630249,\n",
              " 0.005151786899659783,\n",
              " 99.6096134185791,\n",
              " 79.39598560333252,\n",
              " 99.6342658996582,\n",
              " 0.5353659391403198,\n",
              " 4.607981443405151,\n",
              " 71.61862850189209,\n",
              " 0.02065300941467285,\n",
              " 8.767160773277283,\n",
              " 15.074491500854492,\n",
              " 4.475480318069458,\n",
              " 5.713915824890137,\n",
              " 0.1543670892715454,\n",
              " 99.954092502594,\n",
              " 0.14833807945251465,\n",
              " 12.950992584228516,\n",
              " 0.062209367752075195,\n",
              " 17.34181046485901,\n",
              " 91.88287854194641,\n",
              " 98.81564378738403,\n",
              " 99.76587891578674,\n",
              " 99.97167587280273,\n",
              " 0.10477900505065918,\n",
              " 99.83210563659668,\n",
              " 77.74242162704468,\n",
              " 99.37742948532104,\n",
              " 0.03140270709991455,\n",
              " 75.64506530761719,\n",
              " 0.038877129554748535,\n",
              " 87.85197734832764,\n",
              " 99.3719220161438,\n",
              " 99.65900182723999,\n",
              " 0.007666490273550153,\n",
              " 12.142935395240784,\n",
              " 99.66265559196472,\n",
              " 85.38524508476257,\n",
              " 61.338430643081665,\n",
              " 80.92265129089355,\n",
              " 0.3799170255661011,\n",
              " 97.677481174469,\n",
              " 0.4748225212097168,\n",
              " 0.00024175303678930504,\n",
              " 0.6840646266937256,\n",
              " 0.006584738002857193,\n",
              " 0.46378374099731445,\n",
              " 5.701723694801331,\n",
              " 0.17661452293395996,\n",
              " 0.9383022785186768,\n",
              " 79.25781011581421,\n",
              " 0.49908459186553955,\n",
              " 1.6906976699829102,\n",
              " 21.02394998073578,\n",
              " 13.690903782844543,\n",
              " 99.91715550422668,\n",
              " 99.76377487182617,\n",
              " 11.174693703651428,\n",
              " 4.100090265274048,\n",
              " 45.37740349769592,\n",
              " 0.7264554500579834,\n",
              " 86.54811382293701,\n",
              " 0.7058799266815186,\n",
              " 99.29286241531372,\n",
              " 1.272633671760559,\n",
              " 67.25416779518127,\n",
              " 0.21053850650787354,\n",
              " 2.0191699266433716,\n",
              " 99.91451501846313,\n",
              " 90.69952964782715,\n",
              " 2.9381126165390015,\n",
              " 99.97243881225586,\n",
              " 97.94337153434753,\n",
              " 0.04985928535461426]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc-m16Nr9ESK"
      },
      "source": [
        "### ***Random Forest Classifier Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3Td-0zH9ESK",
        "outputId": "2c0c796f-8c62-46e5-dc91-5e4222f18b10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a random forest classifier.\n",
        "rf_model = RandomForestClassifier(n_estimators=256, random_state=32)\n",
        "\n",
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Random forest predictive accuracy: 0.945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xj8nt8cM-oW",
        "outputId": "48b9cd19-ba94-478b-90ef-03aeaaa0be7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 72   3]\n",
            " [  7 101]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZfEmRyi9ESQ"
      },
      "source": [
        "### ***Logistic Regression Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXiMrIEp9ESQ"
      },
      "source": [
        "# Create a Logistic Regression Model\n",
        "classifier = LogisticRegression(solver='lbfgs',\n",
        "                                max_iter=200,\n",
        "                                random_state=1)\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM1hI9zp9ESS",
        "outputId": "8a2df80f-986f-407b-c43d-c446c1baa7cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit (train) or model using the training data\n",
        "classifier.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nVPSP459EST",
        "outputId": "5d983c48-a82f-4032-f5ab-bbc603249c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
        "results.head(20)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Prediction  Actual\n",
              "0            0       0\n",
              "1            0       0\n",
              "2            1       1\n",
              "3            0       0\n",
              "4            0       0\n",
              "5            1       1\n",
              "6            1       1\n",
              "7            1       1\n",
              "8            1       1\n",
              "9            1       1\n",
              "10           0       0\n",
              "11           0       0\n",
              "12           1       1\n",
              "13           0       0\n",
              "14           0       0\n",
              "15           0       0\n",
              "16           1       0\n",
              "17           1       1\n",
              "18           1       1\n",
              "19           1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84DZ0DjH9ESU",
        "outputId": "e1e3ea16-3c74-407d-e568-c756ef575340",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.907103825136612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkCsJSTGNDw2",
        "outputId": "b2afe048-b047-4ebf-e391-68011d62f265",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[68  7]\n",
            " [10 98]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}